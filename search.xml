<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[基于领域模型理念设计下的3D数据应用平台]]></title>
    <url>%2F2020%2F%E9%9A%90%E8%97%8F%2F%E5%9F%BA%E4%BA%8E%E9%A2%86%E5%9F%9F%E6%A8%A1%E5%9E%8B%E7%90%86%E5%BF%B5%E8%AE%BE%E8%AE%A1%E4%B8%8B%E7%9A%843D%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8%E5%B9%B3%E5%8F%B0%2F</url>
    <content type="text"><![CDATA[什么是领域模型领域模型设计几大领域： 3D模型项目领域 用户领域 套餐领域 文件系统领域 子领域： 3D模型项目： 模型属性 项目属性 用户： 积分子领域 组织/空间 用户基本属性 套餐： 订单 财务 发票 模型实体： 刚体 PBR 材质]]></content>
      <categories>
        <category>技术博文</category>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>3D</tag>
        <tag>平台架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于operator sdk编写k8s自定义资源管理应用]]></title>
    <url>%2F2020%2F%E8%BF%90%E7%BB%B4%2F%E5%9F%BA%E4%BA%8Eoperator-sdk%E6%A1%86%E6%9E%B6%E7%BC%96%E5%86%99CRD%2F</url>
    <content type="text"><![CDATA[为什么要CRD在 Kubernetes 中我们使用的 Deployment， DamenSet，StatefulSet, Service，Ingress, ConfigMap, Secret 这些都是资源，而对这些资源的创建、更新、删除的动作都会被成为为事件(Event)，Kubernetes 的 Controller Manager 负责事件监听，并触发相应的动作来满足期望（Spec），这种方式也就是声明式，即用户只需要关心应用程序的最终状态。当我们在使用中发现现有的这些资源不能满足我们的需求的时候，Kubernetes 提供了自定义资源（Custom Resource）和 opertor 为应用程序提供基于 kuberntes 扩展。CRD 则是对自定义资源的描述(Custom Resource Definition)，也就是介绍这个资源有什么属性呀，这些属性的类型是什么，结构是怎样的这类。 我们看一个postgres-operator的CRD：apiVersion: apiextensions.k8s.io/v1beta1kind: CustomResourceDefinitionmetadata: name: postgresqls.acid.zalan.do labels: app.kubernetes.io/name: postgres-operator annotations: "helm.sh/hook": crd-installspec: group: acid.zalan.do names: kind: postgresql listKind: postgresqlList plural: postgresqls singular: postgresql shortNames: - pg additionalPrinterColumns: - name: Team type: string description: Team responsible for Postgres CLuster JSONPath: .spec.teamId - name: Version type: string description: PostgreSQL version JSONPath: .spec.postgresql.version - name: Pods type: integer description: Number of Pods per Postgres cluster JSONPath: .spec.numberOfInstances - name: Volume type: string description: Size of the bound volume JSONPath: .spec.volume.size - name: CPU-Request type: string description: Requested CPU for Postgres containers JSONPath: .spec.resources.requests.cpu - name: Memory-Request type: string description: Requested memory for Postgres containers JSONPath: .spec.resources.requests.memory - name: Age type: date JSONPath: .metadata.creationTimestamp - name: Status type: string description: Current sync status of postgresql resource JSONPath: .status.PostgresClusterStatus... operator是什么operator 是一种 kubernetes 的扩展形式，利用自定义资源对象（Custom Resource）来管理应用和组件，允许用户以 Kubernetes 的声明式 API 风格来管理应用及服务。operator主要是为解决特定应用或服务关于如何运行、部署及出现问题时如何处理提供的一种特定的自定义方式。比如： 按需部署应用服务（总不能用一大堆configmap来管理吧，也会很混乱~w(ﾟДﾟ)w） 实现应用状态的备份和还原，完成版本升级，比如 数据库 schema 或额外的配置设置的改动 为分布式应用进行master选举，例如etcd，或者master-slave架构的mysql集群。 operator SDKoperator SDK —— operator framework，是 CoreOS 公司开发和维护的用于快速创建 operator 的工具，可以帮助我们快速构建 operator 应用，类似的工具还有： KUDO (Kubernetes 通用声明式 Operator) kubebuilder，kubernetes SIG 在维护的一个项目 Metacontroller，可与 Webhook 结合使用，以实现自己的功能。 如果希望查看 Operator 生态，可以上 operatorhub.io ，也可以将自己创建的应用发布上去。 operator 安装安装 operator sdk:export RELEASE_VERSION=v0.13.0curl -LO https://github.com/operator-framework/operator-sdk/releases/download/$&#123;RELEASE_VERSION&#125;/operator-sdk-$&#123;RELEASE_VERSION&#125;-x86_64-linux-gnuchmod +x operator-sdk-$&#123;RELEASE_VERSION&#125;-x86_64-linux-gnu &amp;&amp; sudo mkdir -p /usr/local/bin/ &amp;&amp; sudo cp operator-sdk-$&#123;RELEASE_VERSION&#125;-x86_64-linux-gnu /usr/local/bin/operator-sdk &amp;&amp; rm operator-sdk-$&#123;RELEASE_VERSION&#125;-x86_64-linux-gnu 基于模板创建项目用operator sdk 创建项目模板，这里用官方提供的一个sample-controller的模板：operator-sdk new &lt;controller-name&gt; --repo github.com/kubernetes/sample-controller 项目结构目录创建完成，如下：$ operator-sdk new test-controller --repo github.com/kubernetes/sample-controller$ tree.├── build│ ├── bin│ │ ├── entrypoint│ │ └── user_setup│ └── Dockerfile├── cmd│ └── manager│ └── main.go├── deploy│ ├── operator.yaml│ ├── role_binding.yaml│ ├── role.yaml│ └── service_account.yaml├── go.mod├── go.sum├── pkg│ ├── apis│ │ └── apis.go│ └── controller│ └── controller.go├── tools.go└── version └── version.go 创建CRD创建CRD：operator-sdk add api --api-version=&lt;api的版本&gt; --kind=&lt;类型名称&gt; 创建CRD后，多出来了文件夹：$ operator-sdk add api --api-version=test.k8s.realibox.com/v1 --kind=RealiboxINFO[0000] Generating api version test.k8s.realibox.com/v1 for kind Realibox. INFO[0000] Created pkg/apis/test/group.go INFO[0002] Created pkg/apis/test/v1/realibox_types.go INFO[0002] Created pkg/apis/addtoscheme_test_v1.go INFO[0002] Created pkg/apis/test/v1/register.go INFO[0002] Created pkg/apis/test/v1/doc.go INFO[0002] Created deploy/crds/test.k8s.realibox.com_v1_realibox_cr.yaml INFO[0004] Created deploy/crds/test.k8s.realibox.com_realiboxes_crd.yaml INFO[0004] Running deepcopy code-generation for Custom Resource group versions: [test:[v1], ] INFO[0014] Code-generation complete. INFO[0014] Running CRD generation for Custom Resource group versions: [test:[v1], ] INFO[0014] Created deploy/crds/test.k8s.realibox.com_realiboxes_crd.yaml INFO[0014] CRD generation complete. INFO[0014] API generation complete. $ tree...├── pkg│ ├── apis│ │ ├── addtoscheme_test_v1.go│ │ ├── apis.go│ │ └── test│ │ ├── group.go│ │ └── v1│ │ ├── doc.go│ │ ├── realibox_types.go│ │ ├── register.go│ │ └── zz_generated.deepcopy.go│ └── controller│ └── controller.go... test 文件夹下面放得就是 CRD，我们通过pkg/apis/test/v1/*_types.go文件定义我们的CRD结构，主要是Spec和Status：vim pkg/apis/test/v1/realibox_types.go...// RealiboxSpec defines the desired state of Realiboxtype RealiboxSpec struct &#123; // INSERT ADDITIONAL SPEC FIELDS - desired state of cluster // Important: Run "operator-sdk generate k8s" to regenerate code after modifying this file // Add custom validation using kubebuilder tags: https://book-v1.book.kubebuilder.io/beyond_basics/generating_crd.html&#125;type RealiboxStatus struct &#123; // INSERT ADDITIONAL STATUS FIELD - define observed state of cluster // Important: Run "operator-sdk generate k8s" to regenerate code after modifying this file // Add custom validation using kubebuilder tags: https://book-v1.book.kubebuilder.io/beyond_basics/generating_crd.html&#125;... 这里我们只改Spec字段，将RealiboxSpec结构体改为：type RealiboxSpec struct &#123; Domain string `json:"domain,omitempty"` OSS string `json:"oss,omitempty"` Size string `json:"size,omitempty"`&#125; 更新CRD文件：operator-sdk generate k8soperator-sdk generate crds CRD本质是一种k8s的资源，因此要使用crd，需要在K8s集群上创建CRD：kubectl apply -f deploy/crds/test.k8s.realibox.com_realiboxes_crd.yaml 查看集群CRD：$ kubectl get crdNAME CREATED ATclusterauthtokens.cluster.cattle.io 2020-08-29T06:41:42Zclusteruserattributes.cluster.cattle.io 2020-08-29T06:41:42Zrealiboxes.test.k8s.realibox.com 2020-08-29T07:57:44Z 编写controller创建好 CRD 后，我们可以编写 controller 了，先创建一个 controller 监听和核对新创建的realibox资源类型：operator-sdk add controller --api-version=&lt;api的版本&gt; --kind=&lt;类型名称&gt; $ operator-sdk add controller --api-version=test.k8s.realibox.com/v1 --kind=Realibox$ tree...├── pkg│ ├── apis│ │ ├── addtoscheme_test_v1.go│ │ ├── apis.go│ │ └── test│ │ ├── group.go│ │ └── v1│ │ ├── doc.go│ │ ├── realibox_types.go│ │ ├── register.go│ │ └── zz_generated.deepcopy.go│ └── controller│ ├── add_realibox.go│ ├── controller.go│ └── realibox│ └── realibox_controller.go... 在pkg/controller目录下生成了controller代码，在pkg/controller/realibox/realibox_controller.go编写代码逻辑即可，在这里，我将CR信息在创建pod之前打印到日志里：...func (r *ReconcileRealibox) Reconcile(request reconcile.Request) (reconcile.Result, error) &#123; ... reqLogger.Info(fmt.Sprintf("Domain: %v created, oss info:%v, size: %v",instance.Spec.Domain,instance.Spec.OSS, instance.Spec.Size)) // Define a new Pod object pod := newPodForCR(instance) ...&#125;... 下面就可以运行 controller 了。 运行 controller运行controller有两种方法，可以在本地直接运行controller，也可以打包到k8s运行。 本地运行controller在本地运行controller直接go run就可以了：export WATCH_NAMESPACE=defaultgo run cmd/manager/main.go 注意：不管是在本地运行还是远程运行都需要先在集群中创建CRD 运行好后我们可以编写一个CR资源，提交到k8s集群中：apiVersion: test.k8s.realibox.com/v1kind: Realiboxmetadata: name: example-realiboxspec: domain: "realibox.com" oss: "aliyun.com" size: "3Gb" 通过kubectl提交到集群，可以看到controller程序已经收到CR注册内容打印出来了：...&#123;"level":"info","ts":1598689291.273161,"logger":"controller_realibox","msg":"Domain: realibox.com created, oss info:aliyun.com, size: 3Gb","Request.Namespace":"default","Request.Name":"example-realibox"&#125;&#123;"level":"info","ts":1598689291.2731829,"logger":"controller_realibox","msg":"Skip reconcile: Pod already exists","Request.Namespace":"default","Request.Name":"example-realibox","Pod.Namespace":"default","Pod.Name":"example-realibox-pod"&#125;... 打包提交到k8s运行如果我们controller完成，我们可以将其打包放到k8s上运行： 打包镜像 这里用的阿里云镜像仓库：operator-sdk build registry.cn-shenzhen.aliyuncs.com/shikanon/realibox-operator-test:v0.1 --image-builder docker 将打包好镜像上传镜像仓库：docker login --username=shikanon@foxmail.com registry.cn-shenzhen.aliyuncs.comdocker push registry.cn-shenzhen.aliyuncs.com/shikanon/realibox-operator-test:v0.1 更改deploy/operator.yaml里面的镜像名称：... spec: serviceAccountName: test-controller containers: - name: test-controller # Replace this with the built image name image: registry.cn-shenzhen.aliyuncs.com/shikanon/realibox-operator-test:v0.1 command: - test-controller imagePullPolicy: Always... 将deploy下的YAML文件提交到集群中kubectl apply -f deploy/service_account.yamlkubectl apply -f deploy/role.yamlkubectl apply -f deploy/role_binding.yamlkubectl apply -f deploy/operator.yaml 查看状态，确保全部成功：$ kubectl get allNAME READY STATUS RESTARTS AGEpod/test-controller-75bf886d9c-whjdn 1/1 Running 0 23sNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEservice/kubernetes ClusterIP 10.43.0.1 &lt;none&gt; 443/TCP 123mservice/test-controller-metrics ClusterIP 10.43.100.251 &lt;none&gt; 8383/TCP,8686/TCP 12sNAME READY UP-TO-DATE AVAILABLE AGEdeployment.apps/test-controller 1/1 1 1 23sNAME DESIRED CURRENT READY AGEreplicaset.apps/test-controller-75bf886d9c 1 1 1 23s 提交CR 这和单机运行是一样的，编写一个CR提交到集群，然后可以通过controller的pod日志查看到变化：$ kubectl logs -f test-controller-75bf886d9c-whjdn...&#123;"level":"info","ts":1598690827.2699623,"logger":"controller_realibox","msg":"Reconciling Realibox","Request.Namespace":"default","Request.Name":"example-realibox"&#125;&#123;"level":"info","ts":1598690827.270006,"logger":"controller_realibox","msg":"Domain: realibox.com created, oss info:aliyun.com, size: 3Gb","Request.Namespace":"default","Request.Name":"example-realibox"&#125;&#123;"level":"info","ts":1598690827.2700245,"logger":"controller_realibox","msg":"Skip reconcile: Pod already exists","Request.Namespace":"default","Request.Name":"example-realibox","Pod.Namespace":"default","Pod.Name":"example-realibox-pod"&#125;... 参考文献 https://kubernetes.io/zh/docs/concepts/extend-kubernetes/operator/ https://liqiang.io/post/kubernetes-all-about-crd-part06-kubebuilder-and-operator-sdk-d6e0858e https://coreos.com/blog/introducing-operators.html https://cloud.google.com/blog/products/containers-kubernetes/best-practices-for-building-kubernetes-operators-and-stateful-apps]]></content>
      <categories>
        <category>技术博文</category>
        <category>容器技术</category>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>operator</tag>
        <tag>CRD</tag>
        <tag>kuberntes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[knative安装与实践]]></title>
    <url>%2F2020%2F%E9%9A%90%E8%97%8F%2Fknative%E5%AE%89%E8%A3%85%E4%B8%8E%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[安装knative官方安装步骤安装CRDkubectl apply --filename https://github.com/knative/serving/releases/download/v0.17.0/serving-crds.yaml 安装knative serving安装serving-core，出现镜像无法拉取错误ImagePullBackOff错误，看了下是镜像地址是墙外地址gcr.io，把他换成阿里云地址：kubectl edit deployment -nknative-serving # Please edit the object below. Lines beginning with a '#' will be ignored,# and an empty file will abort the edit. If an error occurs while saving this file will be# reopened with the relevant failures.#apiVersion: v1items:- apiVersion: extensions/v1beta1 kind: Deployment metadata: annotations: deployment.kubernetes.io/revision: "2" kubectl.kubernetes.io/last-applied-configuration: | &#123;"apiVersion":"apps/v1","kind":"Deployment","metadata":&#123;"annotations":&#123;&#125;,"labels":&#123;"serving.knative.dev/release":"v0.17.0"&#125;,"name":"activator","namespace":"knative-serving"&#125;,"spec":&#123;"selector":&#123;"matchLabels":&#123;"app":"activator","role":"activator"&#125;&#125;,"template":&#123;"metadata":&#123;"annotations":&#123;"cluster-autoscaler.kubernetes.io/safe-to-evict":"false"&#125;,"labels":&#123;"app":"activator","role":"activator","serving.knative.dev/release":"v0.17.0"&#125;&#125;,"spec":&#123;"containers":[&#123;"env":[&#123;"name":"GOGC","value":"500"&#125;,&#123;"name":"POD_NAME","valueFrom":&#123;"fieldRef":&#123;"fieldPath":"metadata.name"&#125;&#125;&#125;,&#123;"name":"POD_IP","valueFrom":&#123;"fieldRef":&#123;"fieldPath":"status.podIP"&#125;&#125;&#125;,&#123;"name":"SYSTEM_NAMESPACE","valueFrom":&#123;"fieldRef":&#123;"fieldPath":"metadata.namespace"&#125;&#125;&#125;,&#123;"name":"CONFIG_LOGGING_NAME","value":"config-logging"&#125;,&#123;"name":"CONFIG_OBSERVABILITY_NAME","value":"config-observability"&#125;,&#123;"name":"METRICS_DOMAIN","value":"knative.dev/internal/serving"&#125;],"image":"gcr.io/knative-releases/knative.dev/serving/cmd/activator@sha256:18aadbb4796d7b6316ae971be5233dac28cd794c517e220d127aa9e21d91df42","livenessProbe":&#123;"failureThreshold":12,"httpGet":&#123;"httpHeaders":[&#123;"name":"k-kubelet-probe","value":"activator"&#125;],"port":8012&#125;&#125;,"name":"activator","ports":[&#123;"containerPort":9090,"name":"metrics"&#125;,&#123;"containerPort":8008,"name":"profiling"&#125;,&#123;"containerPort":8012,"name":"http1"&#125;,&#123;"containerPort":8013,"name":"h2c"&#125;],"readinessProbe":&#123;"failureThreshold":12,"httpGet":&#123;"httpHeaders":[&#123;"name":"k-kubelet-probe","value":"activator"&#125;],"port":8012&#125;&#125;,"resources":&#123;"limits":&#123;"cpu":"1000m","memory":"600Mi"&#125;,"requests":&#123;"cpu":"300m","memory":"60Mi"&#125;&#125;,"securityContext":&#123;"allowPrivilegeEscalation":false&#125;&#125;],"serviceAccountName":"controller","terminationGracePeriodSeconds":600&#125;&#125;&#125;&#125; creationTimestamp: "2020-08-25T06:46:49Z" generation: 2 labels: serving.knative.dev/release: v0.17.0 name: activator namespace: knative-serving resourceVersion: "22295922" selfLink: /apis/extensions/v1beta1/namespaces/knative-serving/deployments/activator uid: 581c1b91-b378-4f47-9b3d-ef900d50e23c spec: progressDeadlineSeconds: 600 replicas: 1 revisionHistoryLimit: 10 selector: matchLabels: app: activator role: activator strategy: rollingUpdate: maxSurge: 25% maxUnavailable: 25% type: RollingUpdate template: metadata: annotations: cluster-autoscaler.kubernetes.io/safe-to-evict: "false" creationTimestamp: null labels: app: activator role: activator serving.knative.dev/release: v0.17.0 spec: containers: - env: - name: GOGC value: "500" - name: POD_NAME valueFrom: fieldRef: apiVersion: v1 fieldPath: metadata.name - name: POD_IP valueFrom: fieldRef: apiVersion: v1 fieldPath: status.podIP - name: SYSTEM_NAMESPACE valueFrom: fieldRef: apiVersion: v1 fieldPath: metadata.namespace - name: CONFIG_LOGGING_NAME value: config-logging - name: CONFIG_OBSERVABILITY_NAME value: config-observability - name: METRICS_DOMAIN value: knative.dev/internal/serving image: registry.cn-shenzhen.aliyuncs.com/shikanon/knative-releases.knative.dev.serving.cmd.activator:v0.17.0 imagePullPolicy: IfNotPresent livenessProbe: failureThreshold: 12 httpGet: httpHeaders: - name: k-kubelet-probe value: activator path: / port: 8012 scheme: HTTP periodSeconds: 10 successThreshold: 1 timeoutSeconds: 1 name: activator ports: - containerPort: 9090 name: metrics protocol: TCP - containerPort: 8008 name: profiling protocol: TCP - containerPort: 8012 name: http1 protocol: TCP - containerPort: 8013 name: h2c protocol: TCP readinessProbe: failureThreshold: 12 httpGet: httpHeaders: - name: k-kubelet-probe value: activator path: / port: 8012 scheme: HTTP periodSeconds: 10 successThreshold: 1 timeoutSeconds: 1 resources: limits: cpu: "1" memory: 600Mi requests: cpu: 300m memory: 60Mi securityContext: allowPrivilegeEscalation: false terminationMessagePath: /dev/termination-log terminationMessagePolicy: File dnsPolicy: ClusterFirst restartPolicy: Always schedulerName: default-scheduler securityContext: &#123;&#125; serviceAccount: controller serviceAccountName: controller terminationGracePeriodSeconds: 600 status: availableReplicas: 1 conditions: - lastTransitionTime: "2020-08-25T07:27:17Z" lastUpdateTime: "2020-08-25T07:27:17Z" message: Deployment has minimum availability. reason: MinimumReplicasAvailable status: "True" type: Available - lastTransitionTime: "2020-08-25T07:26:49Z" lastUpdateTime: "2020-08-25T07:27:17Z" message: ReplicaSet "activator-5d9f6d7d4c" has successfully progressed. reason: NewReplicaSetAvailable status: "True" type: Progressing observedGeneration: 2 readyReplicas: 1 replicas: 1 updatedReplicas: 1- apiVersion: extensions/v1beta1 kind: Deployment metadata: annotations: deployment.kubernetes.io/revision: "2" kubectl.kubernetes.io/last-applied-configuration: | &#123;"apiVersion":"apps/v1","kind":"Deployment","metadata":&#123;"annotations":&#123;&#125;,"labels":&#123;"serving.knative.dev/release":"v0.17.0"&#125;,"name":"autoscaler","namespace":"knative-serving"&#125;,"spec":&#123;"replicas":1,"selector":&#123;"matchLabels":&#123;"app":"autoscaler"&#125;&#125;,"template":&#123;"metadata":&#123;"annotations":&#123;"cluster-autoscaler.kubernetes.io/safe-to-evict":"false"&#125;,"labels":&#123;"app":"autoscaler","serving.knative.dev/release":"v0.17.0"&#125;&#125;,"spec":&#123;"affinity":&#123;"podAntiAffinity":&#123;"preferredDuringSchedulingIgnoredDuringExecution":[&#123;"podAffinityTerm":&#123;"labelSelector":&#123;"matchLabels":&#123;"app":"autoscaler"&#125;&#125;,"topologyKey":"kubernetes.io/hostname"&#125;,"weight":100&#125;]&#125;&#125;,"containers":[&#123;"env":[&#123;"name":"SYSTEM_NAMESPACE","valueFrom":&#123;"fieldRef":&#123;"fieldPath":"metadata.namespace"&#125;&#125;&#125;,&#123;"name":"CONFIG_LOGGING_NAME","value":"config-logging"&#125;,&#123;"name":"CONFIG_OBSERVABILITY_NAME","value":"config-observability"&#125;,&#123;"name":"METRICS_DOMAIN","value":"knative.dev/serving"&#125;],"image":"gcr.io/knative-releases/knative.dev/serving/cmd/autoscaler@sha256:0af019e5d0b936468f85f5ca3c658b4913e5ac08734cf377bbbd8ba93eaa9db0","livenessProbe":&#123;"httpGet":&#123;"httpHeaders":[&#123;"name":"k-kubelet-probe","value":"autoscaler"&#125;],"port":8080&#125;&#125;,"name":"autoscaler","ports":[&#123;"containerPort":9090,"name":"metrics"&#125;,&#123;"containerPort":8008,"name":"profiling"&#125;,&#123;"containerPort":8080,"name":"websocket"&#125;],"readinessProbe":&#123;"httpGet":&#123;"httpHeaders":[&#123;"name":"k-kubelet-probe","value":"autoscaler"&#125;],"port":8080&#125;&#125;,"resources":&#123;"limits":&#123;"cpu":"300m","memory":"400Mi"&#125;,"requests":&#123;"cpu":"30m","memory":"40Mi"&#125;&#125;,"securityContext":&#123;"allowPrivilegeEscalation":false&#125;&#125;],"serviceAccountName":"controller"&#125;&#125;&#125;&#125; creationTimestamp: "2020-08-25T06:46:49Z" generation: 2 labels: serving.knative.dev/release: v0.17.0 name: autoscaler namespace: knative-serving resourceVersion: "22295236" selfLink: /apis/extensions/v1beta1/namespaces/knative-serving/deployments/autoscaler uid: 64e12ab1-f79c-44ec-ab19-29a940daa80a spec: progressDeadlineSeconds: 600 replicas: 1 revisionHistoryLimit: 10 selector: matchLabels: app: autoscaler strategy: rollingUpdate: maxSurge: 25% maxUnavailable: 25% type: RollingUpdate template: metadata: annotations: cluster-autoscaler.kubernetes.io/safe-to-evict: "false" creationTimestamp: null labels: app: autoscaler serving.knative.dev/release: v0.17.0 spec: affinity: podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - podAffinityTerm: labelSelector: matchLabels: app: autoscaler topologyKey: kubernetes.io/hostname weight: 100 containers: - env: - name: SYSTEM_NAMESPACE valueFrom: fieldRef: apiVersion: v1 fieldPath: metadata.namespace - name: CONFIG_LOGGING_NAME value: config-logging - name: CONFIG_OBSERVABILITY_NAME value: config-observability - name: METRICS_DOMAIN value: knative.dev/serving image: registry.cn-shenzhen.aliyuncs.com/shikanon/knative-releases.knative.dev.serving.cmd.autoscaler:v0.17.0 imagePullPolicy: IfNotPresent livenessProbe: failureThreshold: 3 httpGet: httpHeaders: - name: k-kubelet-probe value: autoscaler path: / port: 8080 scheme: HTTP periodSeconds: 10 successThreshold: 1 timeoutSeconds: 1 name: autoscaler ports: - containerPort: 9090 name: metrics protocol: TCP - containerPort: 8008 name: profiling protocol: TCP - containerPort: 8080 name: websocket protocol: TCP readinessProbe: failureThreshold: 3 httpGet: httpHeaders: - name: k-kubelet-probe value: autoscaler path: / port: 8080 scheme: HTTP periodSeconds: 10 successThreshold: 1 timeoutSeconds: 1 resources: limits: cpu: 300m memory: 400Mi requests: cpu: 30m memory: 40Mi securityContext: allowPrivilegeEscalation: false terminationMessagePath: /dev/termination-log terminationMessagePolicy: File dnsPolicy: ClusterFirst restartPolicy: Always schedulerName: default-scheduler securityContext: &#123;&#125; serviceAccount: controller serviceAccountName: controller terminationGracePeriodSeconds: 30 status: availableReplicas: 1 conditions: - lastTransitionTime: "2020-08-25T07:27:07Z" lastUpdateTime: "2020-08-25T07:27:07Z" message: Deployment has minimum availability. reason: MinimumReplicasAvailable status: "True" type: Available - lastTransitionTime: "2020-08-25T07:26:49Z" lastUpdateTime: "2020-08-25T07:27:07Z" message: ReplicaSet "autoscaler-7c6b98ddf6" has successfully progressed. reason: NewReplicaSetAvailable status: "True" type: Progressing observedGeneration: 2 readyReplicas: 1 replicas: 1 updatedReplicas: 1- apiVersion: extensions/v1beta1 kind: Deployment metadata: annotations: deployment.kubernetes.io/revision: "2" kubectl.kubernetes.io/last-applied-configuration: | &#123;"apiVersion":"apps/v1","kind":"Deployment","metadata":&#123;"annotations":&#123;&#125;,"labels":&#123;"serving.knative.dev/release":"v0.17.0"&#125;,"name":"controller","namespace":"knative-serving"&#125;,"spec":&#123;"selector":&#123;"matchLabels":&#123;"app":"controller"&#125;&#125;,"template":&#123;"metadata":&#123;"annotations":&#123;"cluster-autoscaler.kubernetes.io/safe-to-evict":"true"&#125;,"labels":&#123;"app":"controller","serving.knative.dev/release":"v0.17.0"&#125;&#125;,"spec":&#123;"affinity":&#123;"podAntiAffinity":&#123;"preferredDuringSchedulingIgnoredDuringExecution":[&#123;"podAffinityTerm":&#123;"labelSelector":&#123;"matchLabels":&#123;"app":"controller"&#125;&#125;,"topologyKey":"kubernetes.io/hostname"&#125;,"weight":100&#125;]&#125;&#125;,"containers":[&#123;"env":[&#123;"name":"SYSTEM_NAMESPACE","valueFrom":&#123;"fieldRef":&#123;"fieldPath":"metadata.namespace"&#125;&#125;&#125;,&#123;"name":"CONFIG_LOGGING_NAME","value":"config-logging"&#125;,&#123;"name":"CONFIG_OBSERVABILITY_NAME","value":"config-observability"&#125;,&#123;"name":"METRICS_DOMAIN","value":"knative.dev/internal/serving"&#125;],"image":"gcr.io/knative-releases/knative.dev/serving/cmd/controller@sha256:5f118d434661a895096c69c036de20c962aee445e339cc9e1b1bf806895d6fa2","name":"controller","ports":[&#123;"containerPort":9090,"name":"metrics"&#125;,&#123;"containerPort":8008,"name":"profiling"&#125;],"resources":&#123;"limits":&#123;"cpu":"1000m","memory":"1000Mi"&#125;,"requests":&#123;"cpu":"100m","memory":"100Mi"&#125;&#125;,"securityContext":&#123;"allowPrivilegeEscalation":false&#125;&#125;],"serviceAccountName":"controller"&#125;&#125;&#125;&#125; creationTimestamp: "2020-08-25T06:46:50Z" generation: 2 labels: serving.knative.dev/release: v0.17.0 name: controller namespace: knative-serving resourceVersion: "22294426" selfLink: /apis/extensions/v1beta1/namespaces/knative-serving/deployments/controller uid: bd1f8881-ccc8-42cc-847d-2d584dce8fd2 spec: progressDeadlineSeconds: 600 replicas: 1 revisionHistoryLimit: 10 selector: matchLabels: app: controller strategy: rollingUpdate: maxSurge: 25% maxUnavailable: 25% type: RollingUpdate template: metadata: annotations: cluster-autoscaler.kubernetes.io/safe-to-evict: "true" creationTimestamp: null labels: app: controller serving.knative.dev/release: v0.17.0 spec: affinity: podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - podAffinityTerm: labelSelector: matchLabels: app: controller topologyKey: kubernetes.io/hostname weight: 100 containers: - env: - name: SYSTEM_NAMESPACE valueFrom: fieldRef: apiVersion: v1 fieldPath: metadata.namespace - name: CONFIG_LOGGING_NAME value: config-logging - name: CONFIG_OBSERVABILITY_NAME value: config-observability - name: METRICS_DOMAIN value: knative.dev/internal/serving image: registry.cn-shenzhen.aliyuncs.com/shikanon/knative-releases.knative.dev.serving.cmd.controller:v0.17.0 imagePullPolicy: IfNotPresent name: controller ports: - containerPort: 9090 name: metrics protocol: TCP - containerPort: 8008 name: profiling protocol: TCP resources: limits: cpu: "1" memory: 1000Mi requests: cpu: 100m memory: 100Mi securityContext: allowPrivilegeEscalation: false terminationMessagePath: /dev/termination-log terminationMessagePolicy: File dnsPolicy: ClusterFirst restartPolicy: Always schedulerName: default-scheduler securityContext: &#123;&#125; serviceAccount: controller serviceAccountName: controller terminationGracePeriodSeconds: 30 status: availableReplicas: 1 conditions: - lastTransitionTime: "2020-08-25T07:26:55Z" lastUpdateTime: "2020-08-25T07:26:55Z" message: Deployment has minimum availability. reason: MinimumReplicasAvailable status: "True" type: Available - lastTransitionTime: "2020-08-25T07:26:49Z" lastUpdateTime: "2020-08-25T07:26:55Z" message: ReplicaSet "controller-5589c698d6" has successfully progressed. reason: NewReplicaSetAvailable status: "True" type: Progressing observedGeneration: 2 readyReplicas: 1 replicas: 1 updatedReplicas: 1- apiVersion: extensions/v1beta1 kind: Deployment metadata: annotations: deployment.kubernetes.io/revision: "2" kubectl.kubernetes.io/last-applied-configuration: | &#123;"apiVersion":"apps/v1","kind":"Deployment","metadata":&#123;"annotations":&#123;&#125;,"labels":&#123;"serving.knative.dev/release":"v0.17.0"&#125;,"name":"webhook","namespace":"knative-serving"&#125;,"spec":&#123;"selector":&#123;"matchLabels":&#123;"app":"webhook","role":"webhook"&#125;&#125;,"template":&#123;"metadata":&#123;"annotations":&#123;"cluster-autoscaler.kubernetes.io/safe-to-evict":"false"&#125;,"labels":&#123;"app":"webhook","role":"webhook","serving.knative.dev/release":"v0.17.0"&#125;&#125;,"spec":&#123;"affinity":&#123;"podAntiAffinity":&#123;"preferredDuringSchedulingIgnoredDuringExecution":[&#123;"podAffinityTerm":&#123;"labelSelector":&#123;"matchLabels":&#123;"app":"webhook"&#125;&#125;,"topologyKey":"kubernetes.io/hostname"&#125;,"weight":100&#125;]&#125;&#125;,"containers":[&#123;"env":[&#123;"name":"SYSTEM_NAMESPACE","valueFrom":&#123;"fieldRef":&#123;"fieldPath":"metadata.namespace"&#125;&#125;&#125;,&#123;"name":"CONFIG_LOGGING_NAME","value":"config-logging"&#125;,&#123;"name":"CONFIG_OBSERVABILITY_NAME","value":"config-observability"&#125;,&#123;"name":"WEBHOOK_PORT","value":"8443"&#125;,&#123;"name":"METRICS_DOMAIN","value":"knative.dev/serving"&#125;],"image":"gcr.io/knative-releases/knative.dev/serving/cmd/webhook@sha256:d36f460aea55b93cce222bcee129776dee356e6499db73f232bfdf482ce28f66","livenessProbe":&#123;"httpGet":&#123;"httpHeaders":[&#123;"name":"k-kubelet-probe","value":"webhook"&#125;],"port":8443,"scheme":"HTTPS"&#125;,"periodSeconds":1&#125;,"name":"webhook","ports":[&#123;"containerPort":9090,"name":"metrics"&#125;,&#123;"containerPort":8008,"name":"profiling"&#125;,&#123;"containerPort":8443,"name":"https-webhook"&#125;],"readinessProbe":&#123;"httpGet":&#123;"httpHeaders":[&#123;"name":"k-kubelet-probe","value":"webhook"&#125;],"port":8443,"scheme":"HTTPS"&#125;,"periodSeconds":1&#125;,"resources":&#123;"limits":&#123;"cpu":"500m","memory":"500Mi"&#125;,"requests":&#123;"cpu":"100m","memory":"100Mi"&#125;&#125;,"securityContext":&#123;"allowPrivilegeEscalation":false&#125;&#125;],"serviceAccountName":"controller","terminationGracePeriodSeconds":300&#125;&#125;&#125;&#125; creationTimestamp: "2020-08-25T06:46:51Z" generation: 2 labels: serving.knative.dev/release: v0.17.0 name: webhook namespace: knative-serving resourceVersion: "22294932" selfLink: /apis/extensions/v1beta1/namespaces/knative-serving/deployments/webhook uid: d17a6b43-259b-4367-be4e-0e51bcd4119f spec: progressDeadlineSeconds: 600 replicas: 1 revisionHistoryLimit: 10 selector: matchLabels: app: webhook role: webhook strategy: rollingUpdate: maxSurge: 25% maxUnavailable: 25% type: RollingUpdate template: metadata: annotations: cluster-autoscaler.kubernetes.io/safe-to-evict: "false" creationTimestamp: null labels: app: webhook role: webhook serving.knative.dev/release: v0.17.0 spec: affinity: podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - podAffinityTerm: labelSelector: matchLabels: app: webhook topologyKey: kubernetes.io/hostname weight: 100 containers: - env: - name: SYSTEM_NAMESPACE valueFrom: fieldRef: apiVersion: v1 fieldPath: metadata.namespace - name: CONFIG_LOGGING_NAME value: config-logging - name: CONFIG_OBSERVABILITY_NAME value: config-observability - name: WEBHOOK_PORT value: "8443" - name: METRICS_DOMAIN value: knative.dev/serving image: registry.cn-shenzhen.aliyuncs.com/shikanon/knative-releases.knative.dev.serving.cmd.webhook:v0.17.0 imagePullPolicy: IfNotPresent livenessProbe: failureThreshold: 3 httpGet: httpHeaders: - name: k-kubelet-probe value: webhook path: / port: 8443 scheme: HTTPS periodSeconds: 1 successThreshold: 1 timeoutSeconds: 1 name: webhook ports: - containerPort: 9090 name: metrics protocol: TCP - containerPort: 8008 name: profiling protocol: TCP - containerPort: 8443 name: https-webhook protocol: TCP readinessProbe: failureThreshold: 3 httpGet: httpHeaders: - name: k-kubelet-probe value: webhook path: / port: 8443 scheme: HTTPS periodSeconds: 1 successThreshold: 1 timeoutSeconds: 1 resources: limits: cpu: 500m memory: 500Mi requests: cpu: 100m memory: 100Mi securityContext: allowPrivilegeEscalation: false terminationMessagePath: /dev/termination-log terminationMessagePolicy: File dnsPolicy: ClusterFirst restartPolicy: Always schedulerName: default-scheduler securityContext: &#123;&#125; serviceAccount: controller serviceAccountName: controller terminationGracePeriodSeconds: 300 status: availableReplicas: 1 conditions: - lastTransitionTime: "2020-08-25T07:27:02Z" lastUpdateTime: "2020-08-25T07:27:02Z" message: Deployment has minimum availability. reason: MinimumReplicasAvailable status: "True" type: Available - lastTransitionTime: "2020-08-25T07:26:49Z" lastUpdateTime: "2020-08-25T07:27:02Z" message: ReplicaSet "webhook-785cf47bd5" has successfully progressed. reason: NewReplicaSetAvailable status: "True" type: Progressing observedGeneration: 2 readyReplicas: 1 replicas: 1 updatedReplicas: 1kind: Listmetadata: &#123;&#125; 选择网络层安装这里我们选择Kong作为网关，安装kong ingress controller：kubectl apply --filename https://raw.githubusercontent.com/Kong/kubernetes-ingress-controller/0.9.x/deploy/single/all-in-one-dbless.yaml 配置knative serving 使用 Kong:kubectl patch configmap/config-network \ --namespace knative-serving \ --type merge \ --patch '&#123;"data":&#123;"ingress.class":"kong"&#125;&#125;' 配置DNSkubectl patch configmap/config-domain \ --namespace knative-serving \ --type merge \ --patch '&#123;"data":&#123;"knative.realibcloud.cn":""&#125;&#125;']]></content>
      <categories>
        <category>技术博文</category>
        <category>容器技术</category>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>云原生</tag>
        <tag>无服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s集群备份迁移工具velero]]></title>
    <url>%2F2020%2F%E8%BF%90%E7%BB%B4%2Fk8s%E9%9B%86%E7%BE%A4%E5%A4%87%E4%BB%BD%E8%BF%81%E7%A7%BB%2F</url>
    <content type="text"><![CDATA[Velero工具简介最近刚刚把公司生产环境、预发环境、测试环境和研发环境做了K8s，运维这块需要实现集群应用备份和迁移功能，发现vmware开源的velero对于kubernetes应用以及持久化数据卷备份以及迁移是个不错的选择。 Velero安装Velero分为服务端和客户端两个部分。 服务端安装服务端使用的是velero-plugin，velero-plugin的存储有很多选择，官方给了像velero-plugin-for-aws,velero-plugin-for-gcp,velero-plugin-for-microsoft-azure等多种形式，因为公司主要用阿里云，所以选阿里云团队开发的velero-plugin: 1、在阿里云OSS创建一个BUCKET： 2、设置环境变量，将环境变量赋值到01-velero.yaml文件： export BUCKET=k8s-velero-backup #这里是创建的BUCKET地址export REGION=cn-shenzhen #这里是你的OSS endpoint地址sed -i "s#&lt;BUCKET&gt;#$BUCKET#" install/01-velero.yamlsed -i "s#&lt;REGION&gt;#$REGION#" install/01-velero.yaml 3、创建一个阿里云的RAM用户，赋予权限： &#123; "Version": "1", "Statement": [ &#123; "Action": [ "ecs:DescribeSnapshots", "ecs:CreateSnapshot", "ecs:DeleteSnapshot", "ecs:DescribeDisks", "ecs:CreateDisk", "ecs:Addtags", "oss:PutObject", "oss:GetObject", "oss:DeleteObject", "oss:GetBucket", "oss:ListObjects" ], "Resource": [ "*" ], "Effect": "Allow" &#125; ]&#125; 4、将install/credentials-velero文件的密钥修改为： ALIBABA_CLOUD_ACCESS_KEY_ID=&lt;你的ALIBABA_CLOUD_ACCESS_KEY_ID&gt;ALIBABA_CLOUD_ACCESS_KEY_SECRET=&lt;你的ALIBABA_CLOUD_ACCESS_KEY_SECRET&gt; 5、创建velero的相关资源和应用： kubectl create namespace velerokubectl create secret generic cloud-credentials --namespace velero --from-file cloud=install/credentials-velerokubectl apply -f install/00-crds.yamlkubectl apply -f install/01-velero.yaml okay，完成了 注：在切换多个集群的时候，出现You must be logged in to the server(unauthorized)，是证书错误，有可能是集群名称一样导致用了另一个集群的证书导致，这个错误还是挺常见的。 客户端安装客户端使用很简单，因为官方直接提供了二进制文件，直接下载解压即可： 1、下载阿里云 verlero-plugin 2、解压：tar -xvf &lt;RELEASE-TARBALL-NAME&gt;.tar.gz -C /dir/to/extract/to 使用备份应用：./velero backup create &lt;备份名称&gt; --include-namespaces &lt;备份的命名空间&gt; 完成备份： 恢复应用：./velero restore create --from-backup &lt;备份名称&gt; 数据卷的备份：./velero backup create &lt;备份名称&gt; --snapshot-volumes --include-namespaces &lt;备份的命名空间&gt; 数据卷的恢复：./velero restore create --from-backup &lt;备份名称&gt; --restore-volumes]]></content>
      <categories>
        <category>技术博文</category>
        <category>容器技术</category>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>velero</tag>
        <tag>集群运维</tag>
        <tag>备份</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于kubeconfig多集群切换]]></title>
    <url>%2F2020%2F%E8%BF%90%E7%BB%B4%2F%E5%85%B3%E4%BA%8Ekubeconfig%E5%A4%9A%E9%9B%86%E7%BE%A4%E5%88%87%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[多集群的切换是K8s运维中比不可少的问题，常见的基于多个集群进行切换的方法有三种： 切换config文件 通过context进行集群切换 用kubectl-plugins进行集群切换 切换config文件我们先看看放在.kube下默认的config集群：$ kubectl config viewapiVersion: v1clusters:- cluster: certificate-authority-data: DATA+OMITTED server: name: kubernetescontexts:- context: cluster: kubernetes user: "212785087522004927" name: 212785087522004927-c02e82b6adaf044bd94d251fea1279648current-context: 212785087522004927-c02e82b6adaf044bd94d251fea1279648kind: Configpreferences: &#123;&#125;users:- name: "212785087522004927" user: client-certificate-data: client-key-data: 通过export更改默认集群配置：$ export KUBECONFIG=$HOME/.kube/rancher-config 查看：$ kubectl config viewapiVersion: v1clusters:- cluster: certificate-authority-data: DATA+OMITTED server: name: stagecontexts:- context: cluster: stage user: stage name: stagecurrent-context: stagekind: Configpreferences: &#123;&#125;users:- name: stage user: token: 这种方法就是特别麻烦，每次切换都要通过export设置，非常麻烦，同时也不方便。 通过context进行集群切换把要切换的所有config文件添加到KUBECONFIG环境变量中$ export KUBECONFIG=$HOME/.kube/config:$HOME/.kube/rancher-config 或者可以将命令直接写到.bashrc文件中，这样就不需要每次手动设置。 通过kubectl config view可以看到这两个文件已经合并到一起了： $ kubectl config viewapiVersion: v1clusters:- cluster: certificate-authority-data: DATA+OMITTED server: name: kubernetes- cluster: certificate-authority-data: DATA+OMITTED server: name: stagecontexts:- context: cluster: kubernetes user: "212785087522004927" name: 212785087522004927-c02e82b6adaf044bd94d251fea1279648- context: cluster: stage user: stage name: stagecurrent-context: 212785087522004927-c02e82b6adaf044bd94d251fea1279648kind: Configpreferences: &#123;&#125;users:- name: "212785087522004927" user: client-certificate-data: client-key-data: - name: stage user: token: 合并一起后就可以通过use-context切换上下文来切换集群：# 切换stage集群$ kubectl config use-context stageSwitched to context "stage". 切换到第二个集群：$ kubectl config use-context 212785087522004927-c02e82b6adaf044bd94d251fea1279648Switched to context "212785087522004927-c02e82b6adaf044bd94d251fea1279648". 但这种方法不方便的地方就在如果context很多的时候，不方便查看。 通过kubectl-plugins切换集群针对不方便查看我们可以永kubectl-plugins来解决。kubectl-plugins 是一个对kubectl的增强插件。 kubectl-glugins安装:git clone https://github.com/jordanwilson230/kubectl-plugins.gitcd kubectl-plugins./install-plugins.shsource ~/.bash_profile 通过switch cluster切换集群：$ kubectl switch cluster stageCURRENT NAME CLUSTER AUTHINFO NAMESPACE 212785087522004927-c02e82b6adaf044bd94d251fea1279648 kubernetes 212785087522004927 stage* stage stage stage]]></content>
      <categories>
        <category>技术博文</category>
        <category>容器技术</category>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>多集群</tag>
        <tag>config</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于云原生系统的应用分发系统设计]]></title>
    <url>%2F2020%2F%E6%9E%B6%E6%9E%84%2F%E5%9F%BA%E4%BA%8E%E4%BA%91%E5%8E%9F%E7%94%9F%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%BA%94%E7%94%A8%E5%88%86%E5%8F%91%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[1、应用分发是什么架构 将我们现有的所有应用都拆分成一个个基于hub之上的应用服务，对于需要私有化的用户可以提供一个分发客户端，通过部署客户端进行私有化部署。对于不需要私有化的用户，可以直接通过云端访问上面的服务。（可以理解我们在云端也部署了一个client controller） 如果用户想安装应用，只需要在客户端界面点击安装，即可从云端hub中心分发到本地集群，完成自动安装。 2、核心价值 功能模式：构建一套以云原生系统为核心的3D数字化应用系统，可以满足用户对私有化环境下的应用分发需求 用户体验：通过应用分发的模式让客户更简单、高效地购买和安装应用 商业价值：拓宽了应用分发形式和渠道，可以更多样化地形式进行商业变现 3、用户界面 命令行工具(CLI)，client controller 提供命令行安装部署。 GUI dashboard，client controller 同时提供了前端的可视化界面进行安装部署操作。 4、关键问题Hub应用分发模式落地需要解决关键问题是什么？ 需要解决的关键问题是应用构建分发标准和3D统一场景描述格式。 4.1、应用构建分发标准（1）应用构建、分发流程 @startumlparticipant &quot;client controller&quot;participant &quot;hub center&quot;participant &quot;cloud app&quot;&quot;cloud app&quot; -&gt; &quot;hub center&quot;: cloud app注册&quot;client controller&quot; -&gt; &quot;hub center&quot;: 发起cloud app列表请求&quot;hub center&quot; -&gt; &quot;client controller&quot;: 返回cloud app信息&quot;client controller&quot; -&gt; &quot;hub center&quot;: 发起安装依赖请求&quot;hub center&quot; -&gt; &quot;client controller&quot;: 返回cloud app安装依赖&quot;client controller&quot; -&gt; &quot;client controller&quot;: 检测环境依赖&quot;client controller&quot; -&gt; &quot;hub center&quot;: 发起下载请求&quot;hub center&quot; -&gt; &quot;client controller&quot;: 下载cloud app(Pull操作)&quot;client controller&quot; -&gt; &quot;client controller&quot;: cloud app自动构建/运行@enduml （2）落地路径 首先需要对现有的应用进行切分，让每个应用作为一个独立的系统，相互之间的调用只能走http协议； 其次需要确定应用构建流程细节设计，包括应用之间具备依赖关系设计、应用自动化构建和测试等； 明确应用分发流程细节设计，在落地过程种应用分发是最核心也最复杂的一块，这一块需要做的事情包括分发协议设计、复杂环境的应用自动化安装部署检测流程； 4.2、3D统一场景描述格式构建统一的场景描述格式供多种3D应用进行数据交换和使用。数据格式要求：轻量的、可扩展的、能充分描述3D场景的3D格式。]]></content>
      <categories>
        <category>技术博文</category>
        <category>容器技术</category>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>云原生</tag>
        <tag>架构设计</tag>
        <tag>应用分发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[代码版本管理规范]]></title>
    <url>%2F2020%2F%E7%AE%A1%E7%90%86%2F%E4%BB%A3%E7%A0%81%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[代码版本管理规范项目代码release包括三类： 大版本(x.0.0) 小版本(x.x.0) 补丁(x.x.x) 版本管理git 流程模式有两种：一种是Git flow工作流，一种是Github flow工作流。 Git Flow 分支模型 @startumlactor &quot;person-repo&quot;participant &quot;feature&quot;participant &quot;develop&quot;participant &quot;release-x.x&quot;participant &quot;hotfix&quot;participant &quot;master&quot;control &quot;预发布环境&quot;control &quot;生产环境&quot;master -&gt; develop: checkoutdevelop -&gt; &quot;person-repo&quot;: pull&quot;person-repo&quot; -&gt; &quot;person-repo&quot;: commit&quot;person-repo&quot; -&gt; develop: merge requestsdevelop -&gt; feature: checkout（功能开发）feature -&gt; &quot;person-repo&quot;: pull&quot;person-repo&quot; -&gt; &quot;person-repo&quot;: commit&quot;person-repo&quot; -&gt; feature: merge requestsfeature -&gt; develop: mergedevelop -&gt; &quot;release-x.x&quot;: checkout（版本发布）&quot;release-x.x&quot; -&gt; &quot;person-repo&quot;: pull&quot;person-repo&quot; -&gt; &quot;person-repo&quot;: fix bug&quot;person-repo&quot; -&gt; &quot;release-x.x&quot;: merge requests&quot;release-x.x&quot; --&gt; &quot;预发布环境&quot;: 测试&quot;release-x.x&quot; -&gt; master: mergemaster --&gt; &quot;生产环境&quot;: 部署测试&quot;release-x.x&quot; -&gt; develop: mergemaster -&gt; &quot;hotfix&quot;: checkout（线上bug紧急修复）&quot;hotfix&quot; -&gt; &quot;person-repo&quot;: pull&quot;person-repo&quot; -&gt; &quot;person-repo&quot;: fix bug&quot;person-repo&quot; -&gt; &quot;hotfix&quot;: merge requests&quot;hotfix&quot; -&gt; master: mergemaster --&gt; &quot;预发布环境&quot;: 测试master --&gt; &quot;生产环境&quot;: 部署发布&quot;hotfix&quot; -&gt; develop: merge@enduml 步骤 master分支不做代码提交，master为生产环境运行代码 开发主要在develop分支上进行提交 功能开发切换一个新的功能分支上，功能分支完成后需合并到develop分支 用release分支做版本发布，release用于预发布环境测试 release分支从开发分支切出来，完成后需要合并到master分支和develop分支 预发布环境测试无误后，release分支合并到master分支，发布到生产环境测试 生产环境测试完成后release分支可以删除 生产环境运行中紧急修复采用hotfix分支，hotfix分支从mater分支切出 hotfix分支修复后需合并会master分支和develop分支 功能开发创建功能分支# 从develop创建功能分支$ git checkout -b myfeature develop 完成功能分支，合并develop，并推送到远程仓库# 切换到develop分支$ git checkout develop# develop分支合并功能分支$ git merge --no-ff myfeature# 删除功能分支$ git branch -d myfeature# 推到远程仓库$ git push origin develop 版本发布版本发布前，创建版本分支# 从develop分支切到版本发布分支$ git checkout -b release-1.2 develop 完成版本测试后，合并到master分支上# 切换到master$ git checkout master# master合并release分支$ git merge --no-ff release-1.2# 给master分支打tag$ git tag -a 1.2 生产环境测试没有问题后，将release分支合并会develop分支，并删除release分支# 切换到develop分支$ git checkout develop# develop分支合并release分支$ git merge --no-ff release-1.2# 删除release分支$ git branch -d release-1.2 临时补丁生产环境上发现bug，直接通过hotfix快速修复:# 从master切出一条分支，紧急修复问题$ git checkout -b hotfix-1.2 master 完成问题修复后，合并进master：# 切到master分支$ git checkout master# master分支合并hotfix分支$ git merge --no-ff hotfix-1.2# 打上新tag$ git tag -a 1.2# 切换到develop分支 如果当前release分支还未删除，合并到release分支，再由release分支合并到develop分支:$ git checkout release-1.2# release-1.2合并hotfix分支$ git merge --no-ff hotfix-1.2# 删除hotfix分支$ git branch -d hotfix-1.2# 切换到develop分支$ git checkout develop# develop分支合并release分支$ git merge --no-ff release-1.2 如果release分支已删除，则直接合并到develop分支：# 切换到develop分支$ git checkout develop# develop分支合并release分支$ git merge --no-ff hotfix-1.2# 删除hotfix分支$ git branch -d hotfix-1.2 原则 开发永远不直接提交到master分支，master保留用于发布到生产中的代码 尽量一个任务，一个功能分支 在合并到开发分支前，对每个merge requests测试 新功能只添加到develop分支 优缺点优点： 流程清晰，覆盖面全，通过分支模型将工作流串通 git flow作为最早提出的分支模型，也是最广泛使用的分支模型，受众广泛 以master作为生产分支，面向单版本的线上产品迭代 缺点： 分支十分复杂，敏捷性较差 仅master分支上做持续集成，而大部分工具默认将master分支设为默认分支，因此经常面临分支切换，导致很繁琐 修补分支和发布分支设置繁琐，比如每次使用修补分支都需要同时合并到master和develop分支，但开发经常犯错误，比如忘记合并回develop分支 Github Flow 分支模型面对git flow的繁琐，github flow分支模型仅具有功能分支和主分支，将所有内容合并到master分支中并进行部署，采用pull request方式进行代码合并，强调持续集成和连续交付。 优点： 流程十分简单，可以满足敏捷交付 不需要频繁切换分支，在自己的仓库进行开发，统一合并master 每次提交均需要测试 缺点： 对自动化测试要求较高，需要大量的单元测、端到端测试和集成测试 模型过于简单，对于部署、发版和集成上存在着大量问题 Gitlab Flow 分支模型结合了git flow分支模型和github flow分支模型： @startumlactor &quot;person-repo&quot;participant &quot;master&quot;participant &quot;release-x.x.x-alpha&quot;participant &quot;release-x.x.x&quot;control &quot;stage预发布环境&quot;control &quot;pre-production&quot;control &quot;生产环境&quot;master -&gt; &quot;person-repo&quot;: fork&quot;person-repo&quot; -&gt; &quot;person-repo&quot;: commit&quot;person-repo&quot; -&gt; master: merge requestsmaster -&gt; &quot;stage预发布环境&quot;: 自动化测试CI&quot;stage预发布环境&quot; -&gt; master: 测试通过+code reviewmaster -&gt; &quot;release-x.x.x-alpha&quot;: cherryPick&quot;release-x.x.x-alpha&quot; -&gt; &quot;pre-production&quot;: 部署&quot;pre-production&quot; -&gt; &quot;pre-production&quot;: 测试&quot;pre-production&quot; --&gt; &quot;release-x.x.x-alpha&quot;: 测试不通过&quot;release-x.x.x-alpha&quot; -&gt; &quot;person-repo&quot;: pull&quot;person-repo&quot; -&gt; &quot;person-repo&quot;: fix bug&quot;person-repo&quot; -&gt; &quot;release-x.x.x-alpha&quot;: merge requests&quot;release-x.x.x-alpha&quot; -&gt; &quot;pre-production&quot;: 部署&quot;pre-production&quot; -&gt; &quot;pre-production&quot;: 测试&quot;pre-production&quot; --&gt; &quot;release-x.x.x-alpha&quot;: 测试通过&quot;release-x.x.x-alpha&quot; -&gt; &quot;release-x.x.x&quot;: checkout -b&quot;release-x.x.x&quot; -x &quot;release-x.x.x-alpha&quot;: 删除分支alpha分支&quot;release-x.x.x&quot; -&gt; &quot;生产环境&quot;: 部署&quot;生产环境&quot; --&gt; &quot;生产环境&quot;: 测试&quot;生产环境&quot; --&gt; &quot;release-x.x.x&quot;: 测试通过&quot;release-x.x.x&quot; -&gt; master: cherryPick@enduml 需要一个staging环境和pre-production环境（两个生产环境镜像） 所有请求直接提交到master分支，每次提交都做持续集成和测试，主要是自动化测试 部署发布的时候，从master中摘取(cherry Pick)核心发布功能到”release-x.x.x-alpha”分支进行测试，并在其上进行修复 测试通过后，切换到”release-x.x.x”分支并删除”release-x.x.x-alpha”分支，将”release-x.x.x”分支发布到生产环境中进行测试 生产环境测试通过后，将”release-x.x.x”合并回master 要使用好cherry-pick，每个提交要清晰简洁 优缺点优点： 相比git flow分支模型更简单，减少了分支数量 和github flow分支模型一样，更强调测试，对所有提交都需进行测试或code review 缺点： 需要自动化测试流程支撑，需要有较好的持续集成和连续交付基础 参考资料原git工作流程 https://wiki.corp.realibox.com/pages/viewpage.action?pageId=20414517gitlab分支介绍 https://forge.etsi.org/rep/help/workflow/gitlab_flow.md]]></content>
      <categories>
        <category>管理</category>
        <category>技术管理</category>
      </categories>
      <tags>
        <tag>代码版本管理</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里云《云原生架构白皮书》解读：云计算的最佳演进路径]]></title>
    <url>%2F2020%2F%E6%9E%B6%E6%9E%84%2F%E9%98%BF%E9%87%8C%E4%BA%91%E3%80%8A%E4%BA%91%E5%8E%9F%E7%94%9F%E6%9E%B6%E6%9E%84%E7%99%BD%E7%9A%AE%E4%B9%A6%E3%80%8B%2F</url>
    <content type="text"><![CDATA[“云原生”已成为一个成为技术圈广泛传播的流行词了。那么什么是云原生？云原生能给我们带来什么？怎么将云原生架构落地？应该是每个关心云计算新技术的技术人都关心的吧，我也不例外，当在群里得知阿里云要出品《云原生架构白皮书》时，第一时间就预约了试读。PS：做个小广告，如果你也想拥有这样的“特权”，可以加入阿里云MVP😜 7月17号就收到第一部分内容，看了编委组成员，满满的大神列表。从结构来看“白皮书”总共分为七章，主要从云原生的架构定义和相关技术栈、阿里云自身的产品和案例实践、未来发展趋势三大部分全面介绍了云原生架构。 从架构设计看云原生的价值核心云原生的概念很多，之前我写过一篇关于《什么是云原生》的博客里面就有说到云原生的各种定义。“白皮书”则从架构和设计模式上对云原生做描述：旨在将云应用中的非业务代码部分进行最大化的剥离，从而让云设施接管应用中原有的大量非功能特性（如弹性、韧性、安全、可观测性、灰度等），使业务不再有非功能性业务中断困扰的同时，具备轻量、敏捷、高度自动化的特点。 这种从架构和模式上的定义比CNCF和十二因素更清晰和具象化，也更清晰地体现云原生的价值核心：架构设计的指导和研发效能的提高。 架构设计主要体现在云原生架构提供了高可用和可扩展能力。非功能特性的建设在实际业务中并不会带来直接业务价值，但又是必不可少的。记得在10年微服务刚出来的时候，需要构建一个高可用和具备可扩展能力的系统是一件很困难的事情，缺乏服务注册中心，需要自行解决上下游寻址、通讯，以及容错等问题。现在这些能力被抽象成云原生的基础设施，我们可以专注于核心业务代码的同时，轻松获得高可用和可扩展能力。 云原生另一方面价值体现是在提高团队和组织的研发效能上。从敏捷交付到DevOps，本质上是对交付和运维效率的追求。自动化让研发变得更高效，非功能性特性和核心代码分离可以让我们更专注于核心业务逻辑。 微服务发展史第一代微服务需要自行解决上下游寻址、通讯，以及容错等问题；第二代微服务架构中，引入了旁路服务注册中心作为协调者来完成服务的自动注册和发现。服务之间的通讯以及容错机制开始模块化，形成独立服务框架。第三代微服务架构 - 服务网格，原来被模块化到服务框架里的微服务基础能力，被进一步的从一个 SDK 演进成为一个独立进程 - Sidecar。第四代多运行时微服务架构（Muti-Runtime Microservices）。 从4+1看阿里云云原生架构设计阿里巴巴云原生架构ACNA「4+1」的架构设计流程，「4」 代表架构设计的关键视角，包括企业战略视角、业务发展视角、组织能力视角和云原生技术架构视角；「1」 表示云原生架构的架构持续演进闭环。 企业战略视角来看，任何架构都必须服务于企业战略，云原生架构不仅是一个技术升级，更是一个对企业核心业务生产流程的重构，即通过软件开发和运营构建数字化业务。这样从顶层的战略上就需要设计技术赋能业务创新的重要角色。从业务发展视角看，数字化业务对技术架构的主要诉求是业务连续性、业务快速上线、成本以及科技赋能业务创新，云计算作为新的技术必须为企业释放成本红利，帮助企业从原来的 CAPEX 模式转变为 OPEX 模式。从组织能力视角看，最重要是需要理性看待技术架构，需要满足“康威定律”原则——让技术架构与企业沟通架构需要保持一致。从云原生技术视角来看，从服务化能力、弹性能力、无服务化程度、可观察性、韧性和自动化都需要逐步迭代，配合企业战略和业务诉求。 云原生架构的发展演变和新技术的展望云原生技术的发展经历了自行解决各种分布式问题的初代，到服务注册、服务发现、服务通讯及容错机制逐渐模块化的中生代，再到逐渐采用服务网格(service mesh)管理微服务架构的新生代，云原生架构对底层和分布式事务的抽象程度越来越高，让工程师们更专注核心业务，Serverless、混合云逐渐成为技术选型的新常态。随着云原生应用快速铺开，云原生生态逐渐操作系统化，类似 OAM 这种标准化云原生应用框架的完善未来会催生新一代应用分发云市场。一次开发，所有云厂商发布和使用，让技术服务化和商业赋能变得像手机APP安装使用一样简单顺畅，打通生态模式最后一环。 《云原生架构白皮书》下载地址]]></content>
      <categories>
        <category>技术博文</category>
        <category>容器技术</category>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>云原生</tag>
        <tag>阿里云</tag>
        <tag>解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于kubernetes的kong网关实战]]></title>
    <url>%2F2020%2F%E6%9E%B6%E6%9E%84%2F%E5%9F%BA%E4%BA%8Ekubernetes%E7%9A%84kong%E7%BD%91%E5%85%B3%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[Kong在k8s安装Kong-ingress安装Kong:# using YAMLs$ kubectl apply -f https://bit.ly/k4k8s# or using Helm$ helm repo add kong https://charts.konghq.com$ helm repo update# Helm 2$ helm install kong/kong# Helm 3$ helm install kong/kong --generate-name --set ingressController.installCRDs=false 部署一个应用部署一个应用： （1）构建一个deployment:apiVersion: apps/v1kind: Deploymentmetadata: name: app-server labels: name: app-serverspec: replicas: 1 selector: matchLabels: name: app-server template: metadata: labels: name: app-server spec: containers: - name: app-server image: registry.cn-shenzhen.aliyuncs.com/shikanon/ambassador-auth-demo:serverv0.1 imagePullPolicy: IfNotPresent ports: - containerPort: 8080 构建一个service:apiVersion: v1kind: Servicemetadata: name: app-serverspec: ports: - name: http port: 8000 protocol: TCP targetPort: 8080 selector: name: app-server 构建一个ingress:apiVersion: extensions/v1beta1kind: Ingressmetadata: name: demo annotations: kubernetes.io/ingress.class: "kong"spec: rules: - http: paths: - path: /open/ backend: serviceName: app-server servicePort: 8000 如果集群中存在多个 ingress controller，需要通过在annotations中指定kubernetes.io/ingress.class，如果是1.18及以上版本的k8s，ingressClassName字段代替annotations。 测试接口：$ curl -i http://$KongService_IP/open/HTTP/1.1 200 OKContent-Type: text/plain; charset=utf-8Content-Length: 6Connection: keep-aliveDate: Sun, 24 May 2020 10:49:07 GMTX-Kong-Upstream-Latency: 1X-Kong-Proxy-Latency: 0Via: kong/2.0.4/open/]]></content>
      <categories>
        <category>技术博文</category>
        <category>容器技术</category>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>云原生</tag>
        <tag>网关</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ambassador网关之小试牛刀]]></title>
    <url>%2F2020%2F%E6%9E%B6%E6%9E%84%2Fambassador%E7%BD%91%E5%85%B3%E4%B9%8B%E5%B0%8F%E8%AF%95%E7%89%9B%E5%88%80%2F</url>
    <content type="text"><![CDATA[AmbassadorAmbassador是一个云原生的API网关，主要用于为集群提供南-北网关，对外网流入的流量进行管理，包括限流、鉴权等。 今天这里用ambassador构建一个的鉴权服务。 这里有一个坑，待填… 安装k8s安装:kubectl apply -f https://www.getambassador.io/yaml/aes-crds.yaml &amp;&amp; \kubectl wait --for condition=established --timeout=180s crd -lproduct=aes &amp;&amp; \kubectl apply -f https://www.getambassador.io/yaml/aes.yaml &amp;&amp; \kubectl -n ambassador wait --for condition=available --timeout=180s deploy -lproduct=aes 其他安装方式参考安装手册。 测试安装好后，查看services:$ kubectl get svc -n ambassadorNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEambassador LoadBalancer 10.43.227.83 &lt;pending&gt; 80:31082/TCP,443:32114/TCP 4h4mambassador-admin ClusterIP 10.43.143.56 &lt;none&gt; 8877/TCP 4h4mambassador-redis ClusterIP 10.43.59.72 &lt;none&gt; 6379/TCP 4h4m 由于这里没有LB，再启一个node-port:apiVersion: v1kind: Servicemetadata: labels: app: ambassador-nodeport name: ambassador-nodeportspec: externalTrafficPolicy: Cluster ports: - name: "80" port: 80 protocol: TCP targetPort: http - name: "443" port: 443 protocol: TCP targetPort: https selector: service: ambassador sessionAffinity: None type: NodePort 直接访问机器的即可看到页面： 添加一个后端应用quote：---apiVersion: v1kind: Servicemetadata: name: quote namespace: ambassadorspec: ports: - name: http port: 80 protocol: TCP targetPort: http selector: app: quote---apiVersion: apps/v1kind: Deploymentmetadata: name: quote namespace: ambassadorspec: replicas: 1 selector: matchLabels: app: quote strategy: type: RollingUpdate template: metadata: labels: app: quote spec: containers: - name: backend image: registry.cn-shenzhen.aliyuncs.com/shikanon/ambassador-auth-demo:serverv0.1 ports: - name: http containerPort: 8080---apiVersion: getambassador.io/v2kind: Mappingmetadata: name: quote-backend namespace: ambassadorspec: prefix: /backend/ service: quote 注：这里Deployment的port用name名称叫”http”，所以service可以写成targetPort: http 测试 注意：由于这里用的是Ambassador Edge Stack版本，访问必须用https的端口： $ kubectl get svc -nambassadorNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEambassador LoadBalancer 10.43.86.4 80:32487/TCP,443:31632/TCP 4h9mambassador-admin ClusterIP 10.43.79.19 8877/TCP 4h9mambassador-nodeport NodePort 10.43.228.37 80:30930/TCP,443:32089/TCP 7m36sambassador-redis ClusterIP 10.43.191.197 6379/TCP 4h9mapp-auth NodePort 10.43.206.119 80:30176/TCP 27mapp-server ClusterIP 10.43.174.101 80/TCP 27mquote ClusterIP 10.43.55.41 80/TCP 7m2s 必须用https访问 $ curl https://10.43.86.4/backend/ –insecure 构建鉴权代码基于golang构建一个简单的鉴权服务：package mainimport ( "fmt" "net/http")func indexHandler(w http.ResponseWriter, r *http.Request) &#123; username := r.URL.Query().Get("username") passwd := r.URL.Query().Get("passwd") content := fmt.Sprintf("username:%v", username) if username == "shikanon" &amp;&amp; passwd == "123456" &#123; w.WriteHeader(200) &#125; else &#123; w.WriteHeader(403) &#125; fmt.Fprintf(w, content)&#125;func main() &#123; http.HandleFunc("/", indexHandler) http.ListenAndServe(":8000", nil)&#125; 构建一个简单的server服务：package mainimport ( "fmt" "net/http")func indexHandler(w http.ResponseWriter, r *http.Request) &#123; fmt.Fprintf(w, "this is server") fmt.Println("RequestURI", r.RequestURI)&#125;func lookHandler(w http.ResponseWriter, r *http.Request) &#123; fmt.Fprintf(w, r.RequestURI) fmt.Println("RequestURI", r.RequestURI)&#125;func main() &#123; http.HandleFunc("/", lookHandler) http.HandleFunc("/lookup", indexHandler) http.ListenAndServe(":8080", nil)&#125; 编写Dockerfile(两个服务的dockerfile类似):FROM golang:1.14.3-alpine as buildCOPY . /appWORKDIR /appRUN go build -o auth main.go RUN chmod +x ./authFROM alpine:latestLABEL maintainer="hexo-shikanon-blog &lt;shikanon@tensorbytes.com&gt;"COPY --from=build /app /appEXPOSE 8000CMD ["/app/auth"] 不想自己 build 可以直接用我上传到阿里云的镜像仓库： auth: registry.cn-shenzhen.aliyuncs.com/shikanon/ambassador-auth-demo:authv0.1 server: registry.cn-shenzhen.aliyuncs.com/shikanon/ambassador-auth-demo:serverv0.1 使用authservice服务构建server基于server镜像构建响应服务：---apiVersion: apps/v1kind: Deploymentmetadata: name: app-server namespace: ambassador labels: name: app-serverspec: replicas: 1 selector: matchLabels: name: app-server template: metadata: labels: name: app-server spec: containers: - name: app-server image: registry.cn-shenzhen.aliyuncs.com/shikanon/ambassador-auth-demo:serverv0.1 imagePullPolicy: IfNotPresent ports: - containerPort: 8080---apiVersion: v1kind: Servicemetadata: name: app-server namespace: ambassadorspec: ports: - name: http port: 80 protocol: TCP targetPort: 8080 selector: name: app-server 构建mapping实现ambassador转发：apiVersion: getambassador.io/v2kind: Mappingmetadata: name: auth-backend-test namespace: ambassadorspec: prefix: /test/ host_redirect: true service: app-server 测试一下： $ kubectl get svc -nambassadorNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEambassador LoadBalancer 10.43.47.77 80:31290/TCP,443:31952/TCP 12hambassador-admin ClusterIP 10.43.181.248 8877/TCP 12hambassador-redis ClusterIP 10.43.65.217 6379/TCP 12happ-server ClusterIP 10.43.56.227 80/TCP 26m 测试效果：$ curl -L http://10.43.47.77/test/helloworld --insecure* About to connect() to 10.43.47.77 port 80 (#0)* Trying 10.43.47.77...* Connected to 10.43.47.77 (10.43.47.77) port 80 (#0)&gt; GET /test2/helloworld HTTP/1.1&gt; User-Agent: curl/7.29.0&gt; Host: 10.43.47.77&gt; Accept: */*&gt; &lt; HTTP/1.1 301 Moved Permanently&lt; location: https://10.43.47.77/test/helloworld&lt; date: Fri, 22 May 2020 02:03:46 GMT&lt; server: envoy&lt; content-length: 0&lt; * Connection #0 to host 10.43.47.77 left intact* Issue another request to this URL: 'https://10.43.47.77/test2/helloworld'* Found bundle for host 10.43.47.77: 0x7fced0* About to connect() to 10.43.47.77 port 443 (#1)* Trying 10.43.47.77...* Connected to 10.43.47.77 (10.43.47.77) port 443 (#1)* Initializing NSS with certpath: sql:/etc/pki/nssdb* skipping SSL peer certificate verification* SSL connection using TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256* Server certificate:* subject: O=Ambassador Edge Stack Self-Signed* start date: May 21 13:32:32 2020 GMT* expire date: May 21 13:32:32 2021 GMT* common name: (nil)* issuer: O=Ambassador Edge Stack Self-Signed&gt; GET /test2/helloworld HTTP/1.1&gt; User-Agent: curl/7.29.0&gt; Host: 10.43.47.77&gt; Accept: */*&gt; &lt; HTTP/1.1 200 OK&lt; date: Fri, 22 May 2020 02:03:46 GMT&lt; content-length: 11&lt; content-type: text/plain; charset=utf-8&lt; x-envoy-upstream-service-time: 0&lt; server: envoy&lt; * Connection #1 to host 10.43.47.77 left intact/helloworld 如果用http协议，这里必须加-L，因为ambassador会强制转成https协议，并返回301进行重定向。 构建authservice构建好server，下面就可以构建authservice做鉴权验证和转发： apiVersion: apps/v1kind: Deploymentmetadata: name: app-auth namespace: ambassador labels: name: app-authspec: replicas: 1 selector: matchLabels: name: app-auth template: metadata: labels: name: app-auth spec: containers: - name: app-auth image: registry.cn-shenzhen.aliyuncs.com/shikanon/ambassador-auth-demo:authv0.1 imagePullPolicy: IfNotPresent ports: - containerPort: 8000---apiVersion: v1kind: Servicemetadata: name: app-auth namespace: ambassador annotations: getambassador.io/config: | --- apiVersion: getambassador.io/v2 kind: AuthService name: authentication auth_service: "app-auth:80" path_prefix: "/extauth" allowed_request_headers: - "x-qotm-session" allowed_authorization_headers: - "x-qotm-session"spec: ports: - name: http port: 80 protocol: TCP targetPort: 8000 selector: name: app-auth type: NodePort 这里设置了对extauth的前缀做验证转发，也就是会匹配包含/extauth的url，传给验证服务，验证通过了才转到应用服务。 需注意，在新版的Ambassador Edge Stack中，官方更推荐采用filter进行鉴权和过滤逻辑 apiVersion: v1kind: Servicemetadata: name: app-auth namespace: ambassadorspec: ports: - name: http port: 80 protocol: TCP targetPort: 8000 selector: name: app-auth type: NodePort---apiVersion: getambassador.io/v2kind: Filtermetadata: name: app-auth namespace: ambassadorspec: External: auth_service: "app-auth:80" # required proto: "http" # optional; default is "http" path_prefix: "/extauth" okay，下面开始测试。 先查看service地址： $ kubectl get svc -nambassadorNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEambassador LoadBalancer 10.43.47.77 80:31290/TCP,443:31952/TCP 12hambassador-admin ClusterIP 10.43.181.248 8877/TCP 12hambassador-redis ClusterIP 10.43.65.217 6379/TCP 12happ-auth NodePort 10.43.179.149 80:32711/TCP 12happ-server ClusterIP 10.43.56.227 80/TCP 26m 测试：$ curl -Lv https://10.43.47.77/extauth/test/helloworld --insecure* About to connect() to 10.43.47.77 port 443 (#0)* Trying 10.43.47.77...* Connected to 10.43.47.77 (10.43.47.77) port 443 (#0)* Initializing NSS with certpath: sql:/etc/pki/nssdb* skipping SSL peer certificate verification* SSL connection using TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256* Server certificate:* subject: O=Ambassador Edge Stack Self-Signed* start date: May 21 13:32:32 2020 GMT* expire date: May 21 13:32:32 2021 GMT* common name: (nil)* issuer: O=Ambassador Edge Stack Self-Signed&gt; GET /extauth/test/helloworld HTTP/1.1&gt; User-Agent: curl/7.29.0&gt; Host: 10.43.47.77&gt; Accept: */*&gt; &lt; HTTP/1.1 301 Moved Permanently&lt; content-type: text/html; charset=utf-8&lt; location: /test/helloworld&lt; date: Fri, 22 May 2020 02:31:35 GMT&lt; content-length: 52&lt; x-envoy-upstream-service-time: 0&lt; server: envoy&lt; * Ignoring the response-body* Connection #0 to host 10.43.47.77 left intact* Issue another request to this URL: 'https://10.43.47.77/test2/helloworld'* Found bundle for host 10.43.47.77: 0x1c73f20* Re-using existing connection! (#0) with host 10.43.47.77* Connected to 10.43.47.77 (10.43.47.77) port 443 (#0)&gt; GET /test2/helloworld HTTP/1.1&gt; User-Agent: curl/7.29.0&gt; Host: 10.43.47.77&gt; Accept: */*&gt; &lt; HTTP/1.1 200 OK&lt; date: Fri, 22 May 2020 02:31:35 GMT&lt; content-length: 11&lt; content-type: text/plain; charset=utf-8&lt; x-envoy-upstream-service-time: 0&lt; server: envoy&lt; * Connection #0 to host 10.43.47.77 left intact/helloworld 成功访问！ 启用etcdctl排查etcd问题由于集群是通过rancher启动的，etcd服务通过docker运行的，查看etcd启动配置：$ docker inspect etcd | jq ".[].Config.Cmd"[ "/usr/local/bin/etcd", "--peer-cert-file=/etc/kubernetes/ssl/kube-etcd-10-17-1-44.pem", "--initial-cluster-token=etcd-cluster-1", "--name=etcd-localhost", "--listen-peer-urls=https://0.0.0.0:2380", "--initial-cluster=etcd-localhost=https://10.17.1.44:2380", "--initial-cluster-state=new", "--heartbeat-interval=500", "--election-timeout=5000", "--data-dir=/var/lib/rancher/etcd/", "--advertise-client-urls=https://10.17.1.44:2379,https://10.17.1.44:4001", "--listen-client-urls=https://0.0.0.0:2379", "--peer-key-file=/etc/kubernetes/ssl/kube-etcd-10-17-1-44-key.pem", "--enable-v2=true", "--trusted-ca-file=/etc/kubernetes/ssl/kube-ca.pem", "--cert-file=/etc/kubernetes/ssl/kube-etcd-10-17-1-44.pem", "--key-file=/etc/kubernetes/ssl/kube-etcd-10-17-1-44-key.pem", "--client-cert-auth=true", "--initial-advertise-peer-urls=https://10.17.1.44:2380", "--peer-trusted-ca-file=/etc/kubernetes/ssl/kube-ca.pem", "--peer-client-cert-auth=true"] 这里endpoints、cert、key、ca四个参数都可以找到，通过设置这四个参考，可以通过etcdctl访问etcd集群：$ ./etcdctl --endpoints=https://10.17.1.44:2379 --cert=/etc/kubernetes/ssl/kube-etcd-10-17-1-44.pem --key=/etc/kubernetes/ssl/kube-etcd-10-17-1-44-key.pem --cacert=/etc/kubernetes/ssl/kube-ca.pem member list5b0279579bcdfd25, started, etcd-localhost, https://10.17.1.44:2380, https://10.17.1.44:2379,https://10.17.1.44:4001, false kubernetes的键值对都是存”/registry”的前缀，查询ambassador相关键值：$ ./etcdctl --endpoints=https://10.17.1.44:2379 --cert=/etc/kubernetes/ssl/kube-etcd-10-17-1-44.pem --key=/etc/kubernetes/ssl/kube-etcd-10-17-1-44-key.pem --cacert=/etc/kubernetes/ssl/kube-ca.pem get "/registry" --prefix=true --keys-only | grep ambassador/registry/apiextensions.k8s.io/customresourcedefinitions/authservices.getambassador.io/registry/apiextensions.k8s.io/customresourcedefinitions/consulresolvers.getambassador.io/registry/apiextensions.k8s.io/customresourcedefinitions/filterpolicies.getambassador.io/registry/apiextensions.k8s.io/customresourcedefinitions/filters.getambassador.io/registry/apiextensions.k8s.io/customresourcedefinitions/hosts.getambassador.io/registry/apiextensions.k8s.io/customresourcedefinitions/kubernetesendpointresolvers.getambassador.io/registry/apiextensions.k8s.io/customresourcedefinitions/kubernetesserviceresolvers.getambassador.io/registry/apiextensions.k8s.io/customresourcedefinitions/logservices.getambassador.io/registry/apiextensions.k8s.io/customresourcedefinitions/mappings.getambassador.io/registry/apiextensions.k8s.io/customresourcedefinitions/modules.getambassador.io/registry/apiextensions.k8s.io/customresourcedefinitions/ratelimits.getambassador.io/registry/apiextensions.k8s.io/customresourcedefinitions/ratelimitservices.getambassador.io/registry/apiextensions.k8s.io/customresourcedefinitions/tcpmappings.getambassador.io/registry/apiextensions.k8s.io/customresourcedefinitions/tlscontexts.getambassador.io/registry/apiextensions.k8s.io/customresourcedefinitions/tracingservices.getambassador.io/registry/apiregistration.k8s.io/apiservices/v1.getambassador.io/registry/apiregistration.k8s.io/apiservices/v1beta1.getambassador.io/registry/apiregistration.k8s.io/apiservices/v1beta2.getambassador.io/registry/apiregistration.k8s.io/apiservices/v2.getambassador.io/registry/clusterrolebindings/ambassador/registry/clusterroles/ambassador/registry/deployments/ambassador/ambassador/registry/deployments/ambassador/ambassador-redis/registry/events/ambassador/acmeclient.1611d42103881983/registry/events/ambassador/acmeclient.1611d42a8f657b22/registry/events/ambassador/acmeclient.1611d47c9a2d559e/registry/events/ambassador/acmeclient.1611d487d1df6cb0/registry/events/ambassador/acmeclient.1611d4d75611dcd7/registry/events/ambassador/acmeclient.1611d4e362feb1b6/registry/events/ambassador/acmeclient.1611d53357ac8137/registry/events/ambassador/acmeclient.1611d53bd22dd4a2/registry/events/ambassador/acmeclient.1611d58c6fda74a4/registry/events/ambassador/acmeclient.1611d59770e65ef6/registry/events/ambassador/acmeclient.1611d5ed8b9bbdaa/registry/events/ambassador/acmeclient.1611d5f7bde30c2e/registry/events/ambassador/acmeclient.1611d648ce16e271/registry/events/ambassador/acmeclient.1611d6540f10c97c/registry/events/ambassador/acmeclient.1611d6a71f391f4f/registry/events/ambassador/acmeclient.1611d6b3387b89df/registry/events/ambassador/ambassador-557999754d-c9x75.1611a47290ea5cce/registry/events/ambassador/ambassador-557999754d-c9x75.1611a473b2092b90/registry/events/ambassador/ambassador-557999754d-c9x75.1611a474c7ee3eef/registry/events/ambassador/ambassador-557999754d-c9x75.1611a48b3d997657/registry/events/ambassador/kale.1611d421033db815/registry/events/ambassador/kale.1611d42a8f59d126/registry/events/ambassador/kale.1611d47c99f771ec/registry/events/ambassador/kale.1611d487d1c3addd/registry/events/ambassador/kale.1611d4d755f315c8/registry/events/ambassador/kale.1611d4e362d7ff0c/registry/events/ambassador/kale.1611d5335793f860/registry/events/ambassador/kale.1611d53bd1c28916/registry/events/ambassador/kale.1611d58c6f8ebc8d/registry/events/ambassador/kale.1611d59770e39acb/registry/events/ambassador/kale.1611d5ed8ae22866/registry/events/ambassador/kale.1611d5f7bd50574f/registry/events/ambassador/kale.1611d648ce038245/registry/events/ambassador/kale.1611d6540f3fefdf/registry/events/ambassador/kale.1611d6a71ea592ca/registry/events/ambassador/kale.1611d6b33778d9bd/registry/getambassador.io/authservices/ambassador/ambassador-edge-stack-auth/registry/getambassador.io/mappings/ambassador/ambassador-devportal/registry/getambassador.io/mappings/ambassador/ambassador-devportal-api/registry/getambassador.io/ratelimitservices/ambassador/ambassador-edge-stack-ratelimit/registry/leases/ambassador/acmeclient]]></content>
      <categories>
        <category>技术博文</category>
        <category>容器技术</category>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>云原生</tag>
        <tag>网关</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用nextcloud搭建个人网盘]]></title>
    <url>%2F2020%2F%E8%BF%90%E7%BB%B4%2F%E7%94%A8nextcloud%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%9B%98%2F</url>
    <content type="text"><![CDATA[nextcloudnextcloud是一个私有云存储网盘项目，nextcloud是owncloud的衍生版本，2016年4月27日，ownCloud联合创始人Frank Karlitschek宣布离开ownCloud ltc.，转而成立另一家公司“Nextcloud”，由于ownCloud程序本身归其开发人员所有，所以Nextcloud可以直接使用ownCloud的核心技术。nextcloud具有强大的扩展性，同时主打 a safe home for all your data，所以在安全性上nextcloud也十分出色。 nextcloud安装参考：https://hub.docker.com/_/nextcloud/ nextcloud安装最简单的方式就是用docker来拉起应用：$ docker run -d \ -v nextcloud:/var/www/html \ -v apps:/var/www/html/custom_apps \ -v config:/var/www/html/config \ -v data:/var/www/html/data \ -v theme:/var/www/html/themes/&lt;YOUR_CUSTOM_THEME&gt; \ -p 8080:80 \ nextcloud nextcloud文件目录说明： /var/www/html主文件夹 var/www/html/custom_apps安装其他应用APP的文件夹 /var/www/html/config本地配置 /var/www/html/datanextcloud的实际数据存储 /var/www/html/themes/主题 如果采用默认的形式启动，其默认是采用sqlite数据库做数据的存储，如果想用mysql或PostgreSQL可以通过--link的方式连接，再设置对应的环境变量： SQLite: SQLITE_DATABASE 数据库名称 MYSQL/MariaDB: MYSQL_DATABASE 数据库名称 MYSQL_USER 数据库用户名 MYSQL_PASSWORD 数据库密码 MYSQL_HOST 数据库服务器地址 PostgreSQL: POSTGRES_DB Name 数据库名称 POSTGRES_USER 数据库用户名 POSTGRES_PASSWORD 数据库密码 POSTGRES_HOST 数据库服务器地址 比如连接一个MySQL:$ docker run -d \ -e MYSQL_DATABASE="nextcloud" \ -e MYSQL_USER="root" \ -e MYSQL_PASSWORD="123456" \ -e MYSQL_HOST="127.0.0.1:3306" \ -p 8080:80 \ nextcloud docker设置管理员用户名密码： NEXTCLOUD_ADMIN_USER管理员用户名 NEXTCLOUD_ADMIN_PASSWORD管理员密码 如果在安装得时候没设置管理员用户名和密码，在第一次打开界面得时候会让你设置。 nextcloud docker迁移可以采用docker-compose的形式部署，将数据存在容器的数据卷中，version: '2'volumes: nextcloud: db:services: db: image: mariadb command: --transaction-isolation=READ-COMMITTED --binlog-format=ROW restart: always volumes: - db:/var/lib/mysql environment: - MYSQL_ROOT_PASSWORD= - MYSQL_PASSWORD= - MYSQL_DATABASE=nextcloud - MYSQL_USER=nextcloud app: image: nextcloud ports: - 8080:80 links: - db volumes: - nextcloud:/var/www/html restart: always 在容器升级或者数据迁移的时候直接重新拉起即可:$ docker-compose pull$ docker-compose up -d]]></content>
      <categories>
        <category>技术博文</category>
        <category>系统运维</category>
      </categories>
      <tags>
        <tag>入门教程</tag>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git小技巧]]></title>
    <url>%2F2020%2F%E8%BF%90%E7%BB%B4%2Fgit%E5%B0%8F%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[基础概念一个文件从改动到提交到 Git 仓库，需要经历三个状态： 工作区：工作区指的是我们本地工作的目录，比如我们可以在刚才创建的 hackers 目录下新增一个 readme 文件，readme 文件这时只是本地文件系统上的修改，还未存储到 Git。 暂存(索引)区：暂存实际上是将我们本地文件系统的改动转化为 Git 的对象存储的过程。 仓库：git commit 后将提交对象存储到 Git 仓库。 git stash应用场景 当正在某个分支A上开发某个项目，这时项目中出现一个bug需要紧急修复，但是正在开发的内容只是完成一半还不想提交，这时git stash命令可以将修改的内容保存至堆栈区，等修复完成后，再次切回到dev分支，从堆栈中恢复刚刚保存的内容。 想比较修改文件部分的性能进些比较，不想再拷贝一份源码，可以利用git stash进些多个版本的切换而不必提交。 本应该在dev分支开发的内容，却在master上进行了开发，需要重新切回到dev分支上进行开发，可以用git stash将内容保存至堆栈中，切回到dev分支后，再次恢复内容即可。 命令将所有未提交的修改（工作区和暂存区）保存至堆栈中，可用于后续恢复当前工作目录。 试验项目目录：$ lsLICENSE test 1. 把当前修改添加到临时堆栈中：$ git stashSaved working directory and index state WIP on master: 454104b Initial commitHEAD is now at 454104b Initial commit 注：如何该文件是新添加的，需要git add先添加到暂存区。 2. 把当前修改添加到临时堆栈中，并可以通过save命名:$ git stash save "fix test field"Saved working directory and index state On master: fix test fieldHEAD is now at 454104b Initial commit 3. 查看当前stash中的内容：$ git stash liststash@&#123;0&#125;: On master: fix test field 4. 将当前stash中的内容弹出(弹出内容会删除)，并应用到当前分支对应的工作目录上：$ git stash pop pop采用的是先进后出: $ git stash liststash@&#123;0&#125;: On master: add test2stash@&#123;1&#125;: On master: add test1stash@&#123;2&#125;: On master: add test$ git stash pop# On branch master# Changes not staged for commit:# (use "git add &lt;file&gt;..." to update what will be committed)# (use "git checkout -- &lt;file&gt;..." to discard changes in working directory)## modified: LICENSE## Untracked files:# (use "git add &lt;file&gt;..." to include in what will be committed)## testno changes added to commit (use "git add" and/or "git commit -a")Dropped refs/stash@&#123;0&#125; (ea8db073e65ab6d9cad25609838a7f2e49c011a9)$ git stash liststash@&#123;0&#125;: On master: add test1stash@&#123;1&#125;: On master: add test 5. 堆栈中的内容应用到当前目录，而不删除： 使用apply：$ git stash apply stash@&#123;1&#125;# On branch master# Changes not staged for commit:# (use "git add &lt;file&gt;..." to update what will be committed)# (use "git checkout -- &lt;file&gt;..." to discard changes in working directory)## modified: LICENSE## Untracked files:# (use "git add &lt;file&gt;..." to include in what will be committed)## testno changes added to commit (use "git add" and/or "git commit -a") 6. 清除堆栈中的所有内容:$ git stash clear 7. 从堆栈中移除某个指定的stash: $ git stash liststash@&#123;0&#125;: WIP on master: 454104b Initial commitstash@&#123;1&#125;: On master: add test1stash@&#123;2&#125;: On master: add test$ git stash drop stash@&#123;1&#125;Dropped stash@&#123;1&#125; (e998224cb579b6a8ae44795abf40b7658a90d487)$ git stash liststash@&#123;0&#125;: WIP on master: 454104b Initial commitstash@&#123;1&#125;: On master: add test 查看堆栈中最新保存的stash和当前目录的差异:$ git stash show LICENSE | 2 +- 1 file changed, 1 insertion(+), 1 deletion(-) git commit –amend应用场景在commit之后发现发现漏掉了几个文件没有添加，或者提交信息写错，可以用--amend修改并重新提交。 命令比如：$ git commit -m 'initial commit'$ git add forgotten_file$ git commit --amend 注：当你在修补最后的提交时，并不是通过用改进后的提交 原位替换 掉旧有提交的方式来修复的， 理解这一点非常重要。从效果上来说，就像是旧有的提交从未存在过一样，它并不会出现在仓库的历史中。在 Git 中任何 commit 的东西几乎总是可以恢复的，那些被删除的分支中的提交或使用 –amend 选项覆盖的提交也可以恢复 场景：$ git status# On branch master# Changes to be committed:# (use "git reset HEAD &lt;file&gt;..." to unstage)## new file: test# 如果添加错了一个修改到暂存区，我们可以通过git reset HEAD的方式重置：$ git reset HEAD test$ git status# On branch master# Untracked files:# (use "git add &lt;file&gt;..." to include in what will be committed)## testnothing added to commit but untracked files present (use "git add" to track) 注意：请务必记得 git checkout -- &lt;file&gt; 是一个危险的命令。 你对那个文件在本地的任何修改都会消失——Git 会用最近提交的版本覆盖掉它。 除非你确实清楚不想要对那个文件的本地修改了，否则请不要使用这个命令。]]></content>
      <categories>
        <category>技术博文</category>
        <category>系统运维</category>
      </categories>
      <tags>
        <tag>快捷键</tag>
        <tag>vscode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker磁盘空间管理]]></title>
    <url>%2F2020%2F%E8%BF%90%E7%BB%B4%2Fdocker%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[docker 容器磁盘空间管理docker 主要包括镜像、容器和数据卷三部分，对docker的磁盘空间管理也主要从着三块入手，在做docker磁盘空间分析之前我们需要简单了解下容器的“镜像层”的概念，一般容器的磁盘管理有一大半是镜像层相关： 什么是镜像层? 说到镜像的层，就要说说Docker镜像的存储组织方式docker 镜像是采用分层的方式构建的，每个镜像都由一系列的 “镜像层” 组成。”镜像层”用来存储一组镜像相关的元数据信息，主要包括镜像的架构(如 amd64)、镜像默认配置信息、构建镜像的容器配置信息、包含所有镜像层信息的 rootfs。当需要修改容器镜像内的某个文件时，docker 利用 rootfs 中的 diff_id 计算出内容寻址的索引(chainID) 来获取 layer 相关信息，进而获取每一个镜像层的文件内容，容器对镜像的修改只对处于最上方的读写层进行变动，不覆写下层已有文件系统的内容，已有文件在只读层中的原始版本仍然存在，但会被读写层中的新版本所隐藏。在多个容器之间共享镜像，每个容器在启动的时候并不需要单独复制一份镜像文件，而是将所有镜像层以只读的方式挂载到一个挂载点，再在上面覆盖一个可读写的容器层。联合挂载技术可以在一个挂载点同时挂载多个文件系统，将挂载点的原目录与被挂载内容进行整合，使得最终可见的文件系统将会包含整合之后的各层的文件和目录。联合挂载包括可读写部分(read-write layer 以及 volumes)、init-layer、只读层(read-only layer) 这 3 部分结构。 layer(镜像层) 是 docker 用来管理镜像层的一个中间概念，镜像是由镜像层组成的，而单个镜像层可能被多个镜像共享，所以 docker 将 layer 与 image 的概念分离。docker 镜像管理中的 layer 主要存放了镜像层的 diff_id、size、cache-id 和 parent 等内容。 dockers磁盘使用空间分析查看docker目录空间从docker目录看磁盘使用情况：$ cd /var/lib/docker$ du -h --max-depth=11.1G ./containers0 ./plugins213G ./overlay228M ./image798M ./volumes0 ./trust116K ./network0 ./swarm16K ./builder56K ./buildkit0 ./tmp0 ./runtimes215G . 可以看出磁盘主要占用都在overlay2和containers这两个文件夹中，containers是容器运行时所产生的文件读写变更，overlay2是容器镜像的层的概念。 进到overlay2继续排查:$ du -h --max-depth=1...196G ./a8f42e1ae9982a4b373d310a9ea1ee08b2d0c571c3757c07f909735c1632f0d7... 发现其中一个目录就占用了近200多G，妥妥的大头，看看具体是哪个容器：import osoverlay = "a8f42e1ae9982a4b373d310a9ea1ee08b2d0c571c3757c07f909735c1632f0d7"names = [line.split(" ")[-1] for line in os.popen("docker ps -a").read().split("\n") if line ]print([name for name in names[1:] if overlay in os.popen("docker inspect %s"%name).read()])# 返回结果: ['livego'] 找到最大的元凶容器了，livego是之前做得一个直播应用，因为当时只是作为试验容器，没有选择外挂的形式，因此容器空间很大，现在已经没什么用了，可以直接删掉:docker rm -f livego 磁盘使用空间资源释放除了直接查看docker目录，还可以通过docker system命令查看各类资源使用状况： $ docker system dfTYPE TOTAL ACTIVE SIZE RECLAIMABLEImages 34 21 9.211GB 4.939GB (53%)Containers 50 28 13.24MB 12.01MB (90%)Local Volumes 11 5 836.2MB 754.5MB (90%)Build Cache 0 0 0B 0B 最后一列表示可回收的比例，可以看到有部分镜像、容器和卷可以回收了，一般是这些资源没有被使用，我们可以逐个去查看:$ docker system df -vImages space usage:REPOSITORY TAG IMAGE ID CREATED SIZE SHARED SIZE UNIQUE SIZE CONTAINERSiotorbhub_iotorbbec latest 9e80c675d506 13 days ago 1.023GB 802.9MB 220MB 1iotorbhub_iot-web latest 3e6100128e21 13 days ago 1.501GB 908.1MB 592.5MB 1nginx latest 6678c7c2e56c 2 weeks ago 126.8MB 69.21MB 57.56MB 1golang 1.13 3a7408f53f79 3 weeks ago 802.9MB 802.9MB ...Containers space usage:CONTAINER ID IMAGE COMMAND LOCAL VOLUMES SIZE CREATED STATUS NAMES2cb435f35f36 rancher/pause:3.1 "/pause" 0 0B 38 seconds ago Created k8s_POD_default-http-backend-67cf578fc4-rhpkv_ingress-nginx_8d427371-c7c4-44fa-9b5e-745b4fea3dbc_13474a58df48bb9cc jenkins "/bin/tini -- /usr/l…" 1 0B 47 hours ago Created loving_mcleanbe40bd464972 redis "docker-entrypoint.s…" 1 0B 11 days ago Up 11 days suspicious_spencea365e2d14c35 nginx "nginx -g 'daemon of…" 1 2B 13 days ago Up 13 days iotorbhub_nginx_1...Local Volumes space usage:VOLUME NAME LINKS SIZE33f5c1809964242a82a70a8e8fddaadc413b593be5c4310a5022a52c29917fd7 0 174.1MB70451b6e13e2584f5174cca6d0b30e6e143015d8cbb16160eedfbb1d7b88684a 0 25.27MB9544fd226986dd7d1921b63927072fbf8634847f524326c713505ab74874cde4 1 120B9fef3da76c45dfcba85359ddf1684ac6c9347ba99ab61be05796f5151cd43306 0 41.43MB... 也可以通过docker system prune的命令一键清理：$ docker system prune --helpUsage: docker system prune [OPTIONS]Remove unused dataOptions: -a, --all Remove all unused images not just dangling ones --filter filter Provide filter values (e.g. 'label=&lt;key&gt;=&lt;value&gt;') -f, --force Do not prompt for confirmation --volumes Prune volumes 再看看：$ docker system dfTYPE TOTAL ACTIVE SIZE RECLAIMABLEImages 15 15 3.712GB 71.03MB (1%)Containers 28 28 1.234MB 0B (0%)Local Volumes 11 3 836.2MB 779.8MB (93%)Build Cache 0 0 0B 0B 发现镜像和容器空间都被释放了。 docker 镜像精简除了对已有运行系统进行容器磁盘空间管理外，我们还可以在镜像的源头进行磁盘空间的管理工作： 选择小体积基础镜像docker 镜像精简最简单的方法就是用alpine作为底层基础镜像，像 alphine 镜像 只有 5MB，是非常小的。或者可以用带 -slim 标签的镜像，一般这类镜像是通过瘦身的，镜像的体积会比较小。 减少RUN、ADD、COPY会改变容器Layer的命令每个镜像都由一系列的 “镜像层” 组成，每次对文件的改动命令（RUN、ADD、COPY）都会被提交到一个版本，所以应该尽量减少这些命令的使用，比如多个RUN可以用&amp;&amp;合并。 对于镜像层是否可以优化，我们可以通过docker history命令查看镜像各层的构建：$ docker history shikanon.com/hyperkube:v1.16.6-rancher1IMAGE CREATED CREATED BY SIZE COMMENT4c20a23643b7 2 months ago /bin/sh -c #(nop) LABEL org.label-schema.vc… 0B &lt;missing&gt; 2 months ago /bin/sh -c #(nop) LABEL org.label-schema.vc… 0B &lt;missing&gt; 2 months ago /bin/sh -c #(nop) LABEL org.label-schema.sc… 0B &lt;missing&gt; 2 months ago /bin/sh -c #(nop) LABEL org.label-schema.bu… 0B &lt;missing&gt; 2 months ago /bin/sh -c echo "deb http://deb.debian.org/d… 17.4MB &lt;missing&gt; 2 months ago /bin/sh -c sed -i -e 's!\bmain\b!main contri… 608MB &lt;missing&gt; 2 months ago /bin/sh -c #(nop) COPY file:0fce35cc22ae9eae… 152MB &lt;missing&gt; 13 months ago /bin/sh -c #(nop) COPY dir:2245a63ce7eafa5c8… 45.9MB &lt;missing&gt; 13 months ago /bin/sh -c echo b3a101b3-deba-49a1-afe2-d42d… 303MB &lt;missing&gt; 13 months ago /bin/sh -c DEBIAN_FRONTEND=noninteractive dp… 9.55kB &lt;missing&gt; 13 months ago /bin/sh -c echo "dash dash/sh boolean false"… 282B &lt;missing&gt; 13 months ago /bin/sh -c echo b3a101b3-deba-49a1-afe2-d42d… 1.49MB &lt;missing&gt; 13 months ago /bin/sh -c ln -s /hyperkube /apiserver &amp;&amp; l… 140B &lt;missing&gt; 13 months ago /bin/sh -c #(nop) CMD ["/bin/sh"] 0B &lt;missing&gt; 13 months ago /bin/sh -c #(nop) ADD file:813b8c3d7b7496f29… 42.3MB 利用FROM AS 和 COPY 实现编译阶段和代码阶段分离Docker 17.05版本以后提供了COPY --from的语法，他提供了从镜像层中直接拷贝文件： # 将 编译阶段 命名为 builderFROM golang:1.10.3 as builder # 编译的各类指令ADD . /app RUN go build /app/main.go... # 运行阶段# 多个 FROM 会以最后一条 FROM 为准，之前的 FROM 会被抛弃FROM scratch # 从编译阶段的中拷贝编译结果到当前镜像中COPY --from=builder /build/server / COPY –from 不但可以从前置阶段中拷贝，还可以直接从一个已经存在的镜像中拷贝，例如：COPY --from=quay.io/coreos/etcd:v3.3.9 /usr/local/bin/etcd /usr/local/bin/ 这样最后运行的只有二进制而没有编译阶段的代码文件，容器体积会缩小很多。 借助distroless借助镜像工具 distroless 减少镜像种不必要的依赖，distroless 是 google 开放的优化版容器镜像， “distroless”镜像仅包含了应用和运行时依赖。]]></content>
      <categories>
        <category>技术博文</category>
        <category>容器技术</category>
        <category>Dokcer</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>Docker</tag>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[经典共识算法解读: raft & paxos]]></title>
    <url>%2F2020%2F%E6%9E%B6%E6%9E%84%2F%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E8%A7%A3%E8%AF%BB-raft-paxos%2F</url>
    <content type="text"><![CDATA[什么是一致性(consensus)一致性(consensus)，这个好理解，就是在分布式系统中，保证各节点上的数据保持一致。一致性是CAP理论的重要一环，如果想了解CAP理论，可以参考CAP简易理解一文。 分布式系统面临的一系列问题： performance -&gt; sharding sharding -&gt; failed tolerance tolerance -&gt; replication replication -&gt; inconsistency consistency -&gt; low performance RaftRaft 放在前面，因为学习适合从简单开始，raft的资料也更充足些，可以帮助理解。 Raft动态图解： Raft可以分为 Leader Election 和 Log Replication 两个阶段。 各阶段的情况]]></content>
      <categories>
        <category>技术博文</category>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>一致性</tag>
        <tag>共识算法</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊云原生的那些事]]></title>
    <url>%2F2020%2F%E6%BC%94%E8%AE%B2%2F%E8%81%8A%E8%81%8A%E4%BA%91%E5%8E%9F%E7%94%9F%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B%2F</url>
    <content type="text"><![CDATA[大家好,今天和大家聊聊云原生,相信这个词大家应该或多或少都听过, 那么什么是云原生计算呢?云原生技术得技术栈有哪些呢? 下面主要从以下三个主题来聊聊今天得话题, 什么是云原生, 云原生得发展史和云原生得生态圈。 云原生的概念最早开始于2010年，在当时 Paul Fremantle 的一篇博客中被提及，他主要将其描述为一种和云一样的系统行为的应用的编写，比如分布式的、松散的、自服务的、持续部署与测试的。当时提出云原生是为了能构建一种符合云计算特性的标准来指导云计算应用的编写。后来到2013年 Matt Stine在推特上迅速推广云原生概念，并在2015年《迁移到云原生架构》一书中定义了符合云原生架构的特征：12因素、微服务、自服务、基于API协作、扛脆弱性。而由于这本书的推广畅销，这也成了很多人对云原生的早 CNCF得定义总结一下就是:（1）基于容器、服务网格、微服务、不可变基础设施和声明式API构建的可弹性扩展的应用；（2）基于自动化技术构建具备高容错性、易管理和便于观察的松耦合系统；（3）构建一个统一的开源云技术生态，能和云厂商提供的服务解耦，可以看出这一阶段CNCF对云原生的定义加上服务网格和声明式API，同时为这一概念阐述更深一层的意义，也就是建立一个统一中立的开源云生态（至于是否中立嘛这里就不谈了:）。这对云原生的生态定位会是很重要的一点，也算CNCF最初成立的宗旨之一吧，打破云巨头的垄断。 为什么用“解构”？ 解构，或译为“结构分解”，是后结构主义提出的一种批评方法。是解构主义者德里达的一个术语。“解构”概念源于海德格尔《存在与时间》中的“deconstruction”一词，原意为分解、消解、拆解、揭示等，德里达在这个基础上补充了“消除”、“反积淀”、“问题化”等意思。这里是打算用解构得思想给大家来分析下“云原生”得理解： Cloud Native，从词面上拆解其实就是 Cloud 和 Native，也就是云计算和土著的意思——云计算上的原生居民，即天生具备云计算的亲和力。那怎么理解“云的原生居民”呢？首先从云的角度来理解，云本质可以看作是一种提供稳定计算存储资源的对象，为了实现这点，像虚拟化、弹性扩展、高可用、高容错性、自恢复这些都是云的基本属性，云原生作为一种云计算，这是所具备的第一层含义。第二层要从 Native 来看，云原生和传统的在云上跑的应用是不同。比如一些基于公有云搭建的应用，是基于传统的SOA架构来搭建的，然后再移植到云上去运行，那么他和云得整合是非常低得。 为什么低呢？云作为一种分布式架构，其“土著居民”也应该是基于分布式架构设计出来得，而微服务或者Serverless这种将服务或函数拆分成一个个模块的松耦合系统天然就具备分布式设计得属性。这是Native的第一种表现。其次云作为一种PaaS服务，这位“土著居民”从出生(设计)到成长(开发)，再到生活(部署)都应该是基于云的理念来实现的，那么就需要一套自动化的开发流程CI/CD来实现。这是Native的第二种表现。而最后“土著居民”的特点希望做到能在所有的云端都是适应的，不管是各厂商的公有云 像AWS、Azure、阿里云，还是各企业自己搭建的私有云，云原生的应用都能做到无缝的运行和连接。 云原生的发展历史可以分为三个时代, 虚拟机时代-&gt;容器时代-&gt;云原生时代。 虚拟机时代:这要从2006年说起，这一年Avi Kivity宣告了Kernel-based Virtual Machine的诞生，也就是我们常说的KVM——基于内核的虚拟机，采用硬件虚拟化技术的全虚拟化解决方案。KVM以其精简的架构，清晰的定位获得Linux社区多数开发人员的支持并快速被合并入主干,2007年2月，KVM发布到内核2.6.20中。KVM从诞生开始就定位于基于硬件虚拟化支持的全虚拟化实现。它以内核模块的形式加载之后，就将Linux内核变成了一个Hypervisor，但硬件管理等还是通过Linux kernel来完成的，一个KVM客户机对应于一个Linux进程，每个vCPU则是这个进程下的一个线程，还有单独的处理IO的线程，也在一个线程组内。所以，宿主机上各个客户机是由宿主机内核像调度普通进程一样调度的，即可以通过Linux的各种进程调度的手段来实现不同客户机的权限限定、优先级等功能。除了KVM，这一年由Google的工程师Paul Menage和Rohit Seth 在2006年发起一个叫进程容器（process containers）的项目，这就是后面容器时代的基石之一 —— Cgroups。在2007年时，因为在Linux内核中，容器（container）这个名词有许多不同的意义，为避免混乱，被重命名为Cgroups，并且被合并到2.6.24版的内核中去。随后，2008 年，通过将 Cgroups 的资源管理能力和 Linux Namespace 的视图隔离能力组合在一起，LXC 完整的容器技术出现在 Linux 内核中，并且可以在单个 Linux 内核上运行而无需任何补丁。随后2010年7月，NASA和Rackspace共同发布了著名的开源项目Openstack，Openstack的开源标志着开源领域真正具有一个成熟的云计算解决方案。 容器时代：容器时代的标志性事件就是 dotCloud 开源的一个基于 LXC 的高级容器引擎 Docker的问世。Docker产品的发布，让企业逐渐从笨重的虚拟机转换到轻量级的容器部署，随着docker的发布，市面上涌现出大量的容器解决方案大量轻量级的虚拟化解决方案，如Rocket、Windows Containers等。 云原生时代：随着容器的成熟和云计算的发展，人们迫切需要一种在云上的最佳实践，云原生就被提出了。在2015年，Linux基金会成立了一个叫The Cloud Native Computing Foundation基金组织，也就是CNCF。随着大厂的加盟，像Google、AWS、微软、阿里巴巴、腾讯云、IBM等，CNCF逐渐成为云原生的最权威组织，并将云原生技术推广到世界各地。 这里主要分成了几个技术板块，应用定义及部署(App Definition and Development)编排与管理(Orchestration &amp; Management)运行环境(Runtime)配置(Provisioning)平台(Platform)可观测性和分析(Observability and Analysis)无服务(Serverless)这几大板块基本把云原生技术所涉及领域都涵括进去了，下面详细介绍下各板块所涉及到的技术栈。从系统层次来看，从上到下分别是：应用层：应用定义及部署(App Definition and Development)、配置(Provisioning)、可观测性和分析(Observability and Analysis)、无服务(Serverless)集群：编排与管理(Orchestration &amp; Management)底层运行环境：运行环境(Runtime) 数据库(Database)：应用层的数据库，其中 PingCAP 公司推出的 TiDB 就是其中的佼佼者之一，其具有水平弹性扩展、分布式事务等特性让其和云原生应用理念天然的契合。流式处理和消息队列(Streaming and Messaging)：常用的消息队列有kafka、NATS、RabbitMQ等，常用的应用系统中也用的比较多。流式处理有Spark streaming、storm、flink等，都是常用的大数据流式计算框架。应用定义和镜像构建(App Definition and Image Build)：云原生的应用构建一般由于一堆 YAML 文件组成，为了能更灵活的生成和打包管理这些配置定义文件，我们需要一些工具，而 Helm 就是k8s应用比较多的一种应用程序 Chart 的创建、打包、发布以及创建的软件包管理工具。持续集成与持续部署(Continuous Integration and Continuous Delivery)：持续集成和持续部署是一种基于敏捷开发提出的开发工具，由于敏捷开发中要求要以快步小走的方式进行迭代，为了节约测试、部署时间周期，必须需要一个能做到和代码管理进行结合的自动化测试和部署工具，而这就是持续集成和部署（简称CI/CD）。常用的CI/CD工具有Jenkins、Travis CI、gitlab runner等。 TiDB算得上比较正宗的云原生数据库，其采用了计算和存储节点分离的方式，TiDB 具有水平扩展和高可用特点，这里简单大家介绍下 TiDB 的整体架构。TiDB 集群主要包括三个核心组件：TiDB Server，PD Server 和 TiKV Server。 PD ServerPlacement Driver (简称 PD) 是整个集群的管理模块，其主要工作有三个：一是存储集群的元信息（某个 Key 存储在哪个 TiKV 节点）；二是对 TiKV 集群进行调度和负载均衡（如数据的迁移、Raft group leader 的迁移等）；三是分配全局唯一且递增的事务 ID。PD 通过 Raft 协议保证数据的安全性。Raft 的 leader server 负责处理所有操作，其余的 PD server 仅用于保证高可用。建议部署奇数个 PD 节点。 TiKV ServerTiKV Server 负责存储数据，从外部看 TiKV 是一个分布式的提供事务的 Key-Value 存储引擎。存储数据的基本单位是 Region，每个 Region 负责存储一个 Key Range（从 StartKey 到 EndKey 的左闭右开区间）的数据，每个 TiKV 节点会负责多个 Region。TiKV 使用 Raft 协议做复制，保持数据的一致性和容灾。副本以 Region 为单位进行管理，不同节点上的多个 Region 构成一个 Raft Group，互为副本。数据在多个 TiKV 之间的负载均衡由 PD 调度，这里也是以 Region 为单位进行调度。 TiSparkTiSpark 作为 TiDB 中解决用户复杂 OLAP 需求的主要组件，将 Spark SQL 直接运行在 TiDB 存储层上，同时融合 TiKV 分布式集群的优势，并融入大数据社区生态。至此，TiDB 可以通过一套系统，同时支持 OLTP 与 OLAP，免除用户数据同步的烦恼。 容器编排与调度(Orchestration and Scheduling)：容器的编排和管理可以说是云原生的基石，而 Kubernetes 可以说是这个领域的事实标准，作为 CNCF 基金会的首个毕业项目和金字招牌甚至很多人认为云原生就是 k8s 和其相关的一系列技术，虽然这样的说法是很不准确的，不过现在云原生技术确实和k8s绑定的越来越紧密，由此而衍生了一大批的工具生态。一致性与服务发现(Coordination and Service Discovery)：各服务之间的协同以及服务发现是分布式计算中的核心，分布式架构作为云原生的基础特性之一可以说是不可或缺的功能组件，从大数据时代的老牌的Zookeeper到到Docker Swarm采用的Consul，再到k8s中集成的分布式键值数据库etcd和DNS服务发现CoreDNS都是其中的佼佼者。远程调用服务(Remote Procedure Call)：广义上的远程调用一般分为两种，一种基于HTTP协议，一种基于RPC，而狭义的远程调用一般指的RPC。比较常用的RPC框架有 Google 开源的 gRPC和 Apache 旗下的 Thrift 框架，k8s是采用 gRPC 框架作为服务间调用。服务代理(Service Proxy)：平常用的最多的服务代理应该就是nginx了，作为一个高性能支持正向和方向代理的服务器, nginx具备成熟和广泛的应用场景。envoy 则是一个新生的用go写的服务代理，像Istio、Ambassador的服务代理就是采用了envoy，因此在云原生应用中 envoy 也具备强大的生命力。API网关(API Gateway)：API网格主要起到对所有的API的调用进行统一接入和管理、认证、授权等功能。ambassador、traefik、kong等都是优秀的微服务网关。服务网格(Service Mesh)：服务网格是用于控制应用的不同部分之间如何共享数据，服务网格是内置于应用程序中的专用基础架构层，用于记录应用的不同部分是否能正常交互。服务网格可以更细粒度地为每个服务提供限流、管控、熔断、安全等功能。Istio 是最流行的 Service Mesh 之一，其以易用性、无侵入、功能强大赢得众多用户青睐，相信不久将来应该有可能会成为服务网格的事实标准。 各种应用和工作负载逐渐运行在k8s之上，有个比喻特别好，就是k8s是云原生的操作系统，而运行在k8s之上的容器应用就像电脑的app一样 云原生存储(Cloud Native Storage)：随着数据库、消息队列等中间件逐步在容器环境中得到应用，容器持久化存储的需求也逐步增多，随之而来的是建立一套基于云原生的存储系统，在k8s中对应的就是CSI——容器存储接口。持久化存储中用的比较多的是Ceph，作为一个分布式存储系统，Ceph提供较好的性能、可靠性和可扩展性。容器运行时(Container Runtime)：容器运行时就是指容器的运行环境，比如最常用的Docker。除了docker,还有一个比较著名的开源容器运行时标准组织（Open Container Initiative），简称OCI。OCI由Linux基金会于2015年6月成立，旨在围绕容器格式和运行时制定一个开放的工业化标准，目前主要有两个标准文档：容器运行时标准 （runtime spec）和 容器镜像标准（image spec），Containerd就是一个满足OCI规范的核心容器运行时。云原生网络(Cloud Native Network)：容器的网络方案，为容器集群提供一层虚拟化的网络，像k8s的CNI就是其中一个标准的网络接口，flannel是 CoreOS 公司主推的容器网络方案，现在现在比较主流的一种网络之一。 Kubernetes的分层架构：核心层：Kubernetes最核心的功能，对外提供API构建高层的应用，对内提供插件式应用执行环境应用层：部署（无状态应用、有状态应用、批处理任务、集群应用等）和路由（服务发现、DNS解析等）管理层：系统度量（如基础设施、容器和网络的度量），自动化（如自动扩展、动态Provision等）以及策略管理（RBAC、Quota、PSP、NetworkPolicy等）接口层：kubectl命令行工具、客户端SDK以及集群联邦生态系统：在接口层之上的庞大容器集群管理调度的生态系统，可以划分为两个范畴Kubernetes外部：日志、监控、配置管理、CI、CD、Workflow、FaaS、OTS应用、ChatOps等Kubernetes内部：CRI、CNI、CVI、镜像仓库、Cloud Provider、集群自身的配置和管理等 自动化与配置(Automation &amp; Configuration)：用于自动化部署和配置容器运行平台和环境，代表工具包括Ansible、Chef、Puppet、VMware、OpenStack。容器注册(Container Registry)：容器注册是整个CNCF云原生中的重要部件，因为基于容器的运行环境中，所有的应用都需要借助容器镜像库来进行安装和部署。容器注册工具主要分公有工具和私有工具，公有的容器镜像库主要包括docker官方的registry，在私有镜像库最著名的是Harbor，目前市面上大量的容器平台目前都基于Harbor构建其镜像仓库。安全与合规性(Security &amp; Compliance)：安全性和合规性基本是所有系统都会面临的东西，Notary和TUF是这个领域两个主要的项目，其中TUF是一个开源的安全标准，Notary是其中一个实现。密钥管理(Key Management)：秘钥管理做权限管理和身份认证，比如雅虎发布的athenz，就是一个基于RBAC的权限管理和配置。SPIFFE通用安全身份框架提供了统一的工作负载身份解决方案。 监控(Monitoring)：监控主要是对运行系统和应用的状态进行观测与预警，常用的监控有Prometheus、Zabbix等，Grafana通常会配合Prometheus做图形化的展示。日志(Logging)：日志采集模块，如ELK(elastic/logstash/kibana)、fluentd等。追踪(Tracing): 这里的tracing是指分布式链路追踪，因为在分布式系统中，各服务之间相互调用，一个地方出问题可以会导致很多其他服务上的组件出现连锁问题，因此在定位问题的时候十分困难，必须要建立分布式链路追踪来对错误和故障进行定位，分布式跟踪是对日志和监控指标的重要补充。OpenTracing 是一套分布式系统跟踪标准协议，为大家建立一套统一的标准来实现分布式跟踪信息的描述和传递。混沌工程(Chaos Engineering)：混沌工程主要是解决在高复杂性的分布式系统之上建立起值得信任的生产部署体系，比如服务不可用时后备设置不当 ; 因超时设置不当导致反复重试 ; 下游依赖关系在接收到大量流量时出现中断 ; 发生单点故障时连锁引发后续问题等一系列混乱的难题，建立受控实验观察分布式系统。 混沌工程类似于“故障演练”，不局限于测试，而更像是工程实践。为什么这么说，通常的测试用例会有“期望结果”和“实际结果”，通过将两个结果比较，或者对用户行为的预期，来判断测试通过或失败。而混沌试验类似于”探索性测试“，试验本身没有明确是输入和预期结果，通过对系统和服务的干预，来观察系统的”反应“。我们将混沌工程原则融入在试验过程中：在生产环境小规模模拟系统故障并定期自动化执行试验，通过试验结果与正常结果进行比对，观察系统”边界“。引入混沌实践时需要了解混沌工程的五大原则。1）建立稳定状态的假设在做混沌工程实验的时候，首先得确定需要测试的指标已经做了高可用的工作，才能进行验证指标对业务的是否有影响。如果没有做好高可用工作，而引入混沌工程实验的话，对业务而言将会是一声灾难。2）多样化现实世界事件不能够凭空想像出一些事件来验证，而是引入那些真实存在的，频繁发生的，且影响重大的事件。对我们而言给这些事件做混沌实验才具有价值。如磁盘故障、网络延时、主机宕机等。3）在生产环境运行实验尽量在类生产环境中进行测试，生产环境的多样性是任何其它环境无法比拟的。混沌工程的价值就是保证生产上的业务连续不中断。4）持续自动化运行实验实施混沌工程实验一般最开始是人工手动操作，当我们对业务有足够的信心时，要把混沌实验做成持续自动化。在版本升级、不断迭代的过程中，持续不断自动化地做验证，最大程序保证业务的连续性验证。5）最小化影响范围做混沌工程的意义就是保证生产上的业务。在我们实施混沌实验时也必须保证对线上业务影响最小。在实施实验时，从小范围开始，不断扩大范围，避开高风险时段，如选择业务量最小的时候实施实验。 工具(Tools)：一些工具集，，比如CNCF的landscape作为一个信息聚合网站可以用于查看各种新的软件工具、Dashbird可以用于serverless监控和故障排查工具。安全(Security)：主要提供serverless的安全防护。框架(Framework)：指直接用于构建、管理serverless应用的框架，比如Apex可以用于构建、发布和管理AWS Lambda，SAM 一个Python的开源serverless应用构建框架。注册平台(Hosted Platfrom)：指提供第三方注册的厂商服务，比如AWS的Lambda、阿里云的函数计算服务、Google的cloud functions服务等。可安装平台(Installable Platform)：这里就是用于自己搭建serverless平台的工具，比如著名的Knative，就是由谷歌开源的 serverless 架构方案。 Serve在这里非常重要，它实际上是一种带有内置Istio的组件。Istio提供了许多功能 ，例如流量管理、智能路由、自动缩放和缩放到零等，这是一个非常酷的概念。但实际上，对于非服务器应用程序，开发者希望的是可以扩展到1000个数据包，并且当没有人访问时，将其恢复为0。那么，让我们看看Knative Serve 是如何工作的。首先，在启动一个传统的microservice或function后，该服务指向并管理两个不同的事物：1）Route 2）Config。Knative Serve为我们提供了快照，提供了智能的、可拓展的路由。使用Istio流量管理功能，实际上可以通过Route管理所有流量，并将它们路由到新旧两个版本中的一个或多个中，我们可以这么假设，如所有流量的10％被路由到版本2，90％停留在版本1上。]]></content>
      <categories>
        <category>演讲稿展示</category>
        <category>云原生</category>
      </categories>
      <tags>
        <tag>入门教程</tag>
        <tag>云原生</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[云原生生态中的技术栈]]></title>
    <url>%2F2020%2F%E6%9E%B6%E6%9E%84%2F%E4%BA%91%E5%8E%9F%E7%94%9F%E7%94%9F%E6%80%81%E6%8A%80%E6%9C%AF%E6%A0%88%2F</url>
    <content type="text"><![CDATA[云原生的生态圈既然介绍云原生的技术生态体系，这里不得不祭出CNCF的这张landscape。 这张取自2020/03/02，最新的可见：https://github.com/cncf/landscape 这里主要分成了几个技术板块， 应用定义及部署(App Definition and Development) 编排与管理(Orchestration &amp; Management) 运行环境(Runtime) 配置(Provisioning) 平台(Platform) 可观测性和分析(Observability and Analysis) 无服务(Serverless) 这几大板块基本把云原生技术所涉及领域都涵括进去了，下面详细介绍下各板块所涉及到的技术栈。 从系统层次来看，从上到下分别是： 应用层：应用定义及部署(App Definition and Development)、配置(Provisioning)、可观测性和分析(Observability and Analysis)、无服务(Serverless) 集群：编排与管理(Orchestration &amp; Management) 底层运行环境：运行环境(Runtime) 应用定义及部署 这个板块的技术栈主要是应用开发过程种都会用到的，像数据库、流式处理和消息队列、应用定义和镜像构建、持续集成和持续部署。 数据库(Database)：应用层的数据库，其中 PingCAP 公司推出的 TiDB 就是其中的佼佼者之一，其具有水平弹性扩展、分布式事务等特性让其和云原生应用理念天然的契合。 流式处理和消息队列(Streaming and Messaging)：常用的消息队列有kafka、NATS、RabbitMQ等，常用的应用系统中也用的比较多。流式处理有Spark streaming、storm、flink等，都是常用的大数据流式计算框架。 应用定义和镜像构建(App Definition and Image Build)：云原生的应用构建一般由于一堆 YAML 文件组成，为了能更灵活的生成和打包管理这些配置定义文件，我们需要一些工具，而 Helm 就是k8s应用比较多的一种应用程序 Chart 的创建、打包、发布以及创建的软件包管理工具。 持续集成与持续部署(Continuous Integration and Continuous Delivery)：持续集成和持续部署是一种基于敏捷开发提出的开发工具，由于敏捷开发中要求要以快步小走的方式进行迭代，为了节约测试、部署时间周期，必须需要一个能做到和代码管理进行结合的自动化测试和部署工具，而这就是持续集成和部署（简称CI/CD）。常用的CI/CD工具有Jenkins、Travis CI、gitlab runner等。 编排与管理 编排与管理板块可以说是云原生的核心，其包括了容器编排、一致性与服务发现、远程程序调用(RPC)、服务代理、API网关、服务网格。 容器编排与调度(Orchestration and Scheduling)：容器的编排和管理可以说是云原生的基石，而 Kubernetes 可以说是这个领域的事实标准，作为 CNCF 基金会的首个毕业项目和金字招牌甚至很多人认为云原生就是 k8s 和其相关的一系列技术，虽然这样的说法是很不准确的，不过现在云原生技术确实和k8s绑定的越来越紧密，由此而衍生了一大批的工具生态。 一致性与服务发现(Coordination and Service Discovery)：各服务之间的协同以及服务发现是分布式计算中的核心，分布式架构作为云原生的基础特性之一可以说是不可或缺的功能组件，从大数据时代的老牌的Zookeeper到到Docker Swarm采用的Consul，再到k8s中集成的分布式键值数据库etcd和DNS服务发现CoreDNS都是其中的佼佼者。 远程调用服务(Remote Procedure Call)：广义上的远程调用一般分为两种，一种基于HTTP协议，一种基于RPC，而狭义的远程调用一般指的RPC。比较常用的RPC框架有 Google 开源的 gRPC和 Apache 旗下的 Thrift 框架，k8s是采用 gRPC 框架作为服务间调用。 服务代理(Service Proxy)：平常用的最多的服务代理应该就是nginx了，作为一个高性能支持正向和方向代理的服务器, nginx具备成熟和广泛的应用场景。envoy 则是一个新生的用go写的服务代理，像Istio、Ambassador的服务代理就是采用了envoy，因此在云原生应用中 envoy 也具备强大的生命力。 API网关(API Gateway)：API网格主要起到对所有的API的调用进行统一接入和管理、认证、授权等功能。ambassador、traefik、kong等都是优秀的微服务网关。 服务网格(Service Mesh)：服务网格是用于控制应用的不同部分之间如何共享数据，服务网格是内置于应用程序中的专用基础架构层，用于记录应用的不同部分是否能正常交互。服务网格可以更细粒度地为每个服务提供限流、管控、熔断、安全等功能。Istio 是最流行的 Service Mesh 之一，其以易用性、无侵入、功能强大赢得众多用户青睐，相信不久将来应该有可能会成为服务网格的事实标准。 运行环境 这里的运行时板块指的就是容器运行环境，包括了容器存储、容器计算、容器网络三大工具，在k8s分别对应的是CSI、CRI和CNI三类接口定义。 云原生存储(Cloud Native Storage)：随着数据库、消息队列等中间件逐步在容器环境中得到应用，容器持久化存储的需求也逐步增多，随之而来的是建立一套基于云原生的存储系统，在k8s中对应的就是CSI——容器存储接口。持久化存储中用的比较多的是Ceph，作为一个分布式存储系统，Ceph提供较好的性能、可靠性和可扩展性。 容器运行时(Container Runtime)：容器运行时就是指容器的运行环境，比如最常用的Docker。除了docker,还有一个比较著名的开源容器运行时标准组织（Open Container Initiative），简称OCI。OCI由Linux基金会于2015年6月成立，旨在围绕容器格式和运行时制定一个开放的工业化标准，目前主要有两个标准文档：容器运行时标准 （runtime spec）和 容器镜像标准（image spec），Containerd就是一个满足OCI规范的核心容器运行时。 云原生网络(Cloud Native Network)：容器的网络方案，为容器集群提供一层虚拟化的网络，像k8s的CNI就是其中一个标准的网络接口，flannel是 CoreOS 公司主推的容器网络方案，现在现在比较主流的一种网络之一。 配置 配置板块主要包括四个模块自动化与配置、容器注册、安全与合规性、密钥管理。 自动化与配置(Automation &amp; Configuration)：用于自动化部署和配置容器运行平台和环境，代表工具包括Ansible、Chef、Puppet、VMware、OpenStack。 容器注册(Container Registry)：容器注册是整个CNCF云原生中的重要部件，因为基于容器的运行环境中，所有的应用都需要借助容器镜像库来进行安装和部署。容器注册工具主要分公有工具和私有工具，公有的容器镜像库主要包括docker官方的registry，在私有镜像库最著名的是Harbor，目前市面上大量的容器平台目前都基于Harbor构建其镜像仓库。 安全与合规性(Security &amp; Compliance)：安全性和合规性基本是所有系统都会面临的东西，Notary和TUF是这个领域两个主要的项目，其中TUF是一个开源的安全标准，Notary是其中一个实现。 密钥管理(Key Management)：秘钥管理做权限管理和身份认证，比如雅虎发布的athenz，就是一个基于RBAC的权限管理和配置。SPIFFE通用安全身份框架提供了统一的工作负载身份解决方案。 可观测性与分析 可观测性与分析板块主要包括了监控、日志、追踪和混沌工程。 监控(Monitoring)：监控主要是对运行系统和应用的状态进行观测与预警，常用的监控有Prometheus、Zabbix等，Grafana通常会配合Prometheus做图形化的展示。 日志(Logging)：日志采集模块，如ELK(elastic/logstash/kibana)、fluentd等。 追踪(Tracing): 这里的tracing是指分布式链路追踪，因为在分布式系统中，各服务之间相互调用，一个地方出问题可以会导致很多其他服务上的组件出现连锁问题，因此在定位问题的时候十分困难，必须要建立分布式链路追踪来对错误和故障进行定位，分布式跟踪是对日志和监控指标的重要补充。OpenTracing 是一套分布式系统跟踪标准协议，为大家建立一套统一的标准来实现分布式跟踪信息的描述和传递。 混沌工程(Chaos Engineering)：混沌工程主要是解决在高复杂性的分布式系统之上建立起值得信任的生产部署体系，比如服务不可用时后备设置不当 ; 因超时设置不当导致反复重试 ; 下游依赖关系在接收到大量流量时出现中断 ; 发生单点故障时连锁引发后续问题等一系列混乱的难题，建立受控实验观察分布式系统。 无服务 Serverless是一个很大的领域，因此针对 serverless 这里专门又细分了五个模块：工具、安全、框架、注册平台和可安装平台。 工具(Tools)：一些工具集，，比如CNCF的landscape作为一个信息聚合网站可以用于查看各种新的软件工具(CNCF永远把自己放第一😂)、Dashbird可以用于serverless监控和故障排查工具。 安全(Security)：主要提供serverless的安全防护。 框架(Framework)：指直接用于构建、管理serverless应用的框架，比如Apex可以用于构建、发布和管理AWS Lambda，SAM 一个Python的开源serverless应用构建框架。 注册平台(Hosted Platfrom)：指提供第三方注册的厂商服务，比如AWS的Lambda、阿里云的函数计算服务、Google的cloud functions服务等。 可安装平台(Installable Platform)：这里就是用于自己搭建serverless平台的工具，比如著名的Knative，就是由谷歌开源的 serverless 架构方案。 平台这些主要是云原生相关的平台供应商，需要找相关的产品和合作可以在这里找。 后记云原生的技术范畴是很广的，可以说所有和分布式系统相关的技术栈基本都包含了，也是云计算最佳实践的集合。针对每个领域细细琢磨研究，也许这是条不错的技术之路。]]></content>
      <categories>
        <category>技术博文</category>
        <category>容器技术</category>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>云原生</tag>
        <tag>kubernetes</tag>
        <tag>CNCF</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[什么是云原生?聊聊云原生的“前世今生”]]></title>
    <url>%2F2020%2F%E6%9E%B6%E6%9E%84%2F%E4%BB%80%E4%B9%88%E6%98%AF%E4%BA%91%E5%8E%9F%E7%94%9F-%E8%81%8A%E8%81%8A%E4%BA%91%E5%8E%9F%E7%94%9F%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%2F</url>
    <content type="text"><![CDATA[云原生这词在这几年突然火了，在很多人还不了解她是什么的时候频频被她刷屏。所以我经常说技术人是一个容易焦虑的群体，每天被一堆新的概念拉着走，扯着学。新语言多，新概念多，新技术多，没什么安全感。对于新概念，我喜欢从三个层次去理解，一个是这技术名词被提出的历史背景，一个是技术名词概念的演化，一个是结合比较主流的话语体系的解读。关于云原生，我也会从这三个方面来解读。 云原生(Cloud Native)的由来云原生的概念最早开始于2010年，在当时 Paul Fremantle 的一篇博客中被提及，他主要将其描述为一种和云一样的系统行为的应用的编写，比如分布式的、松散的、自服务的、持续部署与测试的。当时提出云原生是为了能构建一种符合云计算特性的标准来指导云计算应用的编写。 后来到2013年 Matt Stine在推特上迅速推广云原生概念，并在2015年《迁移到云原生架构》一书中定义了符合云原生架构的特征：12因素、微服务、自服务、基于API协作、扛脆弱性。而由于这本书的推广畅销，这也成了很多人对云原生的早期印象，同时这时云原生也被12要素变成了一个抽象的概念。 CNCF基金会成立及云原生概念的演化2015年由Linux基金会发起了一个 The Cloud Native Computing Foundation（CNCF） 基金组织，CNCF基金会的成立标志着云原生正式进入高速发展轨道，google、Cisco、Docker各大厂纷纷加入，并逐步构建出围绕 Cloud Native 的具体工具，而云原生这个的概念也逐渐变得更具体化。因此，CNCF基金最初对云原生定义是也是深窄的，当时把云原生定位为容器化封装+自动化管理+面向微服务： The CNCF defines “cloud-native” a little more narrowly, to mean using open source software stack to be containerized, where each part of the app is packaged in its own container, dynamically orchestrated so each part is actively scheduled and managed to optimize resource utilization, and microservices-oriented to increase the overall agility and maintainability of applications. 这主要因为CNCF基金会在当时的核心拳头软件就是 k8s，因此在概念定义上主要是围绕着容器编排建立起来的生态。其实这也是为什么我们可以看到 CNCF 定义云原生的时候有时感觉就是再说容器生态。 到了2017年, 云原生应用的提出者之一的Pivotal在其官网上将云原生的定义概况为DevOps、持续交付、微服务、容器这四大特征，这也成了很多人对 Cloud Native的基础印象。 而到了2018年，随着Service Mesh的加入，CNCF对云原生的定义发生了改变，而这也逐渐作为被大家认可的官方定义： Cloud native technologies empower organizations to build and run scalable applications in modern, dynamic environments such as public, private, and hybrid clouds. Containers, service meshes, microservices, immutable infrastructure, and declarative APIs exemplify this approach.These techniques enable loosely coupled systems that are resilient, manageable, and observable. Combined with robust automation, they allow engineers to make high-impact changes frequently and predictably with minimal toil.The Cloud Native Computing Foundation seeks to drive adoption of this paradigm by fostering and sustaining an ecosystem of open source, vendor-neutral projects. We democratize state-of-the-art patterns to make these innovations accessible for everyone. 总结一下就是： （1）基于容器、服务网格、微服务、不可变基础设施和声明式API构建的可弹性扩展的应用； （2）基于自动化技术构建具备高容错性、易管理和便于观察的松耦合系统； （3）构建一个统一的开源云技术生态，能和云厂商提供的服务解耦， 可以看出这一阶段CNCF对云原生的定义加上服务网格和声明式API，同时为这一概念阐述更深一层的意义，也就是建立一个统一中立的开源云生态（至于是否中立嘛这里就不谈了:）。这对云原生的生态定位会是很重要的一点，也算CNCF最初成立的宗旨之一吧，打破云巨头的垄断。 对云原生的解构对一个词的解读，除了看其历史发展背景，还有一种偏向于语言学的方法解读，也就是我们常说的从“字面意思”来理解为何这些理念的集合体。 Cloud Native，从词面上拆解其实就是 Cloud 和 Native，也就是云计算和土著的意思——云计算上的原生居民，即天生具备云计算的亲和力。 那怎么理解“云的原生居民”呢？ 首先从云的角度来理解，云本质可以看作是一种提供稳定计算存储资源的对象，为了实现这点，像虚拟化、弹性扩展、高可用、高容错性、自恢复这些都是云的基本属性，云原生作为一种云计算，这是所具备的第一层含义。 第二层要从 Native 来看，云原生和传统的在云上跑的应用是不同。比如一些基于公有云搭建的应用，是基于传统的SOA架构来搭建的，然后再移植到云上去运行，那么他和云得整合是非常低得。为什么低呢？云作为一种分布式架构，其“土著居民”也应该是基于分布式架构设计出来得，而微服务或者Serverless这种将服务或函数拆分成一个个模块的松耦合系统天然就具备分布式设计得属性。这是Native的第一种表现。 其次云作为一种PaaS服务，这位“土著居民”从出生(设计)到成长(开发)，再到生活(部署)都应该是基于云的理念来实现的，那么就需要一套自动化的开发流程CI/CD来实现。这是Native的第二种表现。 而最后“土著居民”的特点希望做到能在所有的云端都是适应的，不管是各厂商的公有云 像AWS、Azure、阿里云，还是各企业自己搭建的私有云，云原生的应用都能做到无缝的运行和连接。 参考文献 Paul Fremantle’s Blog Cloud-Native: What It Is and How It All Started The Twelve Factor App Migrating to Cloud Native Application Architectures 迁移到云原生应用架构 微软技术文档: 云原生的定义]]></content>
      <categories>
        <category>技术博文</category>
        <category>容器技术</category>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>云原生</tag>
        <tag>CNCF</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes容器开放接口系列:容器运行时接口(CRI)]]></title>
    <url>%2F2020%2F%E6%9E%B6%E6%9E%84%2FKubernetes%E5%AE%B9%E5%99%A8%E5%BC%80%E6%94%BE%E6%8E%A5%E5%8F%A3-CRI%2F</url>
    <content type="text"><![CDATA[CRI 简介在 Kubernetes1.5 之前 Docker 作为第一个容器运行时，Kubelet 通过内嵌 dockershim 操作容器API，但随着越来越多的容器运行时的希望加入kubelet，社区开始有人提出通过加入一个client/server接口来抽象容器运行时。在 v1.6.0 后， Kubernetes 开始默认启用 CRI(容器运行时接口)，下图是容器运行时在 kubernets 中得作用。 图1. kubernets操作数据流图 CRI 架构介绍以下主要介绍Kubernetes1.18版的CRI CRI 为 kubelet 提供一套抽象的容器调度的接口，CRI 主要承接 kubelet 对容器的操作。CRI 得通信协议是 gRPC，当时主要考虑到性能问题。加入 CRI 后 kubelet 得架构如下图所示。 图2. kubelet 架构 Kubelet 现在主要包含两个运行时的模块，一个是 dockershim, 一个是 remote。dockershim 是原来的提供Docker的运行时接口(PS: docker果然还是一等公民🤭:)。remote包对应的就是 CRI 接口，采用gRPC，通过 RemoteRuntime 和 CRI RuntimeService相连：...// createAndStartFakeRemoteRuntime creates and starts fakeremote.RemoteRuntime.// It returns the RemoteRuntime, endpoint on success.// Users should call fakeRuntime.Stop() to cleanup the server.func createAndStartFakeRemoteRuntime(t *testing.T) (*fakeremote.RemoteRuntime, string) &#123; endpoint, err := fakeremote.GenerateEndpoint() require.NoError(t, err) fakeRuntime := fakeremote.NewFakeRemoteRuntime() fakeRuntime.Start(endpoint) return fakeRuntime, endpoint&#125;func createRemoteRuntimeService(endpoint string, t *testing.T) internalapi.RuntimeService &#123; runtimeService, err := NewRemoteRuntimeService(endpoint, defaultConnectionTimeout) require.NoError(t, err) return runtimeService&#125;func TestVersion(t *testing.T) &#123; fakeRuntime, endpoint := createAndStartFakeRemoteRuntime(t) defer fakeRuntime.Stop() r := createRemoteRuntimeService(endpoint, t) version, err := r.Version(apitest.FakeVersion) assert.NoError(t, err) assert.Equal(t, apitest.FakeVersion, version.Version) assert.Equal(t, apitest.FakeRuntimeName, version.RuntimeName)&#125; CRI 容器运行时的三类行为CRI 容器运行时主要描述了三种服务的行为 Sandbox、Container、Image： 图3. CRI容器运行时流程 Sandbox:// PodSandboxManager contains methods for operating on PodSandboxes. The methods// are thread-safe.type PodSandboxManager interface &#123; // RunPodSandbox creates and starts a pod-level sandbox. Runtimes should ensure // the sandbox is in ready state. RunPodSandbox(config *runtimeapi.PodSandboxConfig, runtimeHandler string) (string, error) // StopPodSandbox stops the sandbox. If there are any running containers in the // sandbox, they should be force terminated. StopPodSandbox(podSandboxID string) error // RemovePodSandbox removes the sandbox. If there are running containers in the // sandbox, they should be forcibly removed. RemovePodSandbox(podSandboxID string) error // PodSandboxStatus returns the Status of the PodSandbox. PodSandboxStatus(podSandboxID string) (*runtimeapi.PodSandboxStatus, error) // ListPodSandbox returns a list of Sandbox. ListPodSandbox(filter *runtimeapi.PodSandboxFilter) ([]*runtimeapi.PodSandbox, error) // PortForward prepares a streaming endpoint to forward ports from a PodSandbox, and returns the address. PortForward(*runtimeapi.PortForwardRequest) (*runtimeapi.PortForwardResponse, error)&#125; Container:// ContainerManager contains methods to manipulate containers managed by a// container runtime. The methods are thread-safe.type ContainerManager interface &#123; // CreateContainer creates a new container in specified PodSandbox. CreateContainer(podSandboxID string, config *runtimeapi.ContainerConfig, sandboxConfig *runtimeapi.PodSandboxConfig) (string, error) // StartContainer starts the container. StartContainer(containerID string) error // StopContainer stops a running container with a grace period (i.e., timeout). StopContainer(containerID string, timeout int64) error // RemoveContainer removes the container. RemoveContainer(containerID string) error // ListContainers lists all containers by filters. ListContainers(filter *runtimeapi.ContainerFilter) ([]*runtimeapi.Container, error) // ContainerStatus returns the status of the container. ContainerStatus(containerID string) (*runtimeapi.ContainerStatus, error) // UpdateContainerResources updates the cgroup resources for the container. UpdateContainerResources(containerID string, resources *runtimeapi.LinuxContainerResources) error // ExecSync executes a command in the container, and returns the stdout output. // If command exits with a non-zero exit code, an error is returned. ExecSync(containerID string, cmd []string, timeout time.Duration) (stdout []byte, stderr []byte, err error) // Exec prepares a streaming endpoint to execute a command in the container, and returns the address. Exec(*runtimeapi.ExecRequest) (*runtimeapi.ExecResponse, error) // Attach prepares a streaming endpoint to attach to a running container, and returns the address. Attach(req *runtimeapi.AttachRequest) (*runtimeapi.AttachResponse, error) // ReopenContainerLog asks runtime to reopen the stdout/stderr log file // for the container. If it returns error, new container log file MUST NOT // be created. ReopenContainerLog(ContainerID string) error&#125; Image:// ImageManagerService interface should be implemented by a container image// manager.// The methods should be thread-safe.type ImageManagerService interface &#123; // ListImages lists the existing images. ListImages(filter *runtimeapi.ImageFilter) ([]*runtimeapi.Image, error) // ImageStatus returns the status of the image. ImageStatus(image *runtimeapi.ImageSpec) (*runtimeapi.Image, error) // PullImage pulls an image with the authentication config. PullImage(image *runtimeapi.ImageSpec, auth *runtimeapi.AuthConfig, podSandboxConfig *runtimeapi.PodSandboxConfig) (string, error) // RemoveImage removes the image. RemoveImage(image *runtimeapi.ImageSpec) error // ImageFsInfo returns information of the filesystem that is used to store images. ImageFsInfo() ([]*runtimeapi.FilesystemUsage, error)&#125; CRI 容器生命周期操作流程kubelet创建一个Pod主要可以拆解成： 调用RunPodSandox创建一个pod沙盒 调用CreateContainer创建一个容器 调用StartContainer启动一个容器 图4. 容器生命周期操作流程 CRI Streaming接口streaming接口主要是用于执行 exec 命令，exec 命令主要用于 attach 容器进行交互，通过流式接口的可以节省资源，提高连接的可靠性。kubelet 调用 Exec() 接口发给 RuntimeService ，RuntimeService 返回一个 url 给到 apiserver， 让 apiserver 跟 Stream Server 直接建立连接，获取流式数据。 由于绕过了kubelet，因此Stream Server 也提高连接的可靠性CRI 中 Exec() 接口：// ContainerManager contains methods to manipulate containers managed by a// container runtime. The methods are thread-safe.type ContainerManager interface &#123; ... // Exec prepares a streaming endpoint to execute a command in the container, and returns the address. Exec(*runtimeapi.ExecRequest) (*runtimeapi.ExecResponse, error) // Attach prepares a streaming endpoint to attach to a running container, and returns the address. Attach(req *runtimeapi.AttachRequest) (*runtimeapi.AttachResponse, error) ...&#125; 图5. streaming数据流 CRI proto接口定义CRI 是一个为kubelet提供的一个广泛的容器运行时的无需编译的接口插件。 CRI 包含了一个 protocol buffers 和 gRPC API。kubernetes1.18的 CRI 代码路径：kubernetes/staging/src/k8s.io/cri-api/。CRI中定义了容器和镜像的服务的接口，因为容器运行时与镜像的生命周期是彼此隔离的，因此需要定义两个服务 RuntimeService 和 ImageService。 RuntimeService的proto接口定义文件// Runtime service defines the public APIs for remote container runtimesservice RuntimeService &#123; // Version returns the runtime name, runtime version, and runtime API version. rpc Version(VersionRequest) returns (VersionResponse) &#123;&#125; // RunPodSandbox creates and starts a pod-level sandbox. Runtimes must ensure // the sandbox is in the ready state on success. rpc RunPodSandbox(RunPodSandboxRequest) returns (RunPodSandboxResponse) &#123;&#125; // StopPodSandbox stops any running process that is part of the sandbox and // reclaims network resources (e.g., IP addresses) allocated to the sandbox. // If there are any running containers in the sandbox, they must be forcibly // terminated. // This call is idempotent, and must not return an error if all relevant // resources have already been reclaimed. kubelet will call StopPodSandbox // at least once before calling RemovePodSandbox. It will also attempt to // reclaim resources eagerly, as soon as a sandbox is not needed. Hence, // multiple StopPodSandbox calls are expected. rpc StopPodSandbox(StopPodSandboxRequest) returns (StopPodSandboxResponse) &#123;&#125; // RemovePodSandbox removes the sandbox. If there are any running containers // in the sandbox, they must be forcibly terminated and removed. // This call is idempotent, and must not return an error if the sandbox has // already been removed. rpc RemovePodSandbox(RemovePodSandboxRequest) returns (RemovePodSandboxResponse) &#123;&#125; // PodSandboxStatus returns the status of the PodSandbox. If the PodSandbox is not // present, returns an error. rpc PodSandboxStatus(PodSandboxStatusRequest) returns (PodSandboxStatusResponse) &#123;&#125; // ListPodSandbox returns a list of PodSandboxes. rpc ListPodSandbox(ListPodSandboxRequest) returns (ListPodSandboxResponse) &#123;&#125; // CreateContainer creates a new container in specified PodSandbox rpc CreateContainer(CreateContainerRequest) returns (CreateContainerResponse) &#123;&#125; // StartContainer starts the container. rpc StartContainer(StartContainerRequest) returns (StartContainerResponse) &#123;&#125; // StopContainer stops a running container with a grace period (i.e., timeout). // This call is idempotent, and must not return an error if the container has // already been stopped. // TODO: what must the runtime do after the grace period is reached? rpc StopContainer(StopContainerRequest) returns (StopContainerResponse) &#123;&#125; // RemoveContainer removes the container. If the container is running, the // container must be forcibly removed. // This call is idempotent, and must not return an error if the container has // already been removed. rpc RemoveContainer(RemoveContainerRequest) returns (RemoveContainerResponse) &#123;&#125; // ListContainers lists all containers by filters. rpc ListContainers(ListContainersRequest) returns (ListContainersResponse) &#123;&#125; // ContainerStatus returns status of the container. If the container is not // present, returns an error. rpc ContainerStatus(ContainerStatusRequest) returns (ContainerStatusResponse) &#123;&#125; // UpdateContainerResources updates ContainerConfig of the container. rpc UpdateContainerResources(UpdateContainerResourcesRequest) returns (UpdateContainerResourcesResponse) &#123;&#125; // ReopenContainerLog asks runtime to reopen the stdout/stderr log file // for the container. This is often called after the log file has been // rotated. If the container is not running, container runtime can choose // to either create a new log file and return nil, or return an error. // Once it returns error, new container log file MUST NOT be created. rpc ReopenContainerLog(ReopenContainerLogRequest) returns (ReopenContainerLogResponse) &#123;&#125; // ExecSync runs a command in a container synchronously. rpc ExecSync(ExecSyncRequest) returns (ExecSyncResponse) &#123;&#125; // Exec prepares a streaming endpoint to execute a command in the container. rpc Exec(ExecRequest) returns (ExecResponse) &#123;&#125; // Attach prepares a streaming endpoint to attach to a running container. rpc Attach(AttachRequest) returns (AttachResponse) &#123;&#125; // PortForward prepares a streaming endpoint to forward ports from a PodSandbox. rpc PortForward(PortForwardRequest) returns (PortForwardResponse) &#123;&#125; // ContainerStats returns stats of the container. If the container does not // exist, the call returns an error. rpc ContainerStats(ContainerStatsRequest) returns (ContainerStatsResponse) &#123;&#125; // ListContainerStats returns stats of all running containers. rpc ListContainerStats(ListContainerStatsRequest) returns (ListContainerStatsResponse) &#123;&#125; // UpdateRuntimeConfig updates the runtime configuration based on the given request. rpc UpdateRuntimeConfig(UpdateRuntimeConfigRequest) returns (UpdateRuntimeConfigResponse) &#123;&#125; // Status returns the status of the runtime. rpc Status(StatusRequest) returns (StatusResponse) &#123;&#125;&#125; ImageService 的 proto 接口定义文件：// ImageService defines the public APIs for managing images.service ImageService &#123; // ListImages lists existing images. rpc ListImages(ListImagesRequest) returns (ListImagesResponse) &#123;&#125; // ImageStatus returns the status of the image. If the image is not // present, returns a response with ImageStatusResponse.Image set to // nil. rpc ImageStatus(ImageStatusRequest) returns (ImageStatusResponse) &#123;&#125; // PullImage pulls an image with authentication config. rpc PullImage(PullImageRequest) returns (PullImageResponse) &#123;&#125; // RemoveImage removes the image. // This call is idempotent, and must not return an error if the image has // already been removed. rpc RemoveImage(RemoveImageRequest) returns (RemoveImageResponse) &#123;&#125; // ImageFSInfo returns information of the filesystem that is used to store images. rpc ImageFsInfo(ImageFsInfoRequest) returns (ImageFsInfoResponse) &#123;&#125;&#125; CRI工具介绍 CRI命令工具:crictl，帮助用户和开发者调试容器问题 CRI测试工具：critest，用于验证CRI接口的测试工具，验证是否满足Kubelet要求。 crictl 安装：VERSION="v1.17.0"wget https://github.com/kubernetes-sigs/cri-tools/releases/download/$VERSION/crictl-$VERSION-linux-amd64.tar.gzsudo tar zxvf crictl-$VERSION-linux-amd64.tar.gz -C /usr/local/binrm -f crictl-$VERSION-linux-amd64.tar.gz critest 安装：VERSION="v1.17.0"wget https://github.com/kubernetes-sigs/cri-tools/releases/download/$VERSION/critest-$VERSION-linux-amd64.tar.gzsudo tar zxvf critest-$VERSION-linux-amd64.tar.gz -C /usr/local/binrm -f critest-$VERSION-linux-amd64.tar.gz 参考文献 Introducing Container Runtime Interface (CRI) in Kubernetes CNCF x Alibaba 云原生技术公开课 cri-tools]]></content>
      <categories>
        <category>技术博文</category>
        <category>容器技术</category>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>cri</tag>
        <tag>Kubernetes</tag>
        <tag>接口</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[技术规范(2): 后端技术开发规范]]></title>
    <url>%2F2020%2F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%2F%E6%8A%80%E6%9C%AF%E8%A7%84%E8%8C%83-2-%E5%90%8E%E7%AB%AF%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[Python 开发规范 优美胜于丑陋明了胜于晦涩简洁胜于复杂复杂胜于凌乱扁平胜于嵌套间隔胜于紧凑可读性很重要即便假借特例的实用性之名，也不可违背这些规则 上面是 Python 之禅，很好地体现了 Python 语言所传达的编程理念。 PEP8 标准PEP8 规范：https://www.python.org/dev/peps/pep-0008/ 标准： 缩进：每一级缩进使用4个空格。 续行应该与其包裹元素对齐，要么使用圆括号、方括号和花括号内的隐式行连接来垂直对齐，要么使用挂行缩进对齐3。当使用挂行缩进时，应该考虑到第一行不应该有参数，以及使用缩进以区分自己是续行。 # 与左括号对齐foo = long_function_name(var_one, var_two, var_three, var_four)# 用更多的缩进来与其他行区分# 挂行缩进应该再换一行def long_function_name( var_one, var_two, var_three, var_four): print(var_one) 在多行结构中的大括号/中括号/小括号的右括号可以与内容对齐单独起一行作为最后一行的第一个字符。 my_list = [ 1, 2, 3, 4, 5, 6, ]result = some_function_that_takes_arguments( 'a', 'b', 'c', 'd', 'e', 'f', ) 所有行限制的最大字符数为79。 顶层函数和类的定义，前后用两个空行隔开。类里的方法定义用一个空行隔开。 import导入通常在分开的行。 推荐: import os import sys不推荐: import sys, os import顺序:标准库导入相关第三方库导入本地应用/库特定导入（在每类导入之间加入空行分割） 像 __all__ , __author__ , __version__ 等这样的模块级“呆名“（也就是名字里有两个前缀下划线和两个后缀下划线），应该放在文档字符串的后面，以及除 from __future__ 之外的import表达式前面。Python要求将来在模块中的导入，必须出现在除文档字符串之外的其他代码之前。 """This is the example module.This module does stuff."""from __future__ import barry_as_FLUFL__all__ = ['a', 'b', 'c']__version__ = '0.1'__author__ = 'Cardinal Biggles'import osimport sys 避免使用无关的空格，避免在尾部添加空格。因为尾部的空格通常都看不见，会产生混乱。 总是在二元运算符两边加一个空格。 如果使用具有不同优先级的运算符，请考虑在具有最低优先级的运算符周围添加空格。 i = i + 1submitted += 1x = x*2 - 1hypot2 = x*x + y*yc = (a+b) * (a-b) 与代码相矛盾的注释比没有注释还糟，当代码更改时，优先更新对应的注释。 块注释通常适用于跟随它们的某些（或全部）代码，并缩进到与代码相同的级别。块注释的每一行开头使用一个#和一个空格（除非块注释内部缩进文本）。块注释内部的段落通过只有一个#的空行分隔。 要为所有的公共模块，函数，类以及方法编写文档说明。 def complex(real=0.0, imag=0.0): """Form a complex number. Keyword arguments: real -- the real part (default 0.0) imag -- the imaginary part (default 0.0) """ ... 命名规范 （1）模块应该用简短全小写的名字，如果为了提升可读性，下划线也是可以用的。Python包名也应该使用简短全小写的名字，但不建议用下划线。（2）类名一般使用首字母大写的约定。在接口被文档化并且主要被用于调用的情况下，可以使用函数的命名风格代替。注意，对于内置的变量命名有一个单独的约定：大部分内置变量是单个单词（或者两个单词连接在一起），首字母大写的命名法只用于异常名或者内部的常量。（3）因为异常一般都是类，所有类的命名方法在这里也适用。然而，你需要在异常名后面加上“Error”后缀。（4）函数名应该小写，如果想提高可读性可以用下划线分隔。（5）全局变量名和函数命名规则一样，值得注意的是通过 from M import * 导入的模块应该使用all机制去防止内部的接口对外暴露，或者使用在全局变量前加下划线的方式。（6）如果函数的参数名和已有的关键词冲突，在最后加单一下划线比缩写或随意拼写更好。（7）常量通常定义在模块级，通过下划线分隔的全大写字母命名。例如： MAX_OVERFLOW 和 TOTAL。 从Exception继承异常，而不是BaseException。直接继承BaseException的异常适用于几乎不用来捕捉的异常。 当捕获到异常时，如果可以的话写上具体的异常名，而不是只用一个except，如果只有一个except: 块将会捕获到SystemExit和KeyboardInterrupt异常，这样会很难通过ctrl+C中断程序，而且会掩盖掉其他问题。如果你想捕获所有指示程序出错的异常，使用 except Exception。正确的是： try: import platform_specific_moduleexcept ImportError: platform_specific_module = None 无论何时获取和释放资源，都应该通过单独的函数或方法调用上下文管理器，比如使用with 表达式来确保这个资源使用完后被清理干。 返回的语句保持一致。函数中的返回语句都应该返回一个表达式，或者都不返回。如果一个返回语句需要返回一个表达式，那么在没有值可以返回的情况下，需要用 return None 显式指明。def foo(x): if x &gt;= 0: return math.sqrt(x) else: return Nonedef bar(x): if x &lt; 0: return None return math.sqrt(x) 工具具体的可以使用Autopep8工具协助排版。 安装autopep8：pip install autopep8 用法：autopep8 [参数] [Python文件]核心参数: -d, --diff print the diff for the fixed source -i, --in-place make changes to files in place --global-config filename path to a global pep8 config file; if this file does not exist then this is ignored (default: ~/.config/pep8) --ignore-local-config don't look for and apply local config files; if not passed, defaults are updated with any config files in the project's root directory -r, --recursive run recursively over directories; must be used with --in-place or --diff -j n, --jobs n number of parallel jobs; match CPU count if value is less than 1 -p n, --pep8-passes n maximum number of additional pep8 passes (default: infinite) -a, --aggressive enable non-whitespace changes; multiple -a result in more aggressive changes --experimental enable experimental fixes --exclude globs exclude file/directory names that match these comma- separated globs --list-fixes list codes for fixes; used by --ignore and --select --ignore errors do not fix these errors/warnings (default: E226,E24,W50,W690) --select errors fix only these errors/warnings (e.g. E4,W) --max-line-length n set maximum allowed line length (default: 79) --line-range line line, --range line line only fix errors found within this inclusive range of line numbers (e.g. 1 99); line numbers are indexed at 1 --hang-closing hang-closing option passed to pycodestyle --exit-code change to behavior of exit code. default behavior of return value, 0 is no differences, 1 is error exit. return 2 when add this option. 2 is exists differences. --in-place 会直接将结果保存到源文件中，如果不包含--in-place选项，则会将autopep8格式化以后的代码直接输出到控制台。 Go 开发规范Go 语言规范Go 代码审核规范官方地址：https://github.com/golang/go/wiki/CodeReviewComments 所有代码在发布前均使用gofmt进行修正。 所有的注释都应该是一个完整的句子。句子应该以主语开头，句号结尾。 声明空的数组分片，避免分配内存空间。因为有些时候，可能你从没向这个数组分片里面append元素 // 推荐这样var t []string// 而不是这样t := []string&#123;&#125;` 大多数使用 Context 的函数都应该接受 Context 作为函数的第一个参数。比如这样： func F(ctx context.Context, /* other arguments */) &#123;&#125; 不要将 Context 成员添加到某个 struct 类型中；而是将 ctx 参数添加到该类型的方法上。一个例外情况是当前方法签名必须与标准库或第三方库中的接口方法匹配。不要在函数签名中创建自定义 Context 类型或使用除了 Context 以外的接口。 为避免意外的别名，从另一个包复制 struct 时要小心。例如，bytes.Buffer 类型包含一个 []byte 的 slice，并且作为短字符串的优化，slice 可以引用一个短字节数组。如果复制一个 Buffer，副本中的 slice 可能会对原始数组进行别名操作，从而导致后续方法调用产生令人惊讶的效果。通常，如果 T 类型的方法与其指针类型 *T 相关联，请不要复制 T 类型的值。 不要使用包math/rand来生成密钥，即使是一次性密钥。在没有种子（seed）的情况下，生成器是完全可以被预测的。使用time.Nanoseconds()作为种子值，熵只有几位。请使用crypto/rand的 Reader 作为替代，如果你倾向于使用文本，请输出成十六进制或 base64 编码： import ( "crypto/rand" // "encoding/base64" // "encoding/hex" "fmt")func Key() string &#123; buf := make([]byte, 16) _, err := rand.Read(buf) if err != nil &#123; panic(err) // out of randomness, should never happen &#125; return fmt.Sprintf("%x", buf) // or hex.EncodeToString(buf) // or base64.StdEncoding.EncodeToString(buf)&#125; Go提供两种注释风格，C的块注释风格/**/，C++的行注释风格//。包注释必须出现在 package 声明的临近位置，无空行。所有的顶级导出的名称都应该有 doc 注释，重要的未导出类型或函数声明也应如此。每个public函数都应该有注释，注释句子应该以该函数名开头，如： // Compile parses a regular expression and returns, if successful,// a Regexp that can be used to match against text.func Compile(str string) (*Regexp, error) &#123;&#125; 尽量不要使用panic处理错误。函数应该设计成多返回值，其中包括返回相应的error类型。 错误信息字符串不应大写（除非以专有名词或首字母缩略词开头）或以标点符号结尾，因为它们通常是在其他上下文后打印的。即使用fmt.Errorf(&quot;something bad&quot;)而不要使用fmt.Errorf(&quot;Something bad&quot;)，因此log.Printf(&quot;Reading %s: %v&quot;, filename, err)的格式中将不会出现额外的大写字母。否则这将不适用于日志记录，因为它是隐式的面向行，而不是在其他消息中组合。 添加新包时，请包含预期用法的示例：可运行的示例，或是演示完整调用链的简单测试。Example函数一般放在包下的_test.go文件中，比如： package stringutil_testimport ( "fmt" "github.com/golang/example/stringutil")func ExampleReverse() &#123; fmt.Println(stringutil.Reverse("hello")) // Output: olleh&#125; 这种写法的好处是使用 go test -v，如果和注释种的结果一致只会返回PASS，如果不一定打印。 当你生成 goroutines 时，要清楚它们何时或是否会退出。请尽量让并发代码足够简单，从而更容易地确认 goroutine 的生命周期。 不要使用 _ 变量丢弃 error 如果函数返回 error，请检查它以确保函数成功。处理 error，返回 error，或者在真正特殊的情况下使用 panic。 包导入按组进行组织，组与组之间有空行。标准库包始终位于第一组中。 部分包由于循环依赖，不能作为测试包的一部分进行测试时，可以以.形式导入它们： package foo_testimport ( "bar/testutil" // also imports "foo" . "foo") 将正常的代码路径保持在最小的缩进处，优先处理错误并缩进，如下： if err != nil &#123; // error handling return // or continue, etc.&#125;// normal code 名称中的单词是首字母或首字母缩略词需要具有相同的大小写规则，例如，“URL” 应显示为 “URL” 或 “url” （如 “urlPony” 或 “URLPony” ），而不是 “Url”。 Go 接口通常属于使用 interface 类型值的包，而不是实现这些值的包。实现包应返回具体（通常是指针或结构）类型。案例：这里有一个生产者的包和消费者的包，他们之间有一个Thinger做接口交互。消费者包代码： package consumer // consumer.gotype Thinger interface &#123; Thing() bool &#125;func Foo(t Thinger) string &#123; … &#125; 正确的生产者应该这样实现：package producertype Thinger struct&#123; … &#125;func (t Thinger) Thing() bool &#123; … &#125;func NewThinger() Thinger &#123; return Thinger&#123; … &#125; &#125;// 而不是在这里再声明一个接口，这样是没必要的// type Thinger interface &#123; Thing() bool &#125;// type defaultThinger struct&#123; … &#125;// func (t defaultThinger) Thing() bool &#123; … &#125;// func NewThinger() Thinger &#123; return defaultThinger&#123; … &#125; &#125; 返回参数直接写类型就可以了，但如果函数返回两个或三个相同类型的参数，或者如果从上下文中不清楚返回结果的含义，那么在某些上下文中添加命名可能很有用。比如： // 应该这样func (n *Node) Parent1() *Nodefunc (n *Node) Parent2() (*Node, error)// 不要这样func (n *Node) Parent1() (node *Node)func (n *Node) Parent2() (node *Node, err error)// 多值的时候，应该这样func (f *Foo) Location() (lat, long float64, err error)// 不要这样func (f *Foo) Location() (float64, float64, error) 包中名称的所有引用都将使用包名完成，因此您可以从标识符中省略该名称。例如，如果有一个 chubby 包，你不应该定义类型名称为 ChubbyFile ，否则使用者将写为 chubby.ChubbyFile。而是应该命名类型名称为 File，使用时将写为 chubby.File。 方法接收者的名称应该反映其身份；通常，其类型的一个或两个字母缩写就足够了（例如“client”的“c”或“cl”）。不要使用通用名称，例如“me”，“this”或“self”，这是面向对象语言的典型标识符，它们更强调方法而不是函数。名称不必像方法论证那样具有描述性，因为它的作用是显而易见的，不起任何记录目的。名称可以非常短，因为它几乎出现在每种类型的每个方法的每一行上。 接收器什么时候使用值或者指针：（1）小的不变结构或基本类型可以用值接收器。这样可以提高效率。（2）在你不确定是使用值还是指针作为接收器时，请用指针接收器。（3）如果该方法需要改变接收器的值，则接收器必须是指针。（4）如果接收器是 map，func或 chan，则不要使用指向它们的指针。如果接收器是 slice 并且该方法不重新切片或不重新分配切片，则不要使用指向它的指针。 Go 语言规范工具go 的官方工具链做得很好，可以直接使用gofmt和golint检查代码规范。 安装：go get github.com/golang/lintgo install github.com/golang/lint 用法：golint &lt;文件/文件目录/包名&gt;]]></content>
      <categories>
        <category>技术博文</category>
        <category>技术手册</category>
      </categories>
      <tags>
        <tag>技术规范</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[技术规范(1): 前端技术开发规范]]></title>
    <url>%2F2020%2F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%2F%E6%8A%80%E6%9C%AF%E8%A7%84%E8%8C%83-1-%E5%89%8D%E7%AB%AF%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[ESLint工具介绍ESLint最初是由Nicholas C. Zakas 于2013年6月创建的开源项目。它的目标是提供一个插件化的javascript代码检测工具。 ESLint 配置规则：https://cn.eslint.org/docs/rules/ 命名规范项目命名全部采用小写方式， 以下划线分隔。例：my_project_name 目录命名参照项目命名规则； 有复数结构时，要采用复数命名法。例：scripts, styles, images, data_models JS文件命名参照项目命名规则。 例：account_model.js CSS, SCSS文件命名参照项目命名规则。 例：retina_sprites.scss HTML文件命名参照项目命名规则。 例：error_report.html Vue项目规范vue文件基本结构vue文件基本结构：&lt;template&gt;&lt;div&gt; &lt;!--必须在div中编写页面--&gt;&lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; components : &#123; &#125;, data () &#123; return &#123; &#125; &#125;, methods: &#123; &#125;, mounted() &#123; &#125;&#125;&lt;/script&gt;&lt;!--声明语言，并且添加scoped--&gt;&lt;style lang="less" scoped&gt;&lt;/style&gt; //组件的 data 必须是一个函数。 //当在组件中使用 data 属性的时候 (除了 new Vue 外的任何地方)，它的值必须是返回一个对象的函数。 vue文件方法声明顺序vue文件方法声明顺序（如不需要一些属性可不填） - components - props - data - created - mounted - activited - update - beforeRouteUpdate - metods - filter - computed - watch 不在 mounted、created 之类的方法写逻辑，取 ajax 数据， 定义变量使用let ,定义常量使用const 使用export ，import 模块化 使用console.log() 来debugger时， 使用完及时删除 method 自定义方法命名 动宾短语（good：jumpPage、openCarInfoDialog）（bad：go、nextPage、show、open、login） ajax 方法以 get、post 开头，以 data 结尾（good：getListData、postFormData）（bad：takeData、confirmData、getList、postForm） 事件方法以 on 开头（onTypeChange、onUsernameInput） init、refresh 单词除外 尽量使用常用单词开头（set、get、open、close、jump） 组件组件注册方式：1）公共组件全局注册 2）其余组件局部注册 组件的每一个属性单独使用一个 props，并且使用函数或是原始类型的值。&lt;!-- 推荐 --&gt;&lt;range-slider :values="[10, 20]" min="0" max="100" step="5" :on-slide="updateInputs" :on-end="updateResults"&gt;&lt;/range-slider&gt;&lt;!-- 避免 --&gt;&lt;range-slider :config="complexConfigObject"&gt;&lt;/range-slider&gt; 避免 this.$parent 进行组件间通信用props代替 ，谨慎使用 this.$refs，尽量保持组件的相对独立。]]></content>
      <categories>
        <category>技术博文</category>
        <category>技术手册</category>
      </categories>
      <tags>
        <tag>技术规范</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[云原生技术开发手册(新坑~待填)]]></title>
    <url>%2F2020%2F%E6%9E%B6%E6%9E%84%2F%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91%E6%89%8B%E5%86%8C%2F</url>
    <content type="text"><![CDATA[项目地址：https://github.com/shikanon/cloudnative-technical-manual 有兴趣的可以给个star，不过是新坑，不确定什么时候能填完。 🙉🙉🙉🙉 章节目录 基础篇 基本概念 什么是云原生 后端软件架构的发展演变 云原生发展历史 云原生开发工程师的职责和基础技能 云原生的技术范畴 云原生开发工程师的工作职责 云原生应用开发流程 软件开发规范 代码开发规范 前端开发规范 后端开发规范 数据库设计规范 代码管理规范 代码分支管理规范 代码提交规范 CI/CD的使用规范 代码审计规范 如何做好code review 代码审计目标和原则 代码安全性审计 运维规范及注意事项 进阶篇 云原生的基石：容器与虚拟化技术 容器编排：Kubernetes Kubernetes架构 Kubernetes安装 Kubernetes资源对象 Pod和容器设计模式 无状态应用编排Deployment 工作任务Job和DaemonSet 有状态应用编排StatefulSet 应用配置config 存储资源Volume Kuberntes网络及策略控制 Kubernetes开放接口 容器运行时接口CRI 容器网络接口CNI 容器存储接口CSI Kubernetes集群故障排查 常见的问题排查命令 Pod异常排查 网络异常排查 持久化异常排查 持续集成与持续交付 代码管理: gitlab CI/CD: Jenkins 和 git runner 镜像管理: harbor 服务网格: Istio 什么是服务网格 Istio架构 Pilot服务发现 Gateway网关 限流与熔断 灰度发布 分布式追踪 监控系统：Prometheus Prometheus架构 搭建Prometheus系统 监控应用程序 机器学习工具集Kubeflow kubeflow核心组件 TFJob 模型部署：TF-Serving 任务编排：Argo 搭建kubeflow系统 实战篇 向云原生迁移的第一个项目 事前准备工作 项目预研与集群规划 准备集群环境 容器化改造 搭建自有镜像仓库 编写资源配置文件 构建持续集成环境]]></content>
      <categories>
        <category>技术博文</category>
        <category>技术手册</category>
      </categories>
      <tags>
        <tag>云原生</tag>
        <tag>kubernetes</tag>
        <tag>技术手册</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过建立mock服务器减少前后端联调]]></title>
    <url>%2F2020%2F%E7%AE%A1%E7%90%86%2F%E9%80%9A%E8%BF%87%E5%BB%BA%E7%AB%8Bmock%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%87%8F%E5%B0%91%E5%89%8D%E5%90%8E%E7%AB%AF%E8%81%94%E8%B0%83%2F</url>
    <content type="text"><![CDATA[引言由于多端的出现，前后端分离的技术架构已经是一个不可逆的趋势了，但在web的流程管理上发现经常出现团队管理总是需要花费大量的时间进行“前后端联调”这样一个环节，这让人感觉是十分低效的。本来前后端技术分离就是为了让前端用熟悉的前端技术迅速开发好前端，后端开发好后端，然后根据实现定义的接口直接缝合起来就行了，就像两个零部件，直接将螺丝扭紧组装起来。但在实践中经常发现，事先协商好的数据接口由于后端人员对业务理解的不足在前期设计阶段有遗漏，在开发过程中对接口进行了修改，导致前端开发人员每次都需要再修改接口，导致出现了一段在开发阶段比较长时间的“前后端联调”。 解决方案但是，很明显这种情况是需要避免的，那么有什么比较好的方法呢？核心还是出在架构设计初期，在架构设计初期我们在设计系统架构和接口的时候，建立一套能提供给前端的mock接口。我这里写了一个FastAPI-Project-Template的项目尝试去做这件事情，利用fastapi自带的swagger UI功能，在开发设计初期为前端提供可用于调试的mock接口，如果后端接口有改动只需要修改接口即可，这样就能让前后端联调的工作放到开发前面。 http code http message200 OK201 Created202 Accepted203 Non-Authoritative Information204 No Content205 Reset Content206 Partial Content300 Multiple Choices301 Moved Permanently302 Found303 See Other304 Not Modified305 Use Proxy306 (Unused)307 Temporary Redirect400 Bad Request401 Unauthorized402 Payment Required403 Forbidden404 Not Found405 Method Not Allowed406 Not Acceptable407 Proxy Authentication Required408 Request Timeout409 Conflict410 Gone411 Length Required412 Precondition Failed413 Request Entity Too Large414 Request-URI Too Long415 Unsupported Media Type416 Requested Range Not Satisfiable417 Expectation Failed450 Parameter Requried451 Method Connect Exception500 Internal Server Error501 Not Implemented502 Bad Gateway503 Service Unavailable504 Gateway Timeout505 HTTP Version Not Supported]]></content>
      <categories>
        <category>管理</category>
        <category>技术管理</category>
      </categories>
      <tags>
        <tag>企业管理</tag>
        <tag>mock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vscode小技巧(一)]]></title>
    <url>%2F2020%2F%E8%BF%90%E7%BB%B4%2Fvscode%E5%B0%8F%E6%8A%80%E5%B7%A7-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[文件远程同步通过sftp实现远程文件同步： 安装liximomo的SFTP 配置sftp.json配置文件 sftp.json配置:&#123; "name": "My Server", #名字 "host": "xxx.xx.xx.xx", #远程host地址 "protocol": "sftp", #协议类型 "port": 22, # 远程端口 "username": "shikanon", # 用户名，密码用password, "privateKeyPath": "D:\\keeweb\\xxx.xx.xx.xx", "remotePath": "/home/shikanon/software/bd", #远程的路径(绝对路径) "uploadOnSave": false, # 每次保存都上传 "watcher": &#123; # 什么时候上传，当uploadOnSave为false起作用 "files": "glob", "autoUpload": true, "autoDelete": true &#125;&#125; 详细说明见wiki 调试环境配置调试环境分为两种，一种launch，一种attach。 launch 表示通过直接运行命令行对程序进行调试，即vscode独立运行调试进程 attach 表示通过嵌入对应的开发工具进行调试启动，这种模式一般需要再另外启动对应的DevTools。 详细说明见wiki Python调试环境配置"configurations": [ &#123; "name": "Python: 本地", "type": "python", "request": "launch", "program": "D:\\Program Files (x86)\\Python36-32\\Scripts\\uvicorn.exe", # 程序绝对路径 "args": [ # 程序参数 "run:app", "--reload" ], "cwd": "$&#123;workspaceFolder&#125;" #当前目录 &#125; ]]]></content>
      <categories>
        <category>技术博文</category>
        <category>系统运维</category>
      </categories>
      <tags>
        <tag>快捷键</tag>
        <tag>vscode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[奥比技术中台规划]]></title>
    <url>%2F2019%2F%E9%9A%90%E8%97%8F%2F%E5%A5%A5%E6%AF%94%E4%B8%AD%E5%8F%B0%E6%88%98%E7%95%A5%E8%A7%84%E5%88%92%2F</url>
    <content type="text"><![CDATA[IoT云平台技术中台规划]]></content>
      <categories>
        <category>管理</category>
        <category>企业战略</category>
      </categories>
      <tags>
        <tag>企业战略</tag>
        <tag>中台</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubeflow系列(三)：模型即服务，关于tensorflow serving的使用]]></title>
    <url>%2F2019%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2F%E6%A8%A1%E5%9E%8B%E4%BD%9C%E4%B8%BA%E6%9C%8D%E5%8A%A1tf-serving%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[kubeflow 中采用了 tensorflow serving 作为官方的tensorflow模型接口， TensorFlow Serving是GOOGLE开源的一个服务系统，适用于部署机器学习模型，灵活、性能高、可用于生产环境。 TensorFlow Serving可以轻松部署新算法和实验，同时保持相同的服务器架构和API。 Tensorflow Serving 直接加载模型即可生成接口，不过 serving 支持的模型只有 SaveModel，因此这里主要介绍 SaveModel。 SaveModelSaveModel 是一种专门用于tf模型 拓扑结构(topology) 和 权重(weights) ，基于 SaveModel 不需要运行原始的模型构建代码，这样非常利于共享或部署模型，因此一般模型部署都用 SaveModel。 拓扑结构(Topology): 这是一个描述模型结构的文件（例如它使用的了哪些操作）。它包含对存储在外部的模型权重的引用。 权重(Weights): 这些是以有效格式存储给定模型权重的二进制文件。它们通常存储在与拓扑结构相同的文件夹中。 SaveModel文件目录:assets saved_model.pb variables 查看MetaGraphDefs和SignatureDefs:saved_model_cli show --dir &lt;SaveModel路径&gt; --all 生成模型需要模型的MetaGraphDefs和SignatureDefs，MetaGraphDefs就是我们常见的meta graph，其中包含了四种主要的信息： MetaInfoDef: 存放了一些元信息，例如版本和其他用户信息； GraphDef: 描述的Graph中序列化得到的图，由Protocol Buffer组成； SaverDef: 图的Saver信息，例如最多同时保存的checkpoint数量，需要保存的Tensor名字等，不保存Tensor中的实际内容； CollectionDef: 任何需要特殊注意的python对象，需要特殊的标注以方便import_meta_graph后取回，如”prediction”。 SignatureDefs则是模型的签名定义，定义了 输入 和 输出函数`。 SignatureDefs SignatureDef 定义了 TensorFlow graph 计算的签名，定义了 输入 和 输出函数，SignatureDef 结构 ： inputs as a map of string to TensorInfo. outputs as a map of string to TensorInfo. method_name (which corresponds to a supported method name in the loading tool/system). Classification SignatureDef例子 必须要一个输入 Tensors inputs 和两个输出Tensors: classes和 scoressignature_def: &#123; key : "my_classification_signature" value: &#123; inputs: &#123; key : "inputs" value: &#123; name: "tf_example:0" dtype: DT_STRING tensor_shape: ... &#125; &#125; outputs: &#123; key : "classes" value: &#123; name: "index_to_string:0" dtype: DT_STRING tensor_shape: ... &#125; &#125; outputs: &#123; key : "scores" value: &#123; name: "TopKV2:0" dtype: DT_FLOAT tensor_shape: ... &#125; &#125; method_name: "tensorflow/serving/classify" &#125;&#125; Predict SignatureDef例子 signature_def: &#123; key : "my_prediction_signature" value: &#123; inputs: &#123; key : "images" value: &#123; name: "x:0" dtype: ... tensor_shape: ... &#125; &#125; outputs: &#123; key : "scores" value: &#123; name: "y:0" dtype: ... tensor_shape: ... &#125; &#125; method_name: "tensorflow/serving/predict" &#125;&#125; Regression SignatureDef例子 signature_def: &#123; key : "my_regression_signature" value: &#123; inputs: &#123; key : "inputs" value: &#123; name: "x_input_examples_tensor_0" dtype: ... tensor_shape: ... &#125; &#125; outputs: &#123; key : "outputs" value: &#123; name: "y_outputs_0" dtype: DT_FLOAT tensor_shape: ... &#125; &#125; method_name: "tensorflow/serving/regress" &#125;&#125; 生成 SaveModel 文件生成 SaveModel文件的方式： （1）tf.saved_model # 最直接简单 （2）Estimator的export_savedmodel # 高级API Estimator模型导出 classifier = classifier = tf.estimator.Estimator( model_fn=conv_model, model_dir=args.tf_model_dir, config=training_config, params=model_params)classifier.export_savedmodel(args.tf_export_dir, serving_input_receiver_fn=serving_fn) （3）keras.Model.save(output_path) 将 checkpoint 模型文件 改为 SaveModel 文件import sys, os, ioimport tensorflow as tfmodel_version = "1"model_name = "object"def restore_and_save(input_checkpoint, export_path_base): checkpoint_file = tf.train.latest_checkpoint(input_checkpoint) graph = tf.Graph() with graph.as_default(): session_conf = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False) sess = tf.Session(config=session_conf) with sess.as_default(): # 载入保存好的meta graph，恢复图中变量，通过SavedModelBuilder保存可部署的模型 saver = tf.train.import_meta_graph("&#123;&#125;.meta".format(checkpoint_file)) saver.restore(sess, checkpoint_file) print ("name scope: ",graph.get_name_scope()) export_path_base = export_path_base export_path = os.path.join( tf.compat.as_bytes(export_path_base), tf.compat.as_bytes(model_name+"/"+model_version)) print('Exporting trained model to', export_path) builder = tf.saved_model.builder.SavedModelBuilder(export_path) # 模型的各种operator 可以通过 graph.get_operations() 获得 # input 为输入层operator inputs = tf.saved_model.utils.build_tensor_info(graph.get_operation_by_name("Placeholder").outputs[0]) print(inputs) # output 为输出层operator, 这里的输出层 type 为 Softmax outputs = tf.saved_model.utils.build_tensor_info(graph.get_operation_by_name("final_result").outputs[0]) print(outputs) """ signature_constants：SavedModel保存和恢复操作的签名常量。 在序列标注的任务中，这里的method_name是"tensorflow/serving/predict" """ # 定义模型的输入输出，建立调用接口与tensor签名之间的映射 labeling_signature = ( tf.saved_model.signature_def_utils.build_signature_def( inputs=&#123; "Placeholder": inputs, &#125;, outputs=&#123; "final_result": outputs, &#125;, method_name="tensorflow/serving/predict")) """ tf.group : 创建一个将多个操作分组的操作，返回一个可以执行所有输入的操作 """ legacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op') """ add_meta_graph_and_variables：建立一个Saver来保存session中的变量， 输出对应的原图的定义，这个函数假设保存的变量已经被初始化； 对于一个SavedModelBuilder，这个API必须被调用一次来保存meta graph； 对于后面添加的图结构，可以使用函数 add_meta_graph()来进行添加 """ # 建立模型名称与模型签名之间的映射 builder.add_meta_graph_and_variables( sess, [tf.saved_model.tag_constants.SERVING], signature_def_map=&#123; tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: labeling_signature&#125;, legacy_init_op=legacy_init_op ) builder.save() print("Build Done") Run server生成好 SaveModel 模型文件，就可以直接运行 serving 来实现模型服务： (1)用DOCKER运行: docker run --rm -it -p 8500:8500 \--mount type=bind,source=/root/inception/models,target=/models \-e MODEL_NAME=1 tensorflow/serving 挂载的默认目录为两级目录:./&lt;模型名称&gt;/&lt;版本号&gt;/save_model.pb, 版本号必须为数字。 (2)或者可以用k8s运行deployment(kubeflow)： apiVersion: extensions/v1beta1kind: Deploymentmetadata: labels: app: inception name: inception-service-local namespace: kubeflowspec: template: metadata: labels: app: inception version: v1 spec: containers: - args: - --port=9000 - --rest_api_port=8500 - --model_name=1 - --model_base_path=/mnt/export command: - /usr/bin/tensorflow_model_server env: - name: modelBasePath value: /mnt/export image: tensorflow/serving:1.11.1 imagePullPolicy: IfNotPresent livenessProbe: initialDelaySeconds: 30 periodSeconds: 30 tcpSocket: port: 9000 name: mnist ports: - containerPort: 9000 - containerPort: 8500 volumeMounts: - mountPath: /mnt name: local-storage 构建请求测试测试模型接口 import requestsfrom PIL import Imageimport numpy as npfilename = "./CES/astra_mini/1576210854440.png" # 图片img=Image.open(filename) img_arr=np.array(img,dtype=np.uint8)print(img_arr.shape) # (299, 299, 3)data = json.dumps(&#123;"instances": [img_arr.tolist()]&#125;)headers = &#123;"content-type": "application/json"&#125;json_response = requests.post('http://127.0.0.1:8501/v1/models/object:predict', data=data, headers=headers)print(json_response.text) 参考文献 https://www.tensorflow.org/tfx/tutorials/serving/rest_simple]]></content>
      <categories>
        <category>技术博文</category>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>架构</tag>
        <tag>kubeflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[生活小技能: 实用小众网站收藏]]></title>
    <url>%2F2019%2F%E7%94%9F%E6%B4%BB%2F%E7%94%9F%E6%B4%BB%E5%B0%8F%E6%8A%80%E8%83%BD-%E5%AE%9E%E7%94%A8%E5%B0%8F%E4%BC%97%E7%BD%91%E7%AB%99%E6%94%B6%E8%97%8F%2F</url>
    <content type="text"><![CDATA[历史知识 3D动画 医疗知识 背景抠图背景抠图 PPT素材库PPT素材库]]></content>
      <categories>
        <category>生活技能</category>
        <category>网站笔记</category>
      </categories>
      <tags>
        <tag>标签</tag>
        <tag>实用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s故障问题收集帖]]></title>
    <url>%2F2019%2F%E8%BF%90%E7%BB%B4%2Fk8s%E6%95%85%E9%9A%9C%E9%97%AE%E9%A2%98%E6%94%B6%E9%9B%86%2F</url>
    <content type="text"><![CDATA[网络问题Pod 一直处于 ContainerCreating 状态，显示”cni0” already has an IP address different通过 kubectl describe pod &lt;pod-name&gt; 命令查看到当前 Pod 的事件 Events: Type Reason Age From Message Normal Scheduled 89s default-scheduler Successfully assigned local-path-storage/local-path-provisioner-ccbdd96dc-cbthj to ip-172-31-9-78 Warning FailedCreatePodSandBox 88s kubelet, ip-172-31-9-78 Failed create pod sandbox: rpc error: code = Unknown desc = failed to set up sandbox container “dbe0dc21f80b8778ceff11a98de477e59f5c3fa982563626ed0c01eba5eaed2c” network for pod “local-path-provisioner-ccbdd96dc-cbthj”: NetworkPlugin cni failed to set up pod “local-path-provisioner-ccbdd96dc-cbthj_local-path-storage” network: failed to set bridge addr: “cni0” already has an IP address different from 10.42.0.1/24 查看 kubelet 日志也是显示： E1216 17:30:30.675697 22632 cni.go:331] Error adding local-path-storage_local-path-provisioner-ccbdd96dc-cbthj/ 0d2b1cd6de25ac114e2075f70f8ac25ef72b299048e728038086f3e7324f400a to network flannel/cbr0: failed to set bridge addr: “cni0” already has an IP address different from 10.42.0.1/24 E1216 17:30:30.922504 22632 remote_runtime.go:105] RunPodSandbox from runtime service failed: rpc error: code = Unknown desc = failed to set up sandbox container “0d2b1cd6de25ac114e2075f70f8ac25ef72b299048e728038086f3e7324f400a” network for pod “local-path-provisioner-ccbdd96dc-cbthj”: NetworkPlugin cni failed to set up pod “local-path-provisioner-ccbdd96dc-cbthj_local-path-storage” network: failed to set bridge addr: “cni0” already has an IP address different from 10.42.0.1/24 这类错误是因为 cni0 网桥配置了一个不同网段的 IP 地址导致, 做法是删除cni0让网络插件重新自动创建（由于cni0是作为docker的网桥，这里需要先暂停对于机器的容器）:systemctl stop dockerip link set cni0 downbrctl delbr cni0 Coredns CrashLoopBackOff 问题log日志：kubectl -n kube-system logs coredns-6998d84bf5-r4dbk E1028 06:36:35.489403 1 reflector.go:134] github.com/coredns/coredns/plugin/kubernetes/controller.go:322: Failed to list *v1.Namespace: Get https://10.96.0.1:443/api/v1/namespaces?limit=500&amp;resourceVersion=0: dial tcp 10.96.0.1:443: connect: no route to hostE1028 06:36:35.489403 1 reflector.go:134] github.com/coredns/coredns/plugin/kubernetes/controller.go:322: Failed to list *v1.Namespace: Get https://10.96.0.1:443/api/v1/namespaces?limit=500&amp;resourceVersion=0: dial tcp 10.96.0.1:443: connect: no route to hostlog: exiting because of error: log: cannot create log: open /tmp/coredns.coredns-8686dcc4fd-7fwcz.unknownuser.log.ERROR.20191028-063635.1: no such file or directory 防火墙（iptables）规则错乱或者缓存导致的,解决方案：iptables --flushiptables -tnat --flush 该操作会丢失防火墙规则 metrics-server CrashLoopBackOff 问题实战查看pod发现 metrics-server 一直无法启动：&gt; kubectl -n kube-system get pods -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEScoredns-5c59fd465f-fjf6n 0/1 Running 0 4d5h 10.42.0.4 node1 &lt;none&gt; &lt;none&gt;coredns-autoscaler-d765c8497-g77ql 1/1 Running 0 4d5h 10.42.0.2 node1 &lt;none&gt; &lt;none&gt;kube-flannel-whrbf 2/2 Running 0 4d5h 10.10.6.85 node1 &lt;none&gt; &lt;none&gt;metrics-server-64f6dffb84-p287x 0/1 CrashLoopBackOff 1110 4d5h 10.42.0.3 node1 &lt;none&gt; &lt;none&gt;... 查看log日志&gt; kubectl -n kube-system logs metrics-server-64f6dffb84-p287x...panic: Get https://10.43.0.1:443/api/v1/namespaces/kube-system/configmaps/extension-apiserver-authentication: dial tcp 10.43.0.1:443: connect: no route to host... 通过日志来看这是个网络问题，可以看到 coredns 虽然是 running状态，但 READY 是 0/1，我们查看下 coredns ，我们再看看endpoint:&gt; kubectl get ep kube-dns --namespace=kube-systemNAME ENDPOINTS AGEkube-dns 4d6h 发现 endpoints 列表为空，说明有可能是 kube-dns pod 确实没起来，查看错误信息：&gt; kubectl -n kube-system describe pod coredns-5c59fd465f-fjf6n ...Node: node1/10.10.6.85...Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning DNSConfigForming 9m37s (x4896 over 4d7h) kubelet, node1 Nameserver limits were exceeded, some nameservers have been omitted, the applied nameserver line is: 10.10.20.2 10.10.20.7 202.96.134.133 Warning Unhealthy 4m30s (x37057 over 4d7h) kubelet, node1 Readiness probe failed: HTTP probe failed with statuscode: 503 跟进Nameserver limits were exceeded关键词搜索，发现一篇同样问题的博客（https://www.cnblogs.com/cuishuai/p/10980852.html），意思应该是 nameserver 超出限制，超出的被忽略，会不会是/etc/resolv.conf里面的 nameserver 出现了问题，立刻去对应的node节点查看（通过 describe 找到 Node 节点）：cat /etc/resolv.conf# Generated by NetworkManagersearch orbbec.comnameserver 10.10.20.2nameserver 10.10.20.7nameserver 202.96.134.133# NOTE: the libc resolver may not support more than 3 nameservers.# The nameservers listed below may not be recognized.nameserver 202.96.128.86 果然有问题，将上面nameserver删除，重启docker:systemctl restart docker]]></content>
      <categories>
        <category>技术博文</category>
        <category>容器技术</category>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>运维</tag>
        <tag>疑难杂症</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[智能硬件设备公司在视觉云平台战略布局——IoT的起家之本]]></title>
    <url>%2F2019%2F%E6%88%98%E7%95%A5%2F%E5%85%B3%E4%BA%8E%E7%A1%AC%E4%BB%B6%E5%85%AC%E5%8F%B8%E7%9A%84%E4%BA%91%E5%B9%B3%E5%8F%B0%E6%88%98%E7%95%A5%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[现在新技术层出不穷，5G、边缘计算、云原生，技术晃得我们眼花缭乱的，那么什么真正是我们应该做的，特别对于以硬件为核心的企业，建云平台有没有必要性？毕竟企业发展永远是第一位。我们在聊我们应该做什么，不做什么本质上是在谈边界的问题。在讨论边界的时候，出发点有三个：（1）这个事情和我有什么关系；（2）这个事情对我有什么价值；（3）这个事情我能不能做； 关系问题云、边、端，我们知道端侧特别是针对模组这块是离云端最远的部分，大家相互很少大交道，那么云到底和我有什么关系呢？IoT的缩写的全称是 Internet of Things，Internet 就是联网，就是云。现在上市公司没有谁愿意说自己是一家模组厂商，为啥？因为市盈率低，市值低，没有想象空间。那为啥加上Internet，加上云就上去了呢？因为本质上在于模式变了，小米如果他只卖手机，只卖家具，他不过是一堆有品牌的硬件产品，和我们在淘宝上买的其他硬件没什么本质区别。但他加上了平台，加上了服务，就让很多东西变成可能了，比如你的设备接入、管理，数据采集等等。云本质上是一种服务模式，就像SDK一样。 价值问题第二块，从价值来说。我们现在需要云吗？或者说需要云平台吗？即需要，也不需要，这要看我们认知的角度。从纯模组的供应商来看，云平台是不必要的，也是没有意义的，因为我们只是别人的一个模块，我们不具备单独的网络通信功能，所有的服务皆来自于硬件本身所提供的能力。但是我们不是一个模组供应商，我们不仅要看清世界，更要看懂世界。我们要做算法，我们要做自己的开发板，而这就决定了我们必然会跟外部服务打交道，跟云打交道。像我们公司内部如果能有一个统一的云平台将计算资源整合，我们就可以做到资源的集约化利用，节约机器的成本。如果我们有一个云平台能提供开发板的接入、管理服务，那么我们就可以方便开发者，提升使用者使用体验。如果我们有一个统一的云平台可以将我们的开发算法向开发者提供服务，我们就可以为开发者赋能，建立生态体系。所以，不管是对内、对外来说，我们都需要一个云平台的服务。 能力问题最后，说说能力，就是这块东西到底能不能做？很多事情能不能是看基因的，比如阿里做社交，投入很大，但是总是失败，腾讯做电商，也是做了很多年，半死不活，这就是基因。那么以硬件起家的公司能不能做好云平台呢？我觉得是能做的，相对于门槛更高的硬件，做软件做平台核心是生态，而有硬件的基础，做生态是比较容易的。最好的例子就是苹果，苹果以手机为媒介，在上面搭建了一整套软件服务，并通过提高服务带来硬件价值的提高。]]></content>
      <categories>
        <category>管理</category>
        <category>企业战略</category>
      </categories>
      <tags>
        <tag>企业战略</tag>
        <tag>中台</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[云原生技术在企业内部的落地实践(演讲稿)]]></title>
    <url>%2F2019%2F%E6%9E%B6%E6%9E%84%2F%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%9C%A8%E4%BC%81%E4%B8%9A%E5%86%85%E9%83%A8%E7%9A%84%E8%90%BD%E5%9C%B0%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>演讲稿展示</category>
        <category>云原生</category>
      </categories>
      <tags>
        <tag>技术分享</tag>
        <tag>云原生</tag>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubeflow系列(二)：kubeflow组件介绍]]></title>
    <url>%2F2019%2F%E8%BF%90%E7%BB%B4%2Fkubeflow%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[为了对kubeflow有个更直观深入的了解，对kubeflow的各组件进行简单的介绍，先从机器学习任务来看kubeflow的的实现。 机器学习任务工程化实现流程一个建模任务下来主要可以分为四大块任务 业务理解(Business Understanding) 数据获取及数据理解(Data Acquistition) 特征处理(Feature Engineering)、建模与模型训练(Model Training)、模型评估(Model Evaluation) 模型部署(Deployment)，提供模型服务 一个机器学习任务从开始到结束主要分为了四大任务，Kubeflow的各项功能可以说就是围绕这四项任务构建的。 kubeflowkubeflow 最开始基于tf-operator，后来随着项目发展最后变成一个基于云原生构建的机器学习任务工具大集合。从数据采集，验证，到模型训练和服务发布，几乎所有步骤的小组件 Kubeflow 都提供解决方案的组件： kubeflow特点： 基于k8s，具有云原生的特性：弹性伸缩、高可用、DevOps等 集成大量机器学习所用到的工具 结构kubeflow的完整结构可以看他的kustomize安装文件：kustomize/├── ambassador.yaml├── api-service.yaml├── argo.yaml├── centraldashboard.yaml├── jupyter-web-app.yaml├── katib.yaml├── metacontroller.yaml├── minio.yaml├── mysql.yaml├── notebook-controller.yaml├── persistent-agent.yaml├── pipelines-runner.yaml├── pipelines-ui.yaml├── pipelines-viewer.yaml├── pytorch-operator.yaml├── scheduledworkflow.yaml├── tensorboard.yaml└── tf-job-operator.yaml ambassador 微服务网关argo 用于任务工作流编排centraldashboard kubeflow的dashboard看板页面tf-job-operator 深度学习框架引擎，一个基于tensorflow构建的CRD，资源类型kind为TFJobtensorboard tensorflow的训练可视化UI界面katib 超参数服务器pipeline 一个机器学习的工作流组件jupyter 一个交互式业务IDE编码环境 TFJob TFJob 是将 tensorflow 的分布式架构基于 k8s 构建的一种CRD： Chief 负责协调训练任务 Ps 参数服务器，为模型的参数提供分布式的数据存储 Worker 负责实际训练模型的任务. 在某些情况下 worker 0 可以充当Chief的责任。 Evaluator 负责在训练过程中进行性能评估 apiVersion: kubeflow.org/v1beta2kind: TFJobmetadata: name: mnist-train namespace: kubeflowspec: tfReplicaSpecs: Chief: # 调度器 replicas: 1 template: spec: containers: - command: - /usr/bin/python - /opt/model.py env: - name: modelDir value: /mnt - name: exportDir value: /mnt/export image: mnist-test:v0.1 name: tensorflow volumeMounts: - mountPath: /mnt name: local-storage workingDir: /opt restartPolicy: OnFailure volumes: - name: local-storage persistentVolumeClaim: claimName: local-path-pvc Ps: # 参数服务器 replicas: 1 template: spec: containers: - command: - /usr/bin/python - /opt/model.py env: - name: modelDir value: /mnt - name: exportDir value: /mnt/export image: mnist-test:v0.1 name: tensorflow volumeMounts: - mountPath: /mnt name: local-storage workingDir: /opt restartPolicy: OnFailure volumes: - name: local-storage persistentVolumeClaim: claimName: local-path-pvc Worker: # 计算节点 replicas: 2 template: spec: containers: - command: - /usr/bin/python - /opt/model.py env: - name: modelDir value: /mnt - name: exportDir value: /mnt/export image: mnist-test:v0.1 name: tensorflow volumeMounts: - mountPath: /mnt name: local-storage workingDir: /opt restartPolicy: OnFailure volumes: - name: local-storage persistentVolumeClaim: claimName: local-path-pvc tensorboard 训练可视化界面挂载日志文件，创建 tensorboard 可视化服务 apiVersion: v1kind: Servicemetadata: name: tensorboard-tb namespace: kubeflowspec: ports: - name: http port: 8080 targetPort: 80 selector: app: tensorboard tb-job: tensorboard---apiVersion: apps/v1beta1kind: Deploymentmetadata: name: tensorboard-tb namespace: kubeflowspec: replicas: 1 template: metadata: labels: app: tensorboard tb-job: tensorboard name: tensorboard namespace: kubeflow spec: containers: - command: - /usr/local/bin/tensorboard - --logdir=/mnt - --port=80 env: - name: logDir value: /mnt image: tensorflow/tensorflow:1.11.0 name: tensorboard ports: - containerPort: 80 volumeMounts: - mountPath: /mnt name: local-storage serviceAccount: default-editor volumes: - name: local-storage persistentVolumeClaim: claimName: mnist-test-pvc tf-servingtenserflow serving 提供一个稳定的接口，供用户调用，来应用该模型，serving 通过模型文件直接创建模型即服务(Model as a service) apiVersion: v1kind: Servicemetadata: labels: app: mnist name: mnist-service-local namespace: kubeflowspec: ports: - name: grpc-tf-serving port: 9000 targetPort: 9000 - name: http-tf-serving port: 8500 targetPort: 8500 selector: app: mnist type: ClusterIP---apiVersion: extensions/v1beta1kind: Deploymentmetadata: labels: app: mnist name: mnist-service-local namespace: kubeflowspec: template: metadata: labels: app: mnist version: v1 spec: containers: - args: - --port=9000 - --rest_api_port=8500 - --model_name=mnist - --model_base_path=/mnt/export command: - /usr/bin/tensorflow_model_server env: - name: modelBasePath value: /mnt/export image: tensorflow/serving:1.11.1 imagePullPolicy: IfNotPresent livenessProbe: initialDelaySeconds: 30 periodSeconds: 30 tcpSocket: port: 9000 name: mnist ports: - containerPort: 9000 - containerPort: 8500 resources: limits: cpu: "4" memory: 4Gi requests: cpu: "1" memory: 1Gi volumeMounts: - mountPath: /mnt name: local-storage pipelinepipeline 是一个可视化的kubeflow任务工作流(Workflow)，定义了一个有向无环图描述的流水线，流水线中每一步流程是由容器定义组成的组件。 运行步骤： 先要定义一个Experiment实验 然后发起任务，定义一个Pipeline 运行Pipeline实例 结构介绍 pipeline主要分为八部分： Python SDK: 用于创建kubeflow pipeline 的DSL DSL compiler: 将Python代码转换成YAML静态配置文件 Pipeline web server: pipeline的前端服务 Pipeline Service： pipeline的后端服务 Kubernetes resources: 创建CRDs运行pipeline Machine learning metadata service: 用于存储任务流容器之间的数据交互（input/output） Artifact storage: 用于存储 Metadata 和 Pipeline packages, views Orchestration controllers：任务编排，比如Argo Workflow. 案例import kfpfrom kfp import dsldef gcs_download_op(url): return dsl.ContainerOp( name='GCS - Download', image='google/cloud-sdk:272.0.0', command=['sh', '-c'], arguments=['gsutil cat $0 | tee $1', url, '/tmp/results.txt'], file_outputs=&#123; 'data': '/tmp/results.txt', &#125; )def echo2_op(text1, text2): return dsl.ContainerOp( name='echo', image='library/bash:4.4.23', command=['sh', '-c'], arguments=['echo "Text 1: $0"; echo "Text 2: $1"', text1, text2] )@dsl.pipeline( name='Parallel pipeline', description='Download two messages in parallel and prints the concatenated result.')def download_and_join( url1='gs://ml-pipeline-playground/shakespeare1.txt', url2='gs://ml-pipeline-playground/shakespeare2.txt'): """A three-step pipeline with first two running in parallel.""" download1_task = gcs_download_op(url1) download2_task = gcs_download_op(url2) echo_task = echo2_op(download1_task.output, download2_task.output)if __name__ == '__main__': kfp.compiler.Compiler().compile(download_and_join, __file__ + '.yaml') jupyter-notebookjupyter 是最大限度的利用交互式的工作，他的主要工作体现利用交互式的操作帮助用户快速理解数据和测试评估模型。 主要包括两个模块jupyter-web-app 和 notebook-controller, jupyter 架构： 也可以用 jupyterhub 代替jupyter, jupyterhub提供了更多功能， jupyterhub 结构：]]></content>
      <categories>
        <category>技术博文</category>
        <category>容器技术</category>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>运维</tag>
        <tag>kubeflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈golang的sync包]]></title>
    <url>%2F2019%2F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%2F%E6%B5%85%E8%B0%88golang%E7%9A%84sync%E5%8C%85%2F</url>
    <content type="text"><![CDATA[sync包sync包是 golang 一个官方的异步库，提供了一些各种基础的异步的实现，如互斥锁等。sync 包主要包括了以下几种类型： sync.Mutex 和 sync.WaitGroup sync.Once sync.Map sync.Pool sync.Cond sync.Oncesync.Mapsync.Map是一个线程安全的map结构，一般用于多读少写的并发操作，下图是sync.Map的数据结构 图引至码农桃花源公众号 type Map struct &#123; mu Mutex read atomic.Value // readOnly dirty map[interface&#123;&#125;]*entry misses int&#125; mu是Map的互斥锁用于对并发操作进行加锁保护，read是用于存储只读内容的，可以提供高并发的读操作。 dirty是一个原始的map结构体，对dirty的操作需要加锁，dirty包涵了全量的数据，在读数据的时候会先读取read，read读取不到再读dirty。 misses 是read读取失败的次数，当多次读取失败后 misses 累计特定值，dirty就会升级成read。sync.Map 这里采用的策略类似数据库常用的”读写分离”，技术都是相通的O(∩_∩)O sync.Map用法func main() &#123; var value sync.Map // 写入 value.Store("your name", "shi") value.Store("her name", "kanon") // 读取 name, ok := value.Load("your name") if !ok &#123; println("can't find name") &#125; fmt.Println(name) // 遍历 value.Range(func(ki, vi interface&#123;&#125;) bool &#123; k, v := ki.(string), vi.(string) fmt.Println(k, v) return true &#125;) // 删除 value.Delete("your name") // 读取，如果不存在则写入 activename, loaded := value.LoadOrStore("his name", "baba") fmt.Println(activename.(string), loaded)&#125; sync.Poolsync.Cond]]></content>
      <categories>
        <category>技术博文</category>
        <category>编程语言</category>
        <category>GO</category>
      </categories>
      <tags>
        <tag>sync</tag>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubeflow系列：用kustomize安装kubeflow(基于阿里云镜像版)]]></title>
    <url>%2F2019%2F%E8%BF%90%E7%BB%B4%2Fkubeflow%E7%9A%84%E6%90%AD%E5%BB%BA%E5%8F%8A%E8%B8%A9%E8%BF%87%E7%9A%84%E5%9D%91%2F</url>
    <content type="text"><![CDATA[kubeflow国内完整的安装踩坑记录 环境准备kubeflow 为环境要求很高，看官方要求：at least one worker node with a minimum of: 4 CPU 50 GB storage 12 GB memory 当然，没达到也能安装，不过在后面使用中会出现资源问题，因为这是整包安装方案。 一个已经安装好的kubernetes集群，这里我采用的是rancher安装的集群。sudo docker run -d --restart=unless-stopped -p 80:80 -p 443:443 rancher/rancher 这里我选择的是k8s的1.14版本，kubeflow和k8s之间的版本兼容可以查看官网说明，这里我的kubeflow采用了0.6版本。 如果直接想安装可以直接调到kubeflow一键安装部分 kustomize下载kustomize文件官方的教程是用 kfclt 安装的，kfclt 本质上是使用了 kustomize 来安装，因此这里我直接下载 kustomize 文件，通过修改镜像的方式安装。 官方kustomize文件下载地址 git clone https://github.com/kubeflow/manifestscd manifestsgit checkout v0.6-branchcd &lt;target&gt;/basekubectl kustomize . | tee &lt;output file&gt; 文件比较多，可以用脚本分别导出，也可以用 kfctl 命令生成kfctl generate all -V: kustomize/├── ambassador.yaml├── api-service.yaml├── argo.yaml├── centraldashboard.yaml├── jupyter-web-app.yaml├── katib.yaml├── metacontroller.yaml├── minio.yaml├── mysql.yaml├── notebook-controller.yaml├── persistent-agent.yaml├── pipelines-runner.yaml├── pipelines-ui.yaml├── pipelines-viewer.yaml├── pytorch-operator.yaml├── scheduledworkflow.yaml├── tensorboard.yaml└── tf-job-operator.yaml ambassador 微服务网关argo 用于任务工作流编排centraldashboard kubeflow的dashboard看板页面tf-job-operator 深度学习框架引擎，一个基于tensorflow构建的CRD，资源类型kind为TFJobkatib 超参数服务器 机器学习套件使用流程 修改kustomize文件修改kustomize镜像修改镜像：grc_image = ["gcr.io/kubeflow-images-public/ingress-setup:latest","gcr.io/kubeflow-images-public/admission-webhook:v20190520-v0-139-gcee39dbc-dirty-0d8f4c","gcr.io/kubeflow-images-public/kubernetes-sigs/application:1.0-beta","gcr.io/kubeflow-images-public/centraldashboard:v20190823-v0.6.0-rc.0-69-gcb7dab59","gcr.io/kubeflow-images-public/jupyter-web-app:9419d4d","gcr.io/kubeflow-images-public/katib/v1alpha2/katib-controller:v0.6.0-rc.0","gcr.io/kubeflow-images-public/katib/v1alpha2/katib-manager:v0.6.0-rc.0","gcr.io/kubeflow-images-public/katib/v1alpha2/katib-manager-rest:v0.6.0-rc.0","gcr.io/kubeflow-images-public/katib/v1alpha2/suggestion-bayesianoptimization:v0.6.0-rc.0","gcr.io/kubeflow-images-public/katib/v1alpha2/suggestion-grid:v0.6.0-rc.0","gcr.io/kubeflow-images-public/katib/v1alpha2/suggestion-hyperband:v0.6.0-rc.0","gcr.io/kubeflow-images-public/katib/v1alpha2/suggestion-nasrl:v0.6.0-rc.0","gcr.io/kubeflow-images-public/katib/v1alpha2/suggestion-random:v0.6.0-rc.0","gcr.io/kubeflow-images-public/katib/v1alpha2/katib-ui:v0.6.0-rc.0","gcr.io/kubeflow-images-public/metadata:v0.1.8","gcr.io/kubeflow-images-public/metadata-frontend:v0.1.8","gcr.io/ml-pipeline/api-server:0.1.23","gcr.io/ml-pipeline/persistenceagent:0.1.23","gcr.io/ml-pipeline/scheduledworkflow:0.1.23","gcr.io/ml-pipeline/frontend:0.1.23","gcr.io/ml-pipeline/viewer-crd-controller:0.1.23","gcr.io/kubeflow-images-public/notebook-controller:v20190603-v0-175-geeca4530-e3b0c4","gcr.io/kubeflow-images-public/profile-controller:v20190619-v0-219-gbd3daa8c-dirty-1ced0e","gcr.io/kubeflow-images-public/kfam:v20190612-v0-170-ga06cdb79-dirty-a33ee4","gcr.io/kubeflow-images-public/pytorch-operator:v1.0.0-rc.0","gcr.io/google_containers/spartakus-amd64:v1.1.0","gcr.io/kubeflow-images-public/tf_operator:v0.6.0.rc0","gcr.io/arrikto/kubeflow/oidc-authservice:v0.2"]doc_image = ["registry.cn-shenzhen.aliyuncs.com/shikanon/kubeflow-images-public.ingress-setup:latest","registry.cn-shenzhen.aliyuncs.com/shikanon/kubeflow-images-public.admission-webhook:v20190520-v0-139-gcee39dbc-dirty-0d8f4c","registry.cn-shenzhen.aliyuncs.com/shikanon/kubeflow-images-public.kubernetes-sigs.application:1.0-beta","registry.cn-shenzhen.aliyuncs.com/shikanon/kubeflow-images-public.centraldashboard:v20190823-v0.6.0-rc.0-69-gcb7dab59","registry.cn-shenzhen.aliyuncs.com/shikanon/kubeflow-images-public.jupyter-web-app:9419d4d","registry.cn-shenzhen.aliyuncs.com/shikanon/kubeflow-images-public.katib.v1alpha2.katib-controller:v0.6.0-rc.0","registry.cn-shenzhen.aliyuncs.com/shikanon/kubeflow-images-public.katib.v1alpha2.katib-manager:v0.6.0-rc.0","registry.cn-shenzhen.aliyuncs.com/shikanon/kubeflow-images-public.katib.v1alpha2.katib-manager-rest:v0.6.0-rc.0","registry.cn-shenzhen.aliyuncs.com/shikanon/kubeflow-images-public.katib.v1alpha2.suggestion-bayesianoptimization:v0.6.0-rc.0","registry.cn-shenzhen.aliyuncs.com/shikanon/kubeflow-images-public.katib.v1alpha2.suggestion-grid:v0.6.0-rc.0","registry.cn-shenzhen.aliyuncs.com/shikanon/kubeflow-images-public.katib.v1alpha2.suggestion-hyperband:v0.6.0-rc.0","registry.cn-shenzhen.aliyuncs.com/shikanon/kubeflow-images-public.katib.v1alpha2.suggestion-nasrl:v0.6.0-rc.0","registry.cn-shenzhen.aliyuncs.com/shikanon/kubeflow-images-public.katib.v1alpha2.suggestion-random:v0.6.0-rc.0","registry.cn-shenzhen.aliyuncs.com/shikanon/kubeflow-images-public.katib.v1alpha2.katib-ui:v0.6.0-rc.0","registry.cn-shenzhen.aliyuncs.com/shikanon/kubeflow-images-public.metadata:v0.1.8","registry.cn-shenzhen.aliyuncs.com/shikanon/kubeflow-images-public.metadata-frontend:v0.1.8","registry.cn-shenzhen.aliyuncs.com/shikanon/ml-pipeline.api-server:0.1.23","registry.cn-shenzhen.aliyuncs.com/shikanon/ml-pipeline.persistenceagent:0.1.23","registry.cn-shenzhen.aliyuncs.com/shikanon/ml-pipeline.scheduledworkflow:0.1.23","registry.cn-shenzhen.aliyuncs.com/shikanon/ml-pipeline.frontend:0.1.23","registry.cn-shenzhen.aliyuncs.com/shikanon/ml-pipeline.viewer-crd-controller:0.1.23","registry.cn-shenzhen.aliyuncs.com/shikanon/kubeflow-images-public.notebook-controller:v20190603-v0-175-geeca4530-e3b0c4","registry.cn-shenzhen.aliyuncs.com/shikanon/kubeflow-images-public.profile-controller:v20190619-v0-219-gbd3daa8c-dirty-1ced0e","registry.cn-shenzhen.aliyuncs.com/shikanon/kubeflow-images-public.kfam:v20190612-v0-170-ga06cdb79-dirty-a33ee4","registry.cn-shenzhen.aliyuncs.com/shikanon/kubeflow-images-public.pytorch-operator:v1.0.0-rc.0","registry.cn-shenzhen.aliyuncs.com/shikanon/google_containers.spartakus-amd64:v1.1.0","registry.cn-shenzhen.aliyuncs.com/shikanon/kubeflow-images-public.tf_operator:v0.6.0.rc0","registry.cn-shenzhen.aliyuncs.com/shikanon/arrikto.kubeflow.oidc-authservice:v0.2"] 修改PVC，使用动态存储修改pvc存储，采用local-path-provisioner动态分配PV。 安装local-path-provisioner：kubectl apply -f https://raw.githubusercontent.com/rancher/local-path-provisioner/master/deploy/local-path-storage.yaml 如果想直接在kubeflow中使用，还需要将StorageClass改为默认存储:...apiVersion: storage.k8s.io/v1kind: StorageClassmetadata: name: local-path annotations: #添加为默认StorageClass storageclass.beta.kubernetes.io/is-default-class: "true"provisioner: rancher.io/local-pathvolumeBindingMode: WaitForFirstConsumerreclaimPolicy: Delete... 完成后可以建一个PVC试试：apiVersion: v1kind: PersistentVolumeClaimmetadata: name: local-path-pvc namespace: defaultspec: accessModes: - ReadWriteOnce resources: requests: storage: 2Gi 注：如果没有设为默认storageclass需要在PVC加入storageClassName: local-path进行绑定 一键安装这里我制作了一个一键启动的国内镜像版kubeflow项目：https://github.com/shikanon/kubeflow-manifests 中间踩过的坑Coredns CrashLoopBackOff 问题 log日志：kubectl -n kube-system logs coredns-6998d84bf5-r4dbk E1028 06:36:35.489403 1 reflector.go:134] github.com/coredns/coredns/plugin/kubernetes/controller.go:322: Failed to list *v1.Namespace: Get https://10.96.0.1:443/api/v1/namespaces?limit=500&amp;resourceVersion=0: dial tcp 10.96.0.1:443: connect: no route to hostE1028 06:36:35.489403 1 reflector.go:134] github.com/coredns/coredns/plugin/kubernetes/controller.go:322: Failed to list *v1.Namespace: Get https://10.96.0.1:443/api/v1/namespaces?limit=500&amp;resourceVersion=0: dial tcp 10.96.0.1:443: connect: no route to hostlog: exiting because of error: log: cannot create log: open /tmp/coredns.coredns-8686dcc4fd-7fwcz.unknownuser.log.ERROR.20191028-063635.1: no such file or directory 防火墙（iptables）规则错乱或者缓存导致的,解决方案：iptables --flushiptables -tnat --flush 该操作会丢失防火墙规则]]></content>
      <categories>
        <category>技术博文</category>
        <category>容器技术</category>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>运维</tag>
        <tag>kubeflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[trojan腾讯云部署安装]]></title>
    <url>%2F2019%2F%E8%BF%90%E7%BB%B4%2Ftrojan%E8%85%BE%E8%AE%AF%E4%BA%91%E9%83%A8%E7%BD%B2%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[听说 trojan 梯子的稳定和速度都不错，因为之前买了台国外的腾讯云服务器，但自己搭的VPN一直不太稳定，经常断，正好测试下 trojan 是不是这么牛。 BBR安装BBR加速器BBR加速器： 安装：yum -y install wgetwget --no-check-certificate https://github.com/teddysun/across/raw/master/bbr.shchmod +x bbr.sh./bbr.sh trojan 安装trojan安装torjan前需要安装caddy做web服务和自动生成tls证书：yum install caddy -y 安装好caddy之后就可以安装trojan了： curl -O https://raw.githubusercontent.com/atrandys/trojan/master/trojan_centos7.sh &amp;&amp; chmod +x trojan_centos7.sh &amp;&amp; ./trojan_centos7.sh 安装 trojan 要 root 权限，还有需要准备一个解析到服务器的域名地址。可以在国内买也可以在国外买，这个自行决定，我用的是腾讯云买的域名，需要将域名解析到服务器，因为是国外服务器只能用境外域名解析。 启动后进入交互框：==================================== 介绍：一键安装trojan 系统：&gt;=centos7 作者：atrandys 网站：www.atrandys.com Youtube：atrandys ==================================== 1. 安装trojan 2. 卸载trojan 0. 退出脚本请输入数字:1 一键安装简单方便。然后输入域名即可：....=======================请输入绑定到本VPS的域名=======================xxxxxxxx.com Server端安装完成，给出客户端安装步骤：先下载，然后解压运行即可。======================================================================Trojan已安装完成，请使用以下链接下载trojan客户端，此客户端已配置好所有参数1、复制下面的链接，在浏览器打开，下载客户端http://xxxxxxx/xxxxxxxxxx/trojan-cli.zip2、将下载的压缩包解压，打开文件夹，打开start.bat即打开并运行Trojan客户端3、打开stop.bat即关闭Trojan客户端4、Trojan客户端需要搭配浏览器插件使用，例如switchyomega等====================================================================== 我们看看下载下来的客户端目录：tree /F卷 工作 的文件夹 PATH 列表卷序列号为 0073-9957D:.│ config.json│ CONTRIBUTORS.md│ fullchain.cer│ libcrypto-1_1.dll│ libmariadb.dll│ libssl-1_1.dll│ LICENSE│ msvcp140.dll│ msvcp140_1.dll│ msvcp140_2.dll│ README.md│ start.bat│ stop.bat│ trojan.exe│ vcruntime140.dll│ vcruntime140_1.dll│ VC_redist.x64.exe│└─examples client.json-example forward.json-example server.json-example 我们可以看看里面的配置：&#123; "run_type": "client", "local_addr": "127.0.0.1", "local_port": 1080, "remote_addr": "xxxxxx.com", "remote_port": 443, "password": [ "xxxxxx" ], "log_level": 1, "ssl": &#123; "verify": true, "verify_hostname": true, "cert": "fullchain.cer", "cipher_tls13":"TLS_AES_128_GCM_SHA256:TLS_CHACHA20_POLY1305_SHA256:TLS_AES_256_GCM_SHA384","sni": "", "alpn": [ "h2", "http/1.1" ], "reuse_session": true, "session_ticket": false, "curves": "" &#125;, "tcp": &#123; "no_delay": true, "keep_alive": true, "fast_open": false, "fast_open_qlen": 20 &#125;&#125;]]></content>
      <categories>
        <category>技术博文</category>
        <category>系统运维</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>VPN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于rancher五分钟搭建私有镜像仓库harbor并配置https]]></title>
    <url>%2F2019%2F%E8%BF%90%E7%BB%B4%2F%E6%90%AD%E5%BB%BA%E7%A7%81%E6%9C%89%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93harbor-%E9%85%8D%E7%BD%AEhttps%2F</url>
    <content type="text"><![CDATA[用rancher应用商城搭建harbor在rancher应用商店搜索 harbor ，点击查看详情，进入到配置页面： 可以自建证书也可以直接用kubernetes证书，部署成功可以去work节点下面/etc/docker/certs.d/下面查看会有响应设置的域名证书，按照默认配置，点击启动，这样一个harbor应用就被拉起来了 如果用自建证书（不推荐），步骤如下： (1)openssl生成私钥openssl genrsa -out harbor.key 1024 (2)openssl生成证书openssl req -new -x509 -days 36500 -key harbor.key -out harbor.crt-----Country Name (2 letter code) [XX]:CNState or Province Name (full name) []:GUANGDONGLocality Name (eg, city) [Default City]:SHENZHENOrganization Name (eg, company) [Default Company Ltd]:ORBBECOrganizational Unit Name (eg, section) []:ORBBECCommon Name (eg, your name or your server's hostname) []:*.harbor.orbbecEmail Address []:cifang@orbbec.com （3）导入证书 配置hosts由于搭建的时候采用Ingress的内网域名的形式，我们需要配置hosts或者搭建私有的DNS服务器，这里我们采用默认自己修改域名 修改/etc/hosts[IP地址] core.harbor.domain 这里的修改hosts不仅修改客户端环境的，还要修改work节点的hosts 配置好hosts之后，我们还要配置信任证书，这里有两种方法，一种是直接通过/etc/docker/daemon.json的insecure-registries:&#123;"insecure-registries": ["core.harbor.orbbec","notary.harbor.orbbec"]&#125; 另一种可以到work节点下的/etc/docker/certs.d拷贝到客户端对应位置 重启客户端docker服务：systemctl restart docker 配置镜像仓库凭证： 测试harbor上传登陆harbordocker login core.harbor.orbbec 这里的登陆域名是前面配置的core-harbor的域名，输入用户名密码即可。 上传私有镜像打标签，并上传到librarydocker tag [构建的私有仓库] core.harbor.orbbec/library/python:nginxdocker push core.harbor.orbbec/library/python:nginx 上传可以登陆到 harbor 的 library 项目种查看，可以看到项目已经有一个上传成功的镜像了。 构建基于harbor的deployment构建一个测试deployment，看应用是否正常：apiVersion: apps/v1kind: Deploymentmetadata: name: test-web-deployment labels: app: my-webspec: replicas: 4 selector: matchLabels: app: my-web template: metadata: labels: app: my-web spec: imagePullSecrets: - name: core-harbor containers: - name: nginx image: core.harbor.orbbec/library/python:nginx ports: - containerPort: 80 这里需要注意要加上imagePullSecrets，这里就是我们之前配置的镜像仓库凭证。 发布deployment:kubectl apply -f test-web-deployment.yaml 通过kubectl get deployment可以看到应用已经正常运行了]]></content>
      <categories>
        <category>技术博文</category>
        <category>容器技术</category>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux 文本工具使用小技巧]]></title>
    <url>%2F2019%2F%E8%BF%90%E7%BB%B4%2Flinux-%E6%96%87%E6%9C%AC%E6%9F%A5%E8%AF%A2%E5%B0%8F%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[awkawk 用法awk 通常表达式awk &#39;begin{ commands } pattern{ commands } end{ commands }&#39;，其中 begin 部分和 end 部分可以省略，即awk &#39;{代码}&#39;，比如最简单的打印第一列awk &#39;{print $1}&#39;就是这样。运行原理： 第一步：运行BEGIN{ commands }语句块中的语句。通常用于变量初始化、打印输出表格的表头等语句通常能够写在BEGIN语句块中。可选语块。 第二步：从文件或标准输入(stdin)读取一行。然后运行pattern{ commands }语句块，它逐行扫描文件，从第一行到最后一行反复这个过程。直到文件所有被读取完成。 第三步：当读至输入流末尾时。运行END{ commands }语句块。 print函数print 后面可以跟多个参数，类似python print方法，各参数用空格分开&quot; &quot;,以下是代表的各种变量意义： $0 当前记录（这个变量中存放着整个行的内容） $1~$n 当前记录的第n个字段，字段间由FS分隔 FS 输入字段分隔符 默认是空格或Tab NF 当前记录中的字段个数，就是有多少列 NR 已经读出的记录数，就是行号，从1开始，如果有多个文件话，这个值也是不断累加中。 FNR 当前记录数，与NR不同的是，这个值会是各个文件自己的行号 RS 输入的记录分隔符， 默认为换行符 OFS 输出字段分隔符， 默认也是空格 ORS 输出的记录分隔符，默认为换行符 FILENAME 当前输入文件的名字 docker ps | awk &#39;{print NR &quot;\t&quot; $1}&#39; 表示 打印行号+制表符+第一列数据。 实践使用案例 删除指定关键字容器：删除带有k8s关键字的所有容器docker rm -f $(docker ps -a | grep k8s | awk '&#123;print $1&#125;') jq命令工具jq表达式 单独的一个&#39;.&#39;符号用来表示对作为表达式输入的整个 JSON 对象的引用。 单个&#39;.&lt;attributename&gt;&#39;表示当前一级目录下的属性名称 访问特定数组的元素操作，&#39;.[&lt;index&gt;]&#39;，比如.[1]表示访问数组第2个元素，.[]表示所有元素迭代一次来遍历 也可以支持数组切片操作，类似python，&#39;.[&lt;startindex&gt;:&lt;endindex&gt;]&#39; 实践使用案例 在容器docker inspect的使用: 查看容器挂载目录有哪些：Mounts在第二级目录下docker inspect kubelet | jq ".[].Mounts" 查看容器网络Networks在第三级目录下docker inspect kubelet | jq .[].NetworkSettings.Networks jq 命令后面可以带双引号也可以不带 查看容器配置，比如镜像名称、环境变量、entrypoint:docker inspect kubelet | jq .[].Config grep 和 egrepgrepgrep是一种强大的文本搜索工具命令，它能使用正则表达式搜索文本，并把匹配的行打印出来,grep所支持的正则表达式：^锚定行的开始 如：'^grep'匹配所有以grep开头的行。$锚定行的结束 如：'grep$'匹配所有以grep结尾的行。.匹配一个非换行符的字符如：'gr.p'匹配gr后接一个任意字符，然后是p。*匹配零个或多个先前字符如：'*grep'匹配所有一个或多个空格后紧跟grep的行。 .*一起用代表任意字符。[]匹配一个指定范围内的字符，如'[Gg]rep'匹配Grep和grep。[^]匹配一个不在指定范围内的字符，如：'[^A-FH-Z]rep'匹配不包含A-R和T-Z的一个字母开头，紧跟rep的行。..标记匹配字符，如'love'，love被标记为1。\&lt;锚定单词的开始，如:'\&lt;grep'匹配包含以grep开头的单词的行。\&gt;锚定单词的结束，如'grep\&gt;'匹配包含以grep结尾的单词的行。x\&#123;m\&#125;重复字符x，m次，如：'0\&#123;5\&#125;'匹配包含5个o的行。x\&#123;m,\&#125;重复字符x,至少m次，如：'o\&#123;5,\&#125;'匹配至少有5个o的行。x\&#123;m,n\&#125;重复字符x，至少m次，不多于n次，如：'o\&#123;5,10\&#125;'匹配5--10个o的行。\w匹配文字和数字字符，也就是[A-Za-z0-9]，如：'G\w*p'匹配以G后跟零个或多个文字或数字字符，然后是p。\W\w的反置形式，匹配一个或多个非单词字符，如点号句号等。\b单词锁定符，如: '\bgrep\b'只匹配grep。 egrepegrep是grep的扩展，支持更多的正则表达式元字符，egrep的扩展集如下:+匹配一个或多个先前的字符。如：'[a-z]+able'，匹配一个或多个小写字母后跟able的串，如loveable,enable,disable等。?匹配零个或多个先前的字符。如：'gr?p'匹配gr后跟一个或没有字符，然后是p的行。a|b|c匹配a或b或c。如：grep|sed匹配grep或sed()分组符号，如：love(able|rs)ov+匹配loveable或lovers，匹配一个或多个ov。x&#123;m&#125;,x&#123;m,&#125;,x&#123;m,n&#125;作用同x\&#123;m\&#125;,x\&#123;m,\&#125;,x\&#123;m,n\&#125; 特殊字符写法为了在不同国家的字符编码中保持一至，POSIX(The Portable Operating System Interface)增加了特殊的字符类，如[:alnum:]是A-Za-z0-9的另一个写法。要把它们放到[]号内才能成为正则表达式，如[A- Za-z0-9]或[[:alnum:]]。POSIX的字符类：[:alnum:]文字数字字符[:alpha:]文字字符[:digit:]数字字符[:graph:]非空字符（非空格、控制字符）[:lower:]小写字符[:cntrl:]控制字符[:print:]非空字符（包括空格）[:punct:]标点符号[:space:]所有空白字符（新行，空格，制表符）[:upper:]大写字符[:xdigit:]十六进制数字（0-9，a-f，A-F） 命令案例grep和egrep的命令格式都是grep &lt;命令参数&gt; &lt;表达式&gt; &lt;文件/文件夹&gt;egrep &lt;命令参数&gt; &lt;表达式&gt; &lt;文件/文件夹&gt; 常用命令参数:-v： 反向选取，就是异运算-o：仅显示匹配的字串，而非字串所在的行-i：ignore-case，忽略字符大小写-A：显示之后两行-B：显示之前两行-C：显示上下两行-R: 递归循环 案例1：grep -R '\.HandleCrash' cmd pkg staging | egrep -v 'test|apiserver|kubectl|controller|proxy|scheduler|ssh' 从cmd、pkg、staging文件夹下查找包含.HandleCrash字符的文本的行输出，再返回不包含”test|apiserver|kubectl|controller|proxy|scheduler|ssh”这些字段的行。]]></content>
      <categories>
        <category>技术博文</category>
        <category>系统运维</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker registry:设置私有的镜像缓存仓库]]></title>
    <url>%2F2019%2F%E8%BF%90%E7%BB%B4%2Fdocker-registry-%E8%AE%BE%E7%BD%AE%E7%A7%81%E6%9C%89%E7%9A%84%E9%95%9C%E5%83%8F%E7%BC%93%E5%AD%98%E4%BB%93%E5%BA%93%2F</url>
    <content type="text"><![CDATA[背景介绍docker 提供了官方的 registry 仓库镜像，可以通过docker hub进行拉取：docker pull registry 但是直接拉取的registry我们并不知道如何设置，我们可以看看他的Dockerfile地址，git地址： https://github.com/docker/distribution-library-image 通过这个仓库知道主要是通过config-example.yml来配置。 resgistry 的配置 version: 0.1log: accesslog: disabled: true level: debug formatter: text fields: service: registry environment: staging hooks: - type: mail disabled: true levels: - panic options: smtp: addr: mail.example.com:25 username: mailuser password: password insecure: true from: sender@example.com to: - errors@example.comloglevel: debug # deprecated: use "log"storage: filesystem: rootdirectory: /var/lib/registry maxthreads: 100 azure: accountname: accountname accountkey: base64encodedaccountkey container: containername gcs: bucket: bucketname keyfile: /path/to/keyfile credentials: type: service_account project_id: project_id_string private_key_id: private_key_id_string private_key: private_key_string client_email: client@example.com client_id: client_id_string auth_uri: http://example.com/auth_uri token_uri: http://example.com/token_uri auth_provider_x509_cert_url: http://example.com/provider_cert_url client_x509_cert_url: http://example.com/client_cert_url rootdirectory: /gcs/object/name/prefix chunksize: 5242880 s3: accesskey: awsaccesskey secretkey: awssecretkey region: us-west-1 regionendpoint: http://myobjects.local bucket: bucketname encrypt: true keyid: mykeyid secure: true v4auth: true chunksize: 5242880 multipartcopychunksize: 33554432 multipartcopymaxconcurrency: 100 multipartcopythresholdsize: 33554432 rootdirectory: /s3/object/name/prefix swift: username: username password: password authurl: https://storage.myprovider.com/auth/v1.0 or https://storage.myprovider.com/v2.0 or https://storage.myprovider.com/v3/auth tenant: tenantname tenantid: tenantid domain: domain name for Openstack Identity v3 API domainid: domain id for Openstack Identity v3 API insecureskipverify: true region: fr container: containername rootdirectory: /swift/object/name/prefix oss: accesskeyid: accesskeyid accesskeysecret: accesskeysecret region: OSS region name endpoint: optional endpoints internal: optional internal endpoint bucket: OSS bucket encrypt: optional enable server-side encryption encryptionkeyid: optional KMS key id for encryption secure: optional ssl setting chunksize: optional size valye rootdirectory: optional root directory inmemory: # This driver takes no parameters delete: enabled: false redirect: disable: false cache: blobdescriptor: redis maintenance: uploadpurging: enabled: true age: 168h interval: 24h dryrun: false readonly: enabled: falseauth: silly: realm: silly-realm service: silly-service token: autoredirect: true realm: token-realm service: token-service issuer: registry-token-issuer rootcertbundle: /root/certs/bundle htpasswd: realm: basic-realm path: /path/to/htpasswdmiddleware: registry: - name: ARegistryMiddleware options: foo: bar repository: - name: ARepositoryMiddleware options: foo: bar storage: - name: cloudfront options: baseurl: https://my.cloudfronted.domain.com/ privatekey: /path/to/pem keypairid: cloudfrontkeypairid duration: 3000s ipfilteredby: awsregion awsregion: us-east-1, use-east-2 updatefrenquency: 12h iprangesurl: https://ip-ranges.amazonaws.com/ip-ranges.json storage: - name: redirect options: baseurl: https://example.com/reporting: bugsnag: apikey: bugsnagapikey releasestage: bugsnagreleasestage endpoint: bugsnagendpoint newrelic: licensekey: newreliclicensekey name: newrelicname verbose: truehttp: addr: localhost:5000 prefix: /my/nested/registry/ host: https://myregistryaddress.org:5000 secret: asecretforlocaldevelopment relativeurls: false draintimeout: 60s tls: certificate: /path/to/x509/public key: /path/to/x509/private clientcas: - /path/to/ca.pem - /path/to/another/ca.pem letsencrypt: cachefile: /path/to/cache-file email: emailused@letsencrypt.com hosts: [myregistryaddress.org] debug: addr: localhost:5001 prometheus: enabled: true path: /metrics headers: X-Content-Type-Options: [nosniff] http2: disabled: falsenotifications: events: includereferences: true endpoints: - name: alistener disabled: false url: https://my.listener.com/event headers: &lt;http.Header&gt; timeout: 1s threshold: 10 backoff: 1s ignoredmediatypes: - application/octet-stream ignore: mediatypes: - application/octet-stream actions: - pullredis: addr: localhost:6379 password: asecret db: 0 dialtimeout: 10ms readtimeout: 10ms writetimeout: 10ms pool: maxidle: 16 maxactive: 64 idletimeout: 300shealth: storagedriver: enabled: true interval: 10s threshold: 3 file: - file: /path/to/checked/file interval: 10s http: - uri: http://server.to.check/must/return/200 headers: Authorization: [Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ==] statuscode: 200 timeout: 3s interval: 10s threshold: 3 tcp: - addr: redis-server.domain.com:6379 timeout: 3s interval: 10s threshold: 3proxy: remoteurl: https://registry-1.docker.io username: [username] password: [password]compatibility: schema1: signingkeyfile: /etc/registry/key.json enabled: truevalidation: manifests: urls: allow: - ^https?://([^/]+\.)*example\.com/ deny: - ^https?://www\.example\.com/ 和 proxy cache 相关的参数是 proxy 。 搭建 docker registryokay，下面我们通过原始dockerfile构建一个缓存私有仓库： 1.修改config-example.conf文件 由于本机是intel的64位系统，因此选择amd64，修改里面的config-example.conf: version: 0.1log: fields: service: registrystorage: cache: blobdescriptor: inmemory filesystem: rootdirectory: /var/lib/registryhttp: addr: :5000 headers: X-Content-Type-Options: [nosniff]health: storagedriver: enabled: true interval: 10s threshold: 3proxy: remoteurl: https://registry-1.docker.io 2.构建registry镜像 构建registry镜像:docker build -t docker-registry:v0.1 . 3.运行registry容器 运行registry容器: docker run -d -p 5000:5000 --restart=always --name docker-registry \ -v /home/registry:/var/lib/registry \ docker-registry:v0.1 或者可以直接将配置文件挂载进去：docker run -d -p 5000:5000 --restart=always --name docker-registry \ -v `pwd`/config-example.yml:/etc/docker/registry/config.yml \ -v /home/registry:/var/lib/registry \ docker-registry:v0.1 4.测试缓存是否生效 在测试的daemon.json配置目标地址：cat &gt; /etc/docker/daemon.json &lt;&lt; EOF &#123; "insecure-registries": ["10.10.6.111:5000"], "registry-mirrors":["http://10.10.6.111:5000"]&#125;EOF 重启容器服务service docker restart 测试：docker pull node:8.4.0-onbuild 用docker logs 查看 registry 容器： docker logs -f docker-registry time="2019-10-31T07:48:33.210442036Z" level=info msg="Adding new scheduler entry for library/node@sha256:0485a8f7251f7823455cb5efb010ee034e7b44b13414d11080c4daae8af1acb3 with ttl=167h59m59.999996323s" go.version=go1.11.2 instance.id=154296c5-33a6-44cc-bc25-9cb74eb2fc47 service=registry version=v2.7.1 time="2019-10-31T07:48:33.210850287Z" level=info msg="response completed" go.version=go1.11.2 http.request.host="10.10.6.111:5000" http.request.id=05a32ff6-54f1-4b70-b86e-1802959c0ff2 http.request.method=GET http.request.remoteaddr="10.10.6.19:60562" http.request.uri="/v2/library/node/manifests/8.4.0-onbuild" http.request.useragent="docker/19.03.3 go/go1.12.10 git-commit/a872fc2f86 kernel/3.10.0-1062.el7.x86_64 os/linux arch/amd64 UpstreamClient(Docker-Client/19.03.3 \(linux\))" http.response.contenttype="application/vnd.docker.distribution.manifest.v2+json" http.response.duration=3.632741932s http.response.status=200 http.response.written=2213 10.10.6.19 - - [31/Oct/2019:07:48:29 +0000] "GET /v2/library/node/manifests/8.4.0-onbuild HTTP/1.1" 200 2213 "" "docker/19.03.3 go/go1.12.10 git-commit/a872fc2f86 kernel/3.10.0-1062.el7.x86_64 os/linux arch/amd64 UpstreamClient(Docker-Client/19.03.3 \\(linux\\))"time="2019-10-31T07:48:35.734990871Z" level=info msg="response completed" go.version=go1.11.2 http.request.host="10.10.6.111:5000" http.request.id=76e0c7e6-b6e2-4d48-8baf-bcd296996e69 http.request.method=GET http.request.remoteaddr="10.10.6.19:60564" http.request.uri="/v2/library/node/blobs/sha256:d24de6795fb1d44f2ecd12ab0768fefb45c3a31674824961512f71fbf234a704" http.request.useragent="docker/19.03.3 go/go1.12.10 git-commit/a872fc2f86 kernel/3.10.0-1062.el7.x86_64 os/linux arch/amd64 UpstreamClient(Docker-Client/19.03.3 \(linux\))" http.response.contenttype="application/octet-stream" http.response.duration=2.522583499s http.response.status=200 http.response.written=8639 10.10.6.19 - - [31/Oct/2019:07:48:33 +0000] "GET /v2/library/node/blobs/sha256:d24de6795fb1d44f2ecd12ab0768fefb45c3a31674824961512f71fbf234a704 HTTP/1.1" 200 8639 "" "docker/19.03.3 go/go1.12.10 git-commit/a872fc2f86 kernel/3.10.0-1062.el7.x86_64 os/linux arch/amd64 UpstreamClient(Docker-Client/19.03.3 \\(linux\\))"time="2019-10-31T07:48:36.375234583Z" level=info msg="Adding new scheduler entry for library/node@sha256:d24de6795fb1d44f2ecd12ab0768fefb45c3a31674824961512f71fbf234a704 with ttl=167h59m59.999996974s" go.version=go1.11.2 instance.id=154296c5-33a6-44cc-bc25-9cb74eb2fc47 service=registry version=v2.7.1 从日志可以看出缓存成功了~ PS: 镜像第一次拉取还比较慢，第二次拉取速度立刻飞起~大家可以试试]]></content>
      <categories>
        <category>技术博文</category>
        <category>容器技术</category>
        <category>Dokcer</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>容器</tag>
        <tag>镜像仓库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单元测试中的打桩技术：mock浅谈]]></title>
    <url>%2F2019%2F%E9%9A%90%E8%97%8F%2F%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E4%B8%AD%E7%9A%84%E6%89%93%E6%A1%A9%E6%8A%80%E6%9C%AF%EF%BC%9Amock%E6%B5%85%E8%B0%88%2F</url>
    <content type="text"><![CDATA[背景测试从下到上大致可以分为单元测试、端到端测试和系统集成测试。 单元测试是最基础的，一般其代码量也是最多的，一般是针对函数、方法和类的测试，但其写好后改动一般是最小的，单元测试是其他测试的基石。端到端测试是基于单元测试之上的，主要针对API和接口的测试，由于只针对接口进行测试，相对单元测试，端到端测试代码量更少，但面对需求的变更其测试代码也更容易变更。系统集成测试主要是对整个系统进行测试，针对地是客户端的使用界面。 以现在主流的前后端分离来说明： 单元测试 端到端测试 系统集成测试 针对视图层中的某个视图方法的测试，或者针对模型层中某个orm的测试 模拟接口请求进行测试 模拟用户操作进行测试 介绍完测试的类型，下面主要介绍下单元测试中的mock技术。mock是一种用于单元测试数据模拟的技术，俗称打桩技术。mock的好处：1、并行工作：借助mock，接口之间可以实现解耦合，实现测试驱动开发2、隔离系统：可以模拟请求，避免数据库的污染，同时可以做界面演示 Go 语言中的 mockGo中mock可以使用官方的GoMock包，以本人的https://github.com/shikanon/socks5proxy项目为例，来介绍 mock 在 Go 的单元测试中的使用。 mock 安装go get -u github.com/golang/mock/gomockgo install github.com/golang/mock/mockgen mockgen 生成 mock 文件Go 提供了 mockgen 工具，用来生成:mockgen -source=socks5.go -destination=./mock/socks5_mock.go -package=mock mockgen是根据接口发射的方式生成mock，所以source里面必须要有interface。当然，也可以直接在注释前加入注释再借助 go generate 来生成，如：//go:generate mockgen -source=socks5.go -destination=./mock/socks5_mock.go -package=mocktype Protocol interface &#123; HandleHandshake(b []byte) ([]byte, error) SentHandshake(conn net.Conn) error&#125; 在项目目录下运行：go generate func (c *Call) After(preReq *Call) *Callfunc (c *Call) AnyTimes() *Callfunc (c *Call) Do(f interface&#123;&#125;) *Callfunc (c *Call) MaxTimes(n int) *Callfunc (c *Call) MinTimes(n int) *Callfunc (c *Call) Return(rets ...interface&#123;&#125;) *Callfunc (c *Call) SetArg(n int, value interface&#123;&#125;) *Callfunc (c *Call) String() stringfunc (c *Call) Times(n int) *Call Python 语言中的 mock]]></content>
      <categories>
        <category>技术博文</category>
        <category>编程语言</category>
        <category>GO</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>单元测试</tag>
        <tag>GO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于k8s的Ingress部署hexo博客(http和https)]]></title>
    <url>%2F2019%2F%E8%BF%90%E7%BB%B4%2F%E5%9F%BA%E4%BA%8Ek8s%E7%9A%84Ingress%E9%83%A8%E7%BD%B2hexo%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[注：kuberntes版本为1.15 什么是 IngressIngress 是一个提供对外服务的路由和负载均衡器，其本质是个nginx控制器服务。 k8s文档上Ingress经典数据链路图： internet |[ Ingress ]--|-----|--[ Services ] 对博客进行改造Nginx版构建Dockefile先容器化整个Hexo项目，构建Dockefile，这里采用nginx + 静态资源的形式部署（主要为了节约内存CPU）:FROM nginx:1.13.0-alpineLABEL maintainer="hexo-shikanon-blog &lt;shikanon@tensorbytes.com&gt;"# 装载编译后的文件对外访问COPY ./public /usr/share/nginx/html 构建Deployment构建一个Deployment服务将其部署上kubernetes: apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-hexo-blog-delopyment labels: webtype: staticblogspec: replicas: 2 selector: matchLabels: webtype: staticblog template: metadata: labels: webtype: staticblog function: blog spec: containers: - name: hexo-blog image: nginx-hexo-blog:0.0.1 ports: - containerPort: 80 构建Service暴露服务端口构建一个Service暴露统一的服务端口： apiVersion: v1kind: Servicemetadata: name: static-blogspec: selector: webtype: staticblog ports: - protocol: TCP port: 80 targetPort: 80 # deployment的端口， 这里创建一个名称为 “static-blog” 的 Service 对象，它会将请求代理到使用 TCP 端口 targetPort，并且具有标签 “webtype: staticblog” 的 Pod 上。 查看端口信息： $ kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.13.0.1 443/TCP 10d static-blog ClusterIP 10.13.83.44 80/TCP 8h 测试端口是否可以访问： $ curl -I 10.13.83.44 HTTP/1.1 200 OK Server: nginx/1.13.0 Date: Wed, 16 Oct 2019 16:51:13 GMT Content-Type: text/html Content-Length: 71636 Last-Modified: Mon, 29 Jul 2019 19:25:29 GMT Connection: keep-alive ETag: “5d3f4829-117d4” Accept-Ranges: bytes 构建Ingress服务最后一步，构建Ingress服务对外部提供服务和反向代理： apiVersion: extensions/v1beta1kind: Ingressmetadata: name: reverse-proxy annotations: nginx.ingress.kubernetes.io/rewrite-target: /spec: rules: - host: www.shikanon.com http: paths: - backend: serviceName: static-blog servicePort: 80 完成! Nodejs版Node版和Nginx版的主要区别是 dockefile 构建不同:FORM node:8.16-onbuildLABEL maintainer="hexo-shikanon-blog &lt;shikanon@tensorbytes.com&gt;"# 将源码文件放入目录COPY . /app# 安装安装包npm install hexo -g --registry=https://registry.npm.taobao.orgCMD ["hexo","run","serve"] 构建HTTPS网站用secret类型对象保存密钥数据Secret 对象类型用来保存敏感信息，例如密码、OAuth 令牌和 ssh key，其中 ssh key 就是一个经典的应用。 Secret 参数用例:kubectl create secret -hCreate a secret using specified subcommand.Available Commands: docker-registry Create a secret for use with a Docker registry generic Create a secret from a local file, directory or literal value tls Create a TLS secretUsage: kubectl create secret [flags] [options] 创建Secret加密对象:kubectl create secret tls shikanon-ssh-key-secret --cert=/home/shikanon/web/www/ssl/cert.pem --key=/home/shikanon/web/www/ssl/private.key 修改Ingress:apiVersion: extensions/v1beta1kind: Ingressmetadata: name: reverse-proxy annotations: nginx.ingress.kubernetes.io/rewrite-target: /spec: rules: - host: www.shikanon.com http: paths: - backend: serviceName: static-blog servicePort: 80 tls: - hosts: - www.shikanon.com secretName: shikanon-ssh-key-secret 注：一个Ingress只能支持一个tls 我的博客即将同步至腾讯云+社区，邀请大家一同入驻：https://cloud.tencent.com/developer/support-plan?invite_code=1njpdx5b5diz4]]></content>
      <categories>
        <category>技术博文</category>
        <category>容器技术</category>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>部署</tag>
        <tag>Ingress</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[生活小感悟，技术小总结]]></title>
    <url>%2F2019%2F%E7%94%9F%E6%B4%BB%2F%E7%94%9F%E6%B4%BB%E5%B0%8F%E6%84%9F%E6%82%9F%EF%BC%8C%E6%8A%80%E6%9C%AF%E5%B0%8F%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[算法基础 排序算法总结 算法名词 平均时间复杂度 最好时间复杂度 最坏时间复杂度 空间复杂度 稳定性 冒泡排序 O(n2) O(n) O(n2) O(1) 稳定 选择排序 O(n2) O(n2) O(n2) O(1) 不稳定 插入排序 O(n2) O(n) O(n2) O(1) 稳定 快速排序 O(N*logN) O(N*logN) O(n2) O(N*logN) 不稳定 归并排序 O(N*logN) O(N*logN) O(N*logN) O(n) 稳定 堆排序 O(N*logN) O(N*logN) O(N*logN) O(1) 不稳定 冒泡排序通过两两比较进行排序 快速排序就是采用分治的思想，先排好一堆再排一堆：随机取一个数，大的放右边，小的放左边，对这个数排好后再对小的那堆用同样方法排序，依次递归。 选择排序就是选最小，每次从无序空间选出最小的放到有序空间 插入排序就是在插入时候进行排序，每从无序空间随便选一个数和有序空间逐一比较来插入 归并排序也是用了分治，先排好一堆再排一堆，特点就是一直分，到最小单元然后再一个个排好序（治），因此是不管什么情况时间复杂度都是O(N*logN)，反正要切分到最小。 数据库MySQL 索引的作用是加快数据的查询速度，副作用是增加了插入的开销。 Innodb 存储引擎的 B-Tree 索引是 B+Tree，也就是在每一个Leaf Node 上面除了索引还有下一个LeafNode 的指针信息，这主要是为了加快检索多个相邻 Leaf Node 的效率考虑。 MySQL 中的 B-Tree 索引的物理文件大多都是以 Balance Tree 的结构来存储的，其到每个 LeafNode 的最短路径的长度都是相同的 索引的实现方式：1.跳表，适合等值查询，不支持范围查询2.有序数组，适合范围查询，但是插入数据效率低，因为需要挪动数据3.n叉树，支持等值查询以及范围查询，是个折中方案。大部分数据库都是采用这种数据结构构建索引。 mysql的myisam与innodb在执行没有带条件的count(*)语句的时候，实现的思路是不一样的。 myisam会在写入的时候记录总记录数在查询的时候直接读取，因此速度快。而innodb因为支持事务，且默认的事务隔离级别是可重复读，其MVCC设计实现使得其必须每次都要一行行计算，因此速度不如myisam。 Innodb的表是索引组织表，主键索引的叶子存的正行数据，而普通索引存储的是主键的id。普通索引需要再通过主键索引找到数据。 Mysql有3种锁，全局锁，表级锁，行级锁 Mysql中的锁会在需要的时候获取，但是只会在事务结束后才释放。因此对于一个事务中，对于那些争用锁较多的操作尽量放在后面，减少持有锁的时间，提高并发度。 在更新的时候，如果数据页在内存中，普通索引和唯一索引之间的区别就一个判断，性能相差不大。但是当数据页不在内存中，唯一索引需要将数据页加载到内存，而普通索引则是直接写入Change buffer，不需要从磁盘加载数据页。 当需要读取更新的数据的时候，会立即触发Change buffer的merge操作写入磁盘。因此change buffer适合写多读少的场景。 对字符串字段做索引，可以整个字段作为索引值，也可以使用前缀作为索引，或者新增字符串hash值列做索引。使用前缀作为索引的时候，要考虑各个长度的区分度问题。长度选择合适的情况，可以做到既不增加磁盘读取次数，又能节省磁盘空间的好处。前缀索引的弊端是不能使用覆盖索引。前缀索引在身份证这种前面N个字符大量相同的情况下，可以对字符串先进行倒序存储然后再做前缀索引。 mysql内存中的脏数据flush到磁盘的时候可能会出现性能抖动。mysql会在以下4种情况flush脏数据到内存中（1）redo日志满了（2）内存放不下脏数据了（3）空闲时间（4）shutdown前特别要注意第一和第二种情况，大多数性能抖动问题就是这两种导致的 编程语言Golang篇 对于GC很高的，可以尝试用sync.Pool做优化，sync.Pool 是减少GC的利器]]></content>
      <categories>
        <category>生活技能</category>
        <category>网站笔记</category>
      </categories>
      <tags>
        <tag>感悟</tag>
        <tag>思考</tag>
        <tag>灵光</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[golang的sync包系列讲解(1):sync.Map]]></title>
    <url>%2F2019%2F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%2Fgolang%E7%9A%84sync%E5%8C%85%E7%B3%BB%E5%88%97%E8%AE%B2%E8%A7%A3-1-sync-Map%2F</url>
    <content type="text"><![CDATA[sync.Map是一个线程安全的map结构，一般用于多读少写的并发操作，下图是sync.Map的数据结构 图引至码农桃花源公众号 type Map struct &#123; mu Mutex read atomic.Value // readOnly dirty map[interface&#123;&#125;]*entry misses int&#125; mu是Map的互斥锁用于对并发操作进行加锁保护，read是用于存储只读内容的，可以提供高并发的读操作。 dirty是一个原始的map结构体，对dirty的操作需要加锁，dirty包涵了全量的数据，在读数据的时候会先读取read，read读取不到再读dirty。 misses 是read读取失败的次数，当多次读取失败后 misses 累计特定值，dirty就会升级成read。sync.Map 这里采用的策略类似数据库常用的”读写分离”，技术都是相通的O(∩_∩)O sync.Map用法func main() &#123; var value sync.Map // 写入 value.Store("your name", "shi") value.Store("her name", "kanon") // 读取 name, ok := value.Load("your name") if !ok &#123; println("can't find name") &#125; fmt.Println(name) // 遍历 value.Range(func(ki, vi interface&#123;&#125;) bool &#123; k, v := ki.(string), vi.(string) fmt.Println(k, v) return true &#125;) // 删除 value.Delete("your name") // 读取，如果不存在则写入 activename, loaded := value.LoadOrStore("his name", "baba") fmt.Println(activename.(string), loaded)&#125; 官方的单元测试用例从官方单元测试学习 sync.Map 使用： func TestConcurrentRange(t *testing.T) &#123; const mapSize = 1 &lt;&lt; 10 m := new(sync.Map) for n := int64(1); n &lt;= mapSize; n++ &#123; m.Store(n, int64(n)) &#125; done := make(chan struct&#123;&#125;) var wg sync.WaitGroup defer func() &#123; close(done) wg.Wait() &#125;() for g := int64(runtime.GOMAXPROCS(0)); g &gt; 0; g-- &#123; r := rand.New(rand.NewSource(g)) wg.Add(1) go func(g int64) &#123; defer wg.Done() for i := int64(0); ; i++ &#123; select &#123; case &lt;-done: return default: &#125; for n := int64(1); n &lt; mapSize; n++ &#123; if r.Int63n(mapSize) == 0 &#123; m.Store(n, n*i*g) &#125; else &#123; m.Load(n) &#125; &#125; &#125; &#125;(g) &#125; iters := 1 &lt;&lt; 10 if testing.Short() &#123; iters = 16 &#125; for n := iters; n &gt; 0; n-- &#123; seen := make(map[int64]bool, mapSize) m.Range(func(ki, vi interface&#123;&#125;) bool &#123; k, v := ki.(int64), vi.(int64) if v%k != 0 &#123; t.Fatalf("while Storing multiples of %v, Range saw value %v", k, v) &#125; if seen[k] &#123; t.Fatalf("Range visited key %v twice", k) &#125; seen[k] = true return true &#125;) if len(seen) != mapSize &#123; t.Fatalf("Range visited %v elements of %v-element Map", len(seen), mapSize) &#125; &#125;&#125; 原理结构这里从几个方法的源码展开讲解： Loadfunc (m *Map) Load(key interface&#123;&#125;) (value interface&#123;&#125;, ok bool) &#123; // 首先从只读字段读取内容 read, _ := m.read.Load().(readOnly) e, ok := read.m[key] // 如果没读到，并且dirty有read没有数据则从dirty中读取 if !ok &amp;&amp; read.amended &#123; m.mu.Lock() // 在从dirty读取前需要加锁后再做一次验证，防止期间read突然有数据，也就是double check read, _ = m.read.Load().(readOnly) e, ok = read.m[key] if !ok &amp;&amp; read.amended &#123; e, ok = m.dirty[key] // 将此次记录记录添加到miss中，可以看到这里没对dirty的取值做判断，也就是说不管是否 // 取到miss都会添加一次 m.missLocked() &#125; m.mu.Unlock() &#125; if !ok &#123; return nil, false &#125; return e.load()&#125; Load方法讲解：首先从只读字段read中读取键值的内容，如果没读到，并且amended为true(dirty有read没有数据)则尝试从dirty中读取，不过这里要做 double check， 然后将此次缓存穿透记录一次到miss字段。 Storefunc (m *Map) Store(key, value interface&#123;&#125;) &#123; // 存储之前先从只读字段读取要存储的值，如果存在，则用CAS的方式将新的值存储进去 read, _ := m.read.Load().(readOnly) // tryStore 会检查dirty的keys值是否已经删除， // 如果没有删除标记，则直接采用CAS方式存储entry if e, ok := read.m[key]; ok &amp;&amp; e.tryStore(&amp;value) &#123; return &#125; m.mu.Lock() // double check read, _ = m.read.Load().(readOnly) if e, ok := read.m[key]; ok &#123; // double check 如果read存在，调用 unexpungeLocked 将 expunged 设置为 nil， // 然后更新dirty，expunged 表示dirty中记录的删除标识（read没同步），由于有新的值存储需要 // 将删除标识更新。 if e.unexpungeLocked() &#123; m.dirty[key] = e &#125; e.storeLocked(&amp;value) &#125; else if e, ok := m.dirty[key]; ok &#123; // 如果read中没有对应的键，从dirty中有则直接更新dirty中的键 e.storeLocked(&amp;value) &#125; else &#123; // dirty 和 read 都不存在这个键的情况 if !read.amended &#123; // amended为true标识dirty包含read没有的key，由于dirty是最全的数据，amend为false只有两种 // 情况，一种就是 dirty 的键值等于 read 的键值，一种是dirty为空的时候，所以这里只有可能是 // 第二种，也就是dirty为空，因此再store 之前先判断一下 dirty map 是否为空，如果为空，就把 read map 浅拷贝一次。 m.dirtyLocked() m.read.Store(readOnly&#123;m: read.m, amended: true&#125;) &#125; // 如果dirty数据和read的key不同步数据，直接将值写入dirty m.dirty[key] = newEntry(value) &#125; m.mu.Unlock()&#125; Store方法讲解：存储之前先从只读字段 read 中读取要存储的值，在read中存在键值对的时候，则用 CAS 的方式将新的值存储进去，如果不存在则加锁做个 double check，将新数据写入 dirty 中。如果 dirty 和 read 中都没数据，dirty 和 read 的键值不同步，则将数据直接写入 dirty， 如果 dirty 键值数据和 read 一样，同时 dirty 为 nil ，将 read 浅拷贝 一份到 dirty，为后面赋值可以同时写入 dirty 和 read。 Deletefunc (m *Map) Delete(key interface&#123;&#125;) &#123; m.LoadAndDelete(key)&#125;func (m *Map) LoadAndDelete(key interface&#123;&#125;) (value interface&#123;&#125;, loaded bool) &#123; read, _ := m.read.Load().(readOnly) e, ok := read.m[key] if !ok &amp;&amp; read.amended &#123; m.mu.Lock() read, _ = m.read.Load().(readOnly) e, ok = read.m[key] if !ok &amp;&amp; read.amended &#123; e, ok = m.dirty[key] m.missLocked() &#125; m.mu.Unlock() &#125; if ok &#123; return e.delete() &#125; return nil, false&#125;func (e *entry) delete() (value interface&#123;&#125;, ok bool) &#123; for &#123; p := atomic.LoadPointer(&amp;e.p) if p == nil || p == expunged &#123; return nil, false &#125; if atomic.CompareAndSwapPointer(&amp;e.p, p, nil) &#123; return *(*interface&#123;&#125;)(p), true &#125; &#125;&#125; Delete方法讲解：sync.Map的 Delete 方法本质是用的 读取和删除，也就是先读取到数据再对数据进行删除，读的方法和 Load 的方法是一样的，这里就不再赘述了。 Rangefunc (m *Map) Range(f func(key, value interface&#123;&#125;) bool) &#123; // 如果amend为ture，说明dirty包含了read所有的key，将dirty提升为read， // 并将dirty设置为nil，之后用Store存储新的值的时候再拷贝回来 // 最后对read进行遍历即可 read, _ := m.read.Load().(readOnly) if read.amended &#123; m.mu.Lock() read, _ = m.read.Load().(readOnly) if read.amended &#123; read = readOnly&#123;m: m.dirty&#125; m.read.Store(read) m.dirty = nil m.misses = 0 &#125; m.mu.Unlock() &#125; for k, e := range read.m &#123; v, ok := e.load() if !ok &#123; continue &#125; if !f(k, v) &#123; break &#125; &#125;&#125; Range原理讲解：Range 本质是通过遍历只读字段 read 得到，为了让只读字段包含所有数据，当 dirty 和 read 不相等的时候，将 dirty 升级为 read， 最后再对 read 进行遍历即可。]]></content>
      <categories>
        <category>技术博文</category>
        <category>编程语言</category>
        <category>GO</category>
      </categories>
      <tags>
        <tag>sync</tag>
        <tag>golang</tag>
        <tag>异步</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Federated Learning 联合学习]]></title>
    <url>%2F2019%2F%E9%9A%90%E8%97%8F%2FFederated-Learning-%E8%81%94%E5%90%88%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[【等待更新】 背景现状什么是Federated Learning？Federated Learning，也叫联邦学习，是一种通过加密混淆技术实现数据安全的分布式联合建模的方法，Federated Learning的基础是安全多方计算，一种分布式密码协议。 安全多方计算是什么？安全多方计算(Secure Multi-Party Computation, MPC)，1982年由图灵奖获得者姚期智院士提出，协议允许多个数据所有者在互不信任的情况下进行协同计算，输出计算结果，并保证任何一方均无法得到除应得的计算结果之外的其他任何信息。 数学描述为 $P={P_1,…,P_n}$ 实现安全多方计算的方法有多种，比如不经意传输协议、秘密共享协议、 不经意传输协议 不经意传输协议(oblivious transfer protocols, OT) 相关技术简介Federated Learning 的应用Federated Learning 在企业联合建模中的应用Federated Learning 在边缘计算的应用]]></content>
      <categories>
        <category>技术博文</category>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>联合学习</tag>
        <tag>隐私保护</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BERT代码实现及解读]]></title>
    <url>%2F2019%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2FBERT%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E5%8F%8A%E8%A7%A3%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[注意力机制系列可以参考前面的一文： 注意力机制及其理解 Transformer BlockBERT中的点积注意力模型公式： $$ \text{Attention}(\boldsymbol{Q},\boldsymbol{K},\boldsymbol{V}) = \text{softmax}(\frac{\boldsymbol{Q}\boldsymbol{K}^T}{\sqrt{d_k}})\boldsymbol{V} $$ 代码： class Attention(nn.Module): """ Scaled Dot Product Attention """ def forward(self, query, key, value, mask=None, dropout=None): scores = torch.matmul(query, key.transpose(-2, -1)) \ / math.sqrt(query.size(-1)) if mask is not None: scores = scores.masked_fill(mask == 0, -1e9) # softmax得到概率得分p_atten, p_attn = F.softmax(scores, dim=-1) # 如果有 dropout 就随机 dropout 比例参数 if dropout is not None: p_attn = dropout(p_attn) return torch.matmul(p_attn, value), p_attn 在 𝑠𝑒𝑙𝑓 𝑎𝑡𝑡𝑒𝑛𝑡𝑖𝑜𝑛 的计算过程中, 通常使用 𝑚𝑖𝑛𝑖 𝑏𝑎𝑡𝑐ℎ 来计算, 也就是一次计算多个句子，多句话得长度并不一致，因此，我们需要按照最大得长度对短句子进行补全，也就是padding零，但这样做得话，softmax计算就会被影响，$e^0=1$也就是有值，这样就会影响结果，这并不是我们希望看到得，因此在计算得时候我们需要把他们mask起来，填充一个负无穷（-1e9这样得数值），这样计算就可以为0了，等于把计算遮挡住。 多头自注意力模型公式： $$ \text{MultiHead}(Q,K,V) = \text{Concat}(\text{head1},...,\text{head}_h)\boldsymbol{W}^O $$ $$ \text{head}_i = \text{Attention}(\boldsymbol{Q}\boldsymbol{W}_i^Q,\boldsymbol{K}\boldsymbol{W}_i^K,\boldsymbol{V}\boldsymbol{W}_i^V) $$ $$ \text{Attention}(\boldsymbol{Q},\boldsymbol{K},\boldsymbol{V}) = \text{softmax}(\frac{\boldsymbol{Q}\boldsymbol{K}^T}{\sqrt{d_k}})\boldsymbol{V} $$ Attention Mask 代码： class MultiHeadedAttention(nn.Module): """ Take in model size and number of heads. """ def __init__(self, h, d_model, dropout=0.1): # h 表示模型个数 super().__init__() assert d_model % h == 0 # d_k 表示 key长度，d_model表示模型输出维度，需保证为h得正数倍 self.d_k = d_model // h self.h = h self.linear_layers = nn.ModuleList([nn.Linear(d_model, d_model) for _ in range(3)]) self.output_linear = nn.Linear(d_model, d_model) self.attention = Attention() self.dropout = nn.Dropout(p=dropout) def forward(self, query, key, value, mask=None): batch_size = query.size(0) # 1) Do all the linear projections in batch from d_model =&gt; h x d_k query, key, value = [l(x).view(batch_size, -1, self.h, self.d_k).transpose(1, 2) for l, x in zip(self.linear_layers, (query, key, value))] # 2) Apply attention on all the projected vectors in batch. x, attn = self.attention(query, key, value, mask=mask, dropout=self.dropout) # 3) "Concat" using a view and apply a final linear. x = x.transpose(1, 2).contiguous().view(batch_size, -1, self.h * self.d_k) return self.output_linear(x) Position-wise FFNPosition-wise FFN 是一个双层得神经网络，在论文中采用ReLU做激活层： 公式： $$ \text{FFN}(x) = \text{max}(0, x\boldsymbol{W}_1 + b_1)\boldsymbol{W}_2 + b_2 $$ 注：在 google github中的BERT的代码实现中用Gaussian Error Linear Unit代替了RelU作为激活函数 代码：class PositionwiseFeedForward(nn.Module): def __init__(self, d_model, d_ff, dropout=0.1): super(PositionwiseFeedForward, self).__init__() self.w_1 = nn.Linear(d_model, d_ff) self.w_2 = nn.Linear(d_ff, d_model) self.dropout = nn.Dropout(dropout) self.activation = GELU() def forward(self, x): return self.w_2(self.dropout(self.activation(self.w_1(x))))class GELU(nn.Module): """ Gaussian Error Linear Unit. This is a smoother version of the RELU. Original paper: https://arxiv.org/abs/1606.08415 """ def forward(self, x): return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3)))) Layer NormalizationLayerNorm实际就是对隐含层做层归一化，即对某一层的所有神经元的输入进行归一化（沿着通道channel方向），使得其加快训练速度： 层归一化公式： $$ \sigma^l = \sqrt{\frac{1}{\boldsymbol{H}}\sum_{i=1}^{\boldsymbol{H}}(x_i^l-\mu^l)^2} \\ \mu^l = \frac{1}{\boldsymbol{H}}\sum_{i=1}^{\boldsymbol{H}}x_i^l \\ x^l = w_i^l h^l $$ $l$表示第L层，H 是指每层的隐藏单元数(hidden unit),$\mu$表示平均值，$\sigma$表示方差, $\alpha$表示表征向量，$w$表示矩阵权重。 $$ \text{LayerNorm}(x) = \alpha \odot \frac{x - \mu}{\sqrt{\sigma^2+\epsilon}} + \beta $$ 注：$\odot$表示元素相乘其中，$\alpha$和$\beta$、$\epsilon$为超参数。 代码：class LayerNorm(nn.Module): "Construct a layernorm module (See citation for details)." def __init__(self, features, eps=1e-6): super(LayerNorm, self).__init__() self.a_2 = nn.Parameter(torch.ones(features)) self.b_2 = nn.Parameter(torch.zeros(features)) self.eps = eps def forward(self, x): # mean(-1) 表示 mean(len(x)), 这里的-1就是最后一个维度，也就是最里面一层的维度 mean = x.mean(-1, keepdim=True) std = x.std(-1, keepdim=True) return self.a_2 * (x - mean) / (std + self.eps) + self.b_2 残差连接残差连接就是图中Add+Norm层。每经过一个模块的运算, 都要把运算之前的值和运算之后的值相加, 从而得到残差连接，残差可以使梯度直接走捷径反传到最初始层。 残差连接公式： $$ \boldsymbol{y} = f(\boldsymbol{x}) + \boldsymbol{x} $$ X 表示输入的变量，实际就是跨层相加。 代码：class SublayerConnection(nn.Module): """ A residual connection followed by a layer norm. Note for code simplicity the norm is first as opposed to last. """ def __init__(self, size, dropout): super(SublayerConnection, self).__init__() self.norm = LayerNorm(size) self.dropout = nn.Dropout(dropout) def forward(self, x, sublayer): "Apply residual connection to any sublayer with the same size." # Add and Norm return x + self.dropout(sublayer(self.norm(x))) Transform Block 代码：class TransformerBlock(nn.Module): """ Bidirectional Encoder = Transformer (self-attention) Transformer = MultiHead_Attention + Feed_Forward with sublayer connection """ def __init__(self, hidden, attn_heads, feed_forward_hidden, dropout): """ :param hidden: hidden size of transformer :param attn_heads: head sizes of multi-head attention :param feed_forward_hidden: feed_forward_hidden, usually 4*hidden_size :param dropout: dropout rate """ super().__init__() # 多头注意力模型 self.attention = MultiHeadedAttention(h=attn_heads, d_model=hidden) # PFFN self.feed_forward = PositionwiseFeedForward(d_model=hidden, d_ff=feed_forward_hidden, dropout=dropout) # 输入层 self.input_sublayer = SublayerConnection(size=hidden, dropout=dropout) # 输出层 self.output_sublayer = SublayerConnection(size=hidden, dropout=dropout) self.dropout = nn.Dropout(p=dropout) def forward(self, x, mask): x = self.input_sublayer(x, lambda _x: self.attention.forward(_x, _x, _x, mask=mask)) x = self.output_sublayer(x, self.feed_forward) return self.dropout(x) Embedding嵌入层Embedding采用三种相加的形式表示： 代码：class BERTEmbedding(nn.Module): """ BERT Embedding which is consisted with under features 1. TokenEmbedding : normal embedding matrix 2. PositionalEmbedding : adding positional information using sin, cos 3. SegmentEmbedding : adding sentence segment info, (sent_A:1, sent_B:2) sum of all these features are output of BERTEmbedding """ def __init__(self, vocab_size, embed_size, dropout=0.1): """ :param vocab_size: total vocab size :param embed_size: embedding size of token embedding :param dropout: dropout rate """ super().__init__() self.token = TokenEmbedding(vocab_size=vocab_size, embed_size=embed_size) self.position = PositionalEmbedding(d_model=self.token.embedding_dim) self.segment = SegmentEmbedding(embed_size=self.token.embedding_dim) self.dropout = nn.Dropout(p=dropout) self.embed_size = embed_size def forward(self, sequence, segment_label): x = self.token(sequence) + self.position(sequence) + self.segment(segment_label) return self.dropout(x) 位置编码(Positional Embedding) 位置嵌入的维度为 [𝑚𝑎𝑥 𝑠𝑒𝑞𝑢𝑒𝑛𝑐𝑒 𝑙𝑒𝑛𝑔𝑡ℎ, 𝑒𝑚𝑏𝑒𝑑𝑑𝑖𝑛𝑔 𝑑𝑖𝑚𝑒𝑛𝑠𝑖𝑜𝑛] , 嵌入的维度同词向量的维度, 𝑚𝑎𝑥 𝑠𝑒𝑞𝑢𝑒𝑛𝑐𝑒 𝑙𝑒𝑛𝑔𝑡ℎ 属于超参数, 指的是限定的最大单个句长. 公式： $$ \boldsymbol{P}_{i,2j} = \text{sin}(\frac{i}{10000^{2j/d}}) $$ $$ \boldsymbol{P}_{i,2j+1} = \text{sin}(\frac{i}{10000^{2j/d}}) $$ $$ \boldsymbol{H} = \boldsymbol{X} + \boldsymbol{P}, \\ \boldsymbol{X} \in \Bbb{R}, \boldsymbol{P} \in \Bbb{R} $$ 其所绘制的图形： 代码：class PositionalEmbedding(nn.Module): def __init__(self, d_model, max_len=512): super().__init__() # Compute the positional encodings once in log space. pe = torch.zeros(max_len, d_model).float() pe.require_grad = False position = torch.arange(0, max_len).float().unsqueeze(1) div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp() pe[:, 0::2] = torch.sin(position * div_term) pe[:, 1::2] = torch.cos(position * div_term) # 对数据维度进行扩充，扩展第0维 pe = pe.unsqueeze(0) # 添加一个持久缓冲区pe,缓冲区可以使用给定的名称作为属性访问 self.register_buffer('pe', pe) def forward(self, x): return self.pe[:, :x.size(1)] Segment Embedding主要用来做额外句子或段落划分新够词，这里加入了三个维度，分别是句子开头【CLS】,下一句【STEP】,遮盖词【MASK】例如： [CLS] the man went to the store [SEP] he bought a gallon of milk [SEP] 代码：class SegmentEmbedding(nn.Embedding): def __init__(self, embed_size=512): # 3个新词 super().__init__(3, embed_size, padding_idx=0) Token Embedding代码：class TokenEmbedding(nn.Embedding): def __init__(self, vocab_size, embed_size=512): super().__init__(vocab_size, embed_size, padding_idx=0) BERTclass BERT(nn.Module): """ BERT model : Bidirectional Encoder Representations from Transformers. """ def __init__(self, vocab_size, hidden=768, n_layers=12, attn_heads=12, dropout=0.1): """ :param vocab_size: 所有字的长度 :param hidden: BERT模型隐藏层大小 :param n_layers: Transformer blocks(layers)数量 :param attn_heads: 多头注意力head数量 :param dropout: dropout rate """ super().__init__() self.hidden = hidden self.n_layers = n_layers self.attn_heads = attn_heads # paper noted they used 4*hidden_size for ff_network_hidden_size self.feed_forward_hidden = hidden * 4 # 嵌入层, positional + segment + token self.embedding = BERTEmbedding(vocab_size=vocab_size, embed_size=hidden) # 多层transformer blocks self.transformer_blocks = nn.ModuleList( [TransformerBlock(hidden, attn_heads, hidden * 4, dropout) for _ in range(n_layers)]) def forward(self, x, segment_info): # attention masking for padded token # torch.ByteTensor([batch_size, 1, seq_len, seq_len) mask = (x &gt; 0).unsqueeze(1).repeat(1, x.size(1), 1).unsqueeze(1) # embedding the indexed sequence to sequence of vectors x = self.embedding(x, segment_info) # 多个transformer 堆叠 for transformer in self.transformer_blocks: x = transformer.forward(x, mask) return x 语言模型训练的几点技巧BERT如何做到自训练的，一下是几个小tip，让其做到自监督训练: Mask随机遮盖或替换一句话里面任意字或词, 然后让模型通过上下文的理解预测那一个被遮盖或替换的部分, 之后做𝐿𝑜𝑠𝑠的时候只计算被遮盖部分的𝐿𝑜𝑠𝑠。 随机把一句话中 15% 的 𝑡𝑜𝑘𝑒𝑛 替换成以下内容: 1) 这些 𝑡𝑜𝑘𝑒𝑛 有 80% 的几率被替换成 【𝑚𝑎𝑠𝑘】 ; 2) 有 10% 的几率被替换成任意一个其他的 𝑡𝑜𝑘𝑒𝑛 ; 3) 有 10% 的几率原封不动. 让模型预测和还原被遮盖掉或替换掉的部分，损失函数只计算随机遮盖或替换部分的Loss。 代码：class MaskedLanguageModel(nn.Module): """ predicting origin token from masked input sequence n-class classification problem, n-class = vocab_size """ def __init__(self, hidden, vocab_size): """ :param hidden: output size of BERT model :param vocab_size: total vocab size """ super().__init__() self.linear = nn.Linear(hidden, vocab_size) self.softmax = nn.LogSoftmax(dim=-1) def forward(self, x): return self.softmax(self.linear(x)) 预测下一句代码：class NextSentencePrediction(nn.Module): """ 2-class classification model : is_next, is_not_next """ def __init__(self, hidden): """ :param hidden: BERT model output size """ super().__init__() self.linear = nn.Linear(hidden, 2) # 这里采用了logsoftmax代替了softmax， # 当softmax值远离真实值的时候梯度也很小，logsoftmax的梯度会更好些 self.softmax = nn.LogSoftmax(dim=-1) def forward(self, x): return self.softmax(self.linear(x[:, 0])) 损失函数负对数最大似然损失(negative log likelihood)，也叫交叉熵(Cross-Entropy)公式： $$ E(t,y) = -\sum_i t_i \text{log}y_i $$ 代码：# 在Pytorch中 CrossEntropyLoss()等于NLLLoss+ softmax，因此如果用CrossEntropyLoss最后一层就不用softmax了criterion = nn.NLLLoss(ignore_index=0)# 2-1. NLL(negative log likelihood) loss of is_next classification resultnext_loss = criterion(next_sent_output, data["is_next"])# 2-2. NLLLoss of predicting masked token wordmask_loss = criterion(mask_lm_output.transpose(1, 2), data["bert_label"])# 2-3. Adding next_loss and mask_loss : 3.4 Pre-training Procedureloss = next_loss + mask_loss 语言模型训练代码：class BERTLM(nn.Module): """ BERT Language Model Next Sentence Prediction Model + Masked Language Model """ def __init__(self, bert: BERT, vocab_size): """ :param bert: BERT model which should be trained :param vocab_size: total vocab size for masked_lm """ super().__init__() self.bert = bert self.next_sentence = NextSentencePrediction(self.bert.hidden) self.mask_lm = MaskedLanguageModel(self.bert.hidden, vocab_size) def forward(self, x, segment_label): x = self.bert(x, segment_label) return self.next_sentence(x), self.mask_lm(x) 云端部署BERT SERVICE下载BERT预训练模型： BERT-as-service架构： 先建立service容器搭建kubernetes服务###]]></content>
      <categories>
        <category>技术博文</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>NLP</tag>
        <tag>注意力机制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[注意力机制及其理解]]></title>
    <url>%2F2019%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2F%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E5%8F%8A%E5%85%B6%E6%84%8F%E4%B9%89%2F</url>
    <content type="text"><![CDATA[注意力机制什么是注意力机制注意力机制就是对输入权重分配的关注，最开始使用到注意力机制是在编码器-解码器(encoder-decoder)中, 注意力机制通过对编码器所有时间步的隐藏状态做加权平均来得到下一层的输入变量： 注意力机制的通用表达式可以写为： $$\boldsymbol{O} = \text{softmax}(\boldsymbol{Q}\boldsymbol{K}^\top)\boldsymbol{V}$$ 注意力机制广义上可以理解成一个由查询项矩阵 $\boldsymbol{Q}$ 和所对应的键项 $\boldsymbol{K}$ 和 需加权平均的值项 $\boldsymbol{V}$ 所构成的一层感知机(softmax求和)。 这里我们可以从两个视角来看： 从工程学上理解从工程学上简单理解，我们可以把注意力机制理解成从数据库(内存槽)Q中通过键K和值V得到输出O，由于V是输入，所以可以理解注意力机制的核心就是如何构建数据库Q和键值K的方法。 从算法上理解从算法上来理解，我们可以把注意力机制和池化做类比，即将卷积神经网络中的池化看成一种特殊的平均加权的注意力机制，或者说注意力机制是一种具有对输入分配偏好的通用池化方法(含参数的池化方法)。 从构建查询项看注意力机制最早的Attention的提出在最早提出注意力机制的论文《Neural Machine Translation by Jointly Learning to Align and Translate》中，其主要是用来作翻译模型，解决翻译核对齐问题（论文采用了seq2seq+attention）。文中QK的计算表示： $$\boldsymbol{c}_{t'} = \sum_{t=1}^T\alpha_{t' t}\boldsymbol{h}_t$$ $$\alpha_{t' t} = \text{softmax}(\sigma(\boldsymbol{s}_{t' - 1}, \boldsymbol{h}_t))$$ $$\sigma(\boldsymbol{s}_{t' - 1}, \boldsymbol{h}_t) = \boldsymbol{v}^\top \tanh(\boldsymbol{W}_s \boldsymbol{s}_{t' - 1} + \boldsymbol{W}_h \boldsymbol{h}_t)$$ $\boldsymbol{c}_{t’}$表示输出变量，$\boldsymbol{h}_t$为隐藏层，$\alpha_{t' t}$表示一个权重的概率分布，即QK得softmax值，这里得查询项矩阵Q采用了一个$\tanh(\boldsymbol{W}_s \boldsymbol{s} + \boldsymbol{W}_h \boldsymbol{h})$，所以$\sigma$其本质在是一个单层的感知机。由于这种注意力机制由Bahdanau在seq2seq中正式提出，也叫循环注意力机制，更加$\sigma$函数即其参数不同我们可以把注意力机制分成多种形式。 最基础形态的注意力机制 从上面我们将注意力机制抽象出来即： $$\boldsymbol{c}_{t} = \sum_{t=1}^T\sigma(\boldsymbol{q},\boldsymbol{k}_t)\boldsymbol{h}_t$$ q 为查询项， k 为键值项， h为隐含层输入变量，$\sigma$ 为变换函数，c表示模型输出的context vetor。呃，趣味点的话也可以理解，输入的h，通过其对应键值k查询q，通过$\sigma$输出c 层次注意力(Hierarchical Attention Networks)层次注意力由 Zichao Yang 提出，主要用于解决多层次问题，比如在文本分类中，我们可以把词作为一层，把段落作为一层，这样就有了多层，而且下面一层会对上一层有影响，因此建立了一种堆叠的层次注意力模型： 层次注意力机制就是堆叠了多个注意力模型，形成多层次注意力，其公式表达可以写成： $$ \boldsymbol{c}_{t}^{(\boldsymbol{i+1})} = \sum_{t=1}^T\sigma^{(\boldsymbol{i})}(\boldsymbol{q}^{(\boldsymbol{i})},\boldsymbol{k}_t^{(\boldsymbol{i})})\boldsymbol{h}_t^{(\boldsymbol{i})},\\ \boldsymbol{h}_{t}^{(\boldsymbol{i})} = \boldsymbol{v}_{t}^{(\boldsymbol{i+1})}\boldsymbol{c}_{i}^{(\boldsymbol{t})}$$ $$\boldsymbol{h}_{0} = \boldsymbol{W}_{t}^{(0)}\boldsymbol{X}$$ q 为查询项， k 为键值项， h为隐含层输入变量，$\sigma$ 为变换函数，c表示模型输出的context vetor，i表示层级。 什么意思呢？首先，可以看到上层的注意力是以下层的输出作为输入，一层一层堆叠上去。 循环注意力 前面讲到，其实所谓的循环注意力模型就是最早提出的seq2seq的翻译模型： $$ \begin{align} \boldsymbol{o}_{i} &= f(\boldsymbol{s}_{i}) \\ \boldsymbol{s}_{i} &= a(\boldsymbol{s}_{i-1},\boldsymbol{o}_{i-1},\boldsymbol{s}_{i}) \\ \boldsymbol{c}_{t'} &= \sum_{t=1}^T\alpha_{t' t}\boldsymbol{h}_t \\ \alpha_{t' t} &= \frac{\exp(e_{t' t})}{ \sum_{k=1}^T \exp(e_{t' k}) },\quad t=1,\ldots,T \\ e_{t' t} &= \sigma(\boldsymbol{s}_{t' - 1}, \boldsymbol{h}_t) \\ \sigma(\boldsymbol{s}_{t' - 1}, \boldsymbol{h}_t) &= \boldsymbol{V}^\top \tanh(\boldsymbol{W}_s \boldsymbol{s}_{t' - 1} + \boldsymbol{W}_h \boldsymbol{h}_t) \\ \end{align} $$ 其中 他的核心思想是将下一个输出的状态$\boldsymbol{s}_{t-1}$一起输入$\sigma$函数。$\alpha_{t’ t}$就是注意力模型中的权重项，O表示输出，s表示解码器中的隐藏层变量,c表示context vetor, h表示编码器中的隐藏层变量。 全局注意力模型（Gobal Attention）全局注意力模型是由Minh-Thang Luong在2015年的《Effective Approaches to Attention-based Neural Machine Translation》中提出： 这个全局注意力模型是在循环注意力模型上左的改进，加个一层Global align weights（见上图），原循环注意力模型的键值项K是直接采用$\boldsymbol{h}_t$。其公式： $$ \begin{align} \alpha_t(s) &= \text{align}(\boldsymbol{h}_t, \bar{\boldsymbol{h}_s}) \\ &= \frac{ \text{exp}(\text{score}(\boldsymbol{h}_t, \bar{\boldsymbol{h}_s}))} { \sum_{\boldsymbol{s'}} \text{exp}(\text{score}(\boldsymbol{h}_t, \bar{\boldsymbol{h}_{s'}})) } \end{align} $$ $\boldsymbol{h}_{t}$ 表示当前目标时刻 t 的编码器的隐藏变量，$\bar{\boldsymbol{h}_s}$表示所有的原时刻的编码器的隐藏变量score表示一种打分方式，其中论文中给出的是三种： $$ \text{score}(\boldsymbol{h}_t, \bar{\boldsymbol{h}_s)} = \begin{cases} \boldsymbol{h}_t^T \bar{\boldsymbol{h}_s}, &\text{dot}\\ \boldsymbol{h}_t^T \boldsymbol{W}_a \bar{\boldsymbol{h}_s}, &\text{general}\\ \boldsymbol{v}_a^T \text{tanh}(\boldsymbol{W}_a[\boldsymbol{h}_t;\bar{\boldsymbol{h}_s}]),&\text{concat} \end{cases} $$ dot表示点乘/点积，concat表示联接，即将两个变量连接起来，general是一般形式，中间加权重参数。 注： While our global attention approach is similar in spirit to the model proposed by Bahdanau et al. (2015), there are several key differences which reﬂect how we have both simpliﬁed and generalized from the original model. 局部注意力模型（Local Attention）局部注意力模型其实是和全局注意力模型在同一篇论文提出的，局部注意力模型在全局注意力模型的基础上增加了aligned position帮助定位，使查询项Q和键值项K能专注部分信息： 位置aligned position的公式: $$p_t = S \cdot \text{sigmod}(\boldsymbol{v}_p^T \text{tanh}(\boldsymbol{W}_p\boldsymbol{h}_t)), \\p_t \in [0, S]$$ S表示原句的长度，W和v为预测参数。 键值和查询项的权重: $$\alpha_t(s) = \text{align}(\boldsymbol{h}_t, \bar{\boldsymbol{h}_s})\text{exp}(- \frac{(s-p_t)^2}{2\sigma^2})$$ $p_t$的范围是【0，S】，s为$p_t$窗体中间的正数,$\sigma=\frac{D}{2}$: 自注意力(Self Attention)1、从n个输入直接输出n个输出，没有序列，每个输入对应着一个K,V,Q；2、可以并行运算 多头注意力模型(Multi-Head Attention) 多头自注意力模型其公式： $$ \text{MultiHead}(Q,K,V) = \text{Concat}(\text{head1},...,\text{head}_h)\boldsymbol{W}^O $$ $$ \text{head}_i = \text{Attention}(\boldsymbol{Q}\boldsymbol{W}_i^Q,\boldsymbol{K}\boldsymbol{W}_i^K,\boldsymbol{V}\boldsymbol{W}_i^V) $$ $$ \text{Attention}(\boldsymbol{Q},\boldsymbol{K},\boldsymbol{V}) = \text{softmax}(\frac{\boldsymbol{Q}\boldsymbol{K}^T}{\sqrt{d_k}})\boldsymbol{V} $$ 注意力模型的应用TransformerTransformer模型是 Google 团队在2017年《Attention is All You Need》中提出，Transformer模型在后面成为构成 BERT 的基石之一，那么我们来看看是怎么通过自注意力模型构建Transformer的： Transformer从结构上来说依然是个Encoder-Decoder模型，但是，它和传统的seq2seq主要有三点不同： 使用位置编码，也就是Positional Encoding代替序列信息。 使用Transformer Block来实现注意力机制 采用多头自注意力，可以并行运算 位置编码(Positional Encoding)公式： $$ \boldsymbol{P}_{i,2j} = \text{sin}(\frac{i}{10000^{2j/d}}) $$ $$ \boldsymbol{P}_{i,2j+1} = \text{sin}(\frac{i}{10000^{2j/d}}) $$ $$ \boldsymbol{H} = \boldsymbol{X} + \boldsymbol{P}, \\ \boldsymbol{X} \in \Bbb{R}, \boldsymbol{P} \in \Bbb{R} $$ Position-wise FFN input(batch, seq len, fea size) 转换成 (batch*seq len, fea siz) 使用了两层MLP 最后的输出在转化为3-D 等于使用了一个$1\times1$的卷积层 Layer Normalizaiton Layer NormalizationLayer Normalization最早由 Jimmy Lei Ba 在2016年《Layer Normalization》一文中提出。 shape:[N, C, H, W]N 代表batch长度，C代表通道数，H代表每层的隐藏单元数，W代表每层的权重； BatchNorm是在batch上，对NHW做归一化； LayerNorm在channel方向上，对CHW归一化； InstanceNorm在单个通道像素上，对HW做归一化； GroupNorm，有点类似LayerNorm,将channel分组，然后再做归一化； BERTBERT，全称 Bidirectional Encoder Representations from Transformers，是由 BERT特点： 使用 Transformer Block 代替 RNN，通过堆叠Transformer Block将模型变深； 使用随机 Mark 的方式训练; 使用双向编码的形式； 后面我们通过实现BERT来回归整个Attention系列:BERT代码实现及解读 ### 推荐系统中的注意力机制Jun Xiao, et al. Attentional Factorization Machines: Learning the Weight of Feature Interactions via Attention Networks. 2017 参考文献 https://github.com/d2l-ai/d2l-zh Neural Machine Translation by Jointly Learning to Align and Translate. Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. ICLR, 2015. Hierarchical attention networks for document classification. Zichao Yang et al. ACL, 2016. Effective approaches to attention-based neural machine translation. Minh-Thang Luong, Hieu Pham, and Christopher D Manning. EMNLP, 2015. Long Short-Term Memory-Networks for Machine Reading. Jianpeng Cheng, Li Dong and Mirella Lapata. EMNLP, 2016. Attention Is All You Need. Ashish Vaswani, et al. NIPS, 2017.]]></content>
      <categories>
        <category>技术博文</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>算法</tag>
        <tag>注意力机制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[weekly kaggle 练习题解读(House Prices)]]></title>
    <url>%2F2019%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2Fweekly-kaggle-%E7%BB%83%E4%B9%A0%E5%86%8C%2F</url>
    <content type="text"><![CDATA[每日一课 Kaggle 练习讲解每周一道Kaggle题，学习机器学习！ 今天给大家来讲讲《House Prices: Advanced Regression Techniques》（房价预测模型）的思路: （1） 数据可视化和数据分布变换 （2） 缺省值处理 （3） 数据特征变换 （4） 数据建模及交叉检验 （5） 模型组合 import numpy as npimport pandas as pd import matplotlib.pyplot as pltimport seaborn as snsfrom scipy import statsfrom scipy.stats import norm, skewfrom scipy.special import boxcox1pfrom scipy.stats import boxcox_normmaxfrom sklearn.model_selection import KFold, cross_val_scorefrom sklearn.preprocessing import LabelEncoder%matplotlib inline 加载数据去除ID train_path = "http://kaggle.shikanon.com/house-prices-advanced-regression-techniques/train.csv"test_path = "http://kaggle.shikanon.com/house-prices-advanced-regression-techniques/test.csv"train_df = pd.read_csv(train_path)test_df = pd.read_csv(test_path)train_df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } .rendered_html th, .rendered_html td { text-align: right; vertical-align: middle; padding: 0.5em 0.5em; line-height: normal; white-space: nowrap; width: 80px; border: none; } Id MSSubClass MSZoning LotFrontage LotArea Street Alley LotShape LandContour Utilities ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold YrSold SaleType SaleCondition SalePrice 0 1 60 RL 65.0 8450 Pave NaN Reg Lvl AllPub ... 0 NaN NaN NaN 0 2 2008 WD Normal 208500 1 2 20 RL 80.0 9600 Pave NaN Reg Lvl AllPub ... 0 NaN NaN NaN 0 5 2007 WD Normal 181500 2 3 60 RL 68.0 11250 Pave NaN IR1 Lvl AllPub ... 0 NaN NaN NaN 0 9 2008 WD Normal 223500 3 4 70 RL 60.0 9550 Pave NaN IR1 Lvl AllPub ... 0 NaN NaN NaN 0 2 2006 WD Abnorml 140000 4 5 60 RL 84.0 14260 Pave NaN IR1 Lvl AllPub ... 0 NaN NaN NaN 0 12 2008 WD Normal 250000 5 rows × 81 columns 我们在分析之前要先了解个字段的意思： train_df.columns Index([&apos;Id&apos;, &apos;MSSubClass&apos;, &apos;MSZoning&apos;, &apos;LotFrontage&apos;, &apos;LotArea&apos;, &apos;Street&apos;, &apos;Alley&apos;, &apos;LotShape&apos;, &apos;LandContour&apos;, &apos;Utilities&apos;, &apos;LotConfig&apos;, &apos;LandSlope&apos;, &apos;Neighborhood&apos;, &apos;Condition1&apos;, &apos;Condition2&apos;, &apos;BldgType&apos;, &apos;HouseStyle&apos;, &apos;OverallQual&apos;, &apos;OverallCond&apos;, &apos;YearBuilt&apos;, &apos;YearRemodAdd&apos;, &apos;RoofStyle&apos;, &apos;RoofMatl&apos;, &apos;Exterior1st&apos;, &apos;Exterior2nd&apos;, &apos;MasVnrType&apos;, &apos;MasVnrArea&apos;, &apos;ExterQual&apos;, &apos;ExterCond&apos;, &apos;Foundation&apos;, &apos;BsmtQual&apos;, &apos;BsmtCond&apos;, &apos;BsmtExposure&apos;, &apos;BsmtFinType1&apos;, &apos;BsmtFinSF1&apos;, &apos;BsmtFinType2&apos;, &apos;BsmtFinSF2&apos;, &apos;BsmtUnfSF&apos;, &apos;TotalBsmtSF&apos;, &apos;Heating&apos;, &apos;HeatingQC&apos;, &apos;CentralAir&apos;, &apos;Electrical&apos;, &apos;1stFlrSF&apos;, &apos;2ndFlrSF&apos;, &apos;LowQualFinSF&apos;, &apos;GrLivArea&apos;, &apos;BsmtFullBath&apos;, &apos;BsmtHalfBath&apos;, &apos;FullBath&apos;, &apos;HalfBath&apos;, &apos;BedroomAbvGr&apos;, &apos;KitchenAbvGr&apos;, &apos;KitchenQual&apos;, &apos;TotRmsAbvGrd&apos;, &apos;Functional&apos;, &apos;Fireplaces&apos;, &apos;FireplaceQu&apos;, &apos;GarageType&apos;, &apos;GarageYrBlt&apos;, &apos;GarageFinish&apos;, &apos;GarageCars&apos;, &apos;GarageArea&apos;, &apos;GarageQual&apos;, &apos;GarageCond&apos;, &apos;PavedDrive&apos;, &apos;WoodDeckSF&apos;, &apos;OpenPorchSF&apos;, &apos;EnclosedPorch&apos;, &apos;3SsnPorch&apos;, &apos;ScreenPorch&apos;, &apos;PoolArea&apos;, &apos;PoolQC&apos;, &apos;Fence&apos;, &apos;MiscFeature&apos;, &apos;MiscVal&apos;, &apos;MoSold&apos;, &apos;YrSold&apos;, &apos;SaleType&apos;, &apos;SaleCondition&apos;, &apos;SalePrice&apos;], dtype=&apos;object&apos;) MSSubClass: 建筑的等级，类型：类别型 MSZoning: 区域分类，类型：类别型 LotFrontage: 距离街道的直线距离，类型：数值型，单位：英尺 LotArea: 地皮面积，类型：数值型，单位：平方英尺 Street: 街道类型，类型：类别型 Alley: 巷子类型，类型：类别型 LotShape: 房子整体形状，类型：类别型 LandContour: 平整度级别，类型：类别型 Utilities: 公共设施类型，类型：类别型 LotConfig: 房屋配置，类型：类别型 LandSlope: 倾斜度，类型：类别型 Neighborhood: 市区物理位置，类型：类别型 Condition1: 主干道或者铁路便利程度，类型：类别型 Condition2: 主干道或者铁路便利程度，类型：类别型 BldgType: 住宅类型，类型：类别型 HouseStyle: 住宅风格，类型：类别型 OverallQual: 整体材料和饰面质量，类型：数值型 OverallCond: 总体状况评价，类型：数值型 YearBuilt: 建筑年份，类型：数值型 YearRemodAdd: 改建年份，类型：数值型 RoofStyle: 屋顶类型，类型：类别型 RoofMatl: 屋顶材料，类型：类别型 Exterior1st: 住宅外墙，类型：类别型 Exterior2nd: 住宅外墙，类型：类别型 MasVnrType: 砌体饰面类型，类型：类别型 MasVnrArea: 砌体饰面面积，类型：数值型，单位：平方英尺 ExterQual: 外部材料质量，类型：类别型 ExterCond: 外部材料的现状，类型：类别型 Foundation: 地基类型，类型：类别型 BsmtQual: 地下室高度，类型：类别型 BsmtCond: 地下室概况，类型：类别型 BsmtExposure: 花园地下室墙，类型：类别型 BsmtFinType1: 地下室装饰质量，类型：类别型 BsmtFinSF1: 地下室装饰面积，类型：类别型 BsmtFinType2: 地下室装饰质量，类型：类别型 BsmtFinSF2: 地下室装饰面积，类型：类别型 BsmtUnfSF: 未装饰的地下室面积，类型：数值型，单位：平方英尺 TotalBsmtSF: 地下室总面积，类型：数值型，单位：平方英尺 Heating: 供暖类型，类型：类别型 HeatingQC: 供暖质量和条件，类型：类别型 CentralAir: 中央空调状况，类型：类别型 Electrical: 电力系统，类型：类别型 1stFlrSF: 首层面积，类型：数值型，单位：平方英尺 2ndFlrSF: 二层面积，类型：数值型，单位：平方英尺 LowQualFinSF: 低质装饰面积，类型：数值型，单位：平方英尺 GrLivArea: 地面以上居住面积，类型：数值型，单位：平方英尺 BsmtFullBath: 地下室全浴室，类型：数值 BsmtHalfBath: 地下室半浴室，类型：数值 FullBath: 高档全浴室，类型：数值 HalfBath: 高档半浴室，类型：数值 BedroomAbvGr: 地下室以上的卧室数量，类型：数值 KitchenAbvGr: 厨房数量，类型：数值 KitchenQual: 厨房质量，类型：类别型 TotRmsAbvGrd: 地上除卧室以外的房间数，类型：数值 Functional: 房屋功用性评级，类型：类别型 Fireplaces: 壁炉数量，类型：数值 FireplaceQu: 壁炉质量，类型：类别型 GarageType: 车库位置，类型：类别型 GarageYrBlt: 车库建造年份，类别：数值型 GarageFinish: 车库内饰，类型：类别型 GarageCars: 车库车容量大小，类别：数值型 GarageArea: 车库面积，类别：数值型，单位：平方英尺 GarageQual: 车库质量，类型：类别型 GarageCond: 车库条件，类型：类别型 PavedDrive: 铺的车道情况，类型：类别型 WoodDeckSF: 木地板面积，类型：数值型，单位：平方英尺 OpenPorchSF: 开放式门廊区面积，类型：数值型，单位：平方英尺 EnclosedPorch: 封闭式门廊区面积，类型：数值型，单位：平方英尺 3SsnPorch: 三个季节门廊面积，类型：数值型，单位：平方英尺 ScreenPorch: 纱门门廊面积，类型：数值型，单位：平方英尺 PoolArea: 泳池面积，类型：数值型，单位：平方英尺 PoolQC:泳池质量，类型：类别型 Fence: 围墙质量，类型：类别型 MiscFeature: 其他特征，类型：类别型 MiscVal: 其他杂项特征值，类型：类别型 MoSold: 卖出月份，类别：数值型 YrSold: 卖出年份，类别：数值型 SaleType: 交易类型，类型：类别型 SaleCondition: 交易条件，类型：类别型数据处理和特征分析 #Saving Idstrain_ID = train_df['Id']test_ID = test_df['Id']#Dropping Idstrain_df.drop("Id", axis = 1, inplace = True)test_df.drop("Id", axis = 1, inplace = True) 数据观察和可视化更加常识，一般和房价最相关的是居住面积，也就是GrLivArea，我们查看下GrLivArea和SalePrice的关系 fig, ax = plt.subplots()ax.scatter(x = train_df['GrLivArea'], y = train_df['SalePrice'], c = "skyblue")plt.ylabel('SalePrice', fontsize=8)plt.xlabel('GrLivArea', fontsize=8)plt.show() 我们发现有个别值特别的偏离，GrLivArea有两个点在4000以上，但其价格不到200000，首先这种点特别少（不到总数的3%），我们把他作为异常值去掉（其实是否去掉我们可以多做几次实验来验证）Kaggle的作者在这里有建议去掉:) train_df.drop(train_df[(train_df['GrLivArea']&gt;4000)&amp;(train_df['GrLivArea']&lt;30000)].index,inplace=True) fig, ax = plt.subplots()ax.scatter(x = train_df['GrLivArea'], y = train_df['SalePrice'], c = "skyblue")plt.ylabel('SalePrice', fontsize=8)plt.xlabel('GrLivArea', fontsize=8)plt.show() 最后一行是 SalePrice， 我们可以看到她跟各变量的关系，还有各变量相互之间的关系观察数据分布在机器学习中，对数据的认识是很重要的，他会影响我们的特征构建和建模，特别对于偏态分布，我们要做一些变换 # 统计表述train_df['SalePrice'].describe() count 1456.000000 mean 180151.233516 std 76696.592530 min 34900.000000 25% 129900.000000 50% 163000.000000 75% 214000.000000 max 625000.000000 Name: SalePrice, dtype: float64 # 绘制分布图sns.distplot(train_df['SalePrice'], kde_kws=&#123;"color": "coral", "lw": 1, "label": "KDE"&#125;, hist_kws=&#123;"histtype": "stepfilled", "linewidth": 3, "alpha": 1, "color": "skyblue"&#125;); Q-Q图，全称 Quantile Quantile Plot，中文名叫分位数图，Q-Q图是一个概率图，用于比较观测与预测值之间的概率分布差异，这里的比较对象一般采用正态分布，Q-Q图可以用于检验数据分布的相似性，而P-P图是根据变量的累积概率对应于所指定的理论分布累积概率绘制的散点图，两者基本一样 # 绘制P-P图fig = plt.figure()res = stats.probplot(train_df['SalePrice'], dist="norm", plot=plt)plt.show() 红色线是正态分布，蓝色线是我们的数据，可以看出，我们的数据头尾都严重偏离了正太分布,我们尝试对数据做变换，常用的变换有指数变换、对数变换、幂函数等。 # 对数变换train_df['SalePrice_Log'] = np.log(train_df['SalePrice'])sns.distplot(train_df['SalePrice_Log'], kde_kws=&#123;"color": "coral", "lw": 1, "label": "KDE"&#125;, hist_kws=&#123;"histtype": "stepfilled", "linewidth": 3, "alpha": 1, "color": "skyblue"&#125;); # 偏度与峰值(skewness and kurtosis)print("Skewness: %f" % train_df['SalePrice_Log'].skew())print("Kurtosis: %f" % train_df['SalePrice_Log'].kurt())fig = plt.figure()res = stats.probplot(train_df['SalePrice_Log'], plot=plt)plt.show() Skewness: 0.065449 Kurtosis: 0.666438 # 指数变换train_df['SalePrice_Exp'] = np.exp(train_df['SalePrice']/train_df['SalePrice'].mean())sns.distplot(train_df['SalePrice_Exp'], kde_kws=&#123;"color": "coral", "lw": 1, "label": "KDE"&#125;, hist_kws=&#123;"histtype": "stepfilled", "linewidth": 3, "alpha": 1, "color": "skyblue"&#125;); # 偏度与峰值(skewness and kurtosis)print("Skewness: %f" % train_df['SalePrice_Exp'].skew())print("Kurtosis: %f" % train_df['SalePrice_Exp'].kurt())fig = plt.figure()res = stats.probplot(train_df['SalePrice_Exp'], plot=plt)plt.show() Skewness: 6.060076 Kurtosis: 56.822460 # 幂函数变换train_df['SalePrice_Square'] = train_df['SalePrice']**0.5sns.distplot(train_df['SalePrice_Square'], kde_kws=&#123;"color": "coral", "lw": 1, "label": "KDE"&#125;, hist_kws=&#123;"histtype": "stepfilled", "linewidth": 3, "alpha": 1, "color": "skyblue"&#125;); # 偏度与峰值(skewness and kurtosis)print("Skewness: %f" % train_df['SalePrice_Square'].skew())print("Kurtosis: %f" % train_df['SalePrice_Square'].kurt())fig = plt.figure()res = stats.probplot(train_df['SalePrice_Square'], plot=plt)plt.show() Skewness: 0.810797 Kurtosis: 1.245798 三个函数拟合对比，对数转换最吻合,但是我们知道对数意味着小于1的时候为负数，这明显和认知不符合，应该采用log(1+x)，也就是log1p，保证了x数据的有效性，当x很小时,如: 10^{-16} ，由于太小超过数值有效性，用log(x+1)计算得到结果为0 # 对数变换train_df['SalePrice_Log1p'] = np.log1p(train_df['SalePrice'])sns.distplot(train_df['SalePrice_Log1p'], kde_kws=&#123;"color": "coral", "lw": 1, "label": "KDE"&#125;, hist_kws=&#123;"histtype": "stepfilled", "linewidth": 3, "alpha": 1, "color": "skyblue"&#125;); # 偏度与峰值(skewness and kurtosis)print("Skewness: %f" % train_df['SalePrice_Log1p'].skew())print("Kurtosis: %f" % train_df['SalePrice_Log1p'].kurt())fig = plt.figure()res = stats.probplot(train_df['SalePrice_Log1p'], plot=plt)plt.show() Skewness: 0.065460 Kurtosis: 0.666423 del train_df['SalePrice_Square']del train_df["SalePrice_Exp"]del train_df['SalePrice_Log'] del train_df["SalePrice"] 将测试数据和训练数据联合一起进行特征分析 size_train_df = train_df.shape[0]size_test_df = test_df.shape[0]target_variable = train_df['SalePrice_Log1p'].valuesdata = pd.concat((train_df, test_df),sort=False).reset_index(drop=True)data.drop(['SalePrice_Log1p'], axis=1, inplace=True) 缺失值处理缺失值是实际数据分析很重要的一块，在实际生产中一直都会有大量的缺失值存在，如何处理好缺失值是很关键也很重要的一步。常见的缺失值处理有： （1）把缺失值单独作为一类，比如对类别型用none。 （2）采用平均数、中值、众数等特定统计值来填充缺失值。 （3）采用函数预测等方法填充缺失值。这里的各变量填充策略：NA for ‘PoolQC’ means “No Pool”.MiscFeature: NA means “None”Alley: NA means “No alley access”Fence: NA means “No fence”FireplaceQu: NA means “No fireplace”LotFrontage: fill missing values with median LotFrontage of neighborhoodGarageFinish: NA means “None”GarageQual: NA means “None”GarageCond: NA means “None”GarageYrBlt: NA means 0GarageType: NA means “None”BsmtCond: NA means “None”BsmtExposure: NA means “None”BsmtQual: NA means “None”BsmtFinType2: NA means “None”BsmtFinType1: NA means “None”MasVnrType: NA means “None”MasVnrArea: NA means “0”BsmtHalfBath: NA means “0”BsmtFullBath: NA means “0”BsmtFinSF1: NA means “0”BsmtFinSF2: NA means “0”BsmtUnfSF: NA means “0”TotalBsmtSF: NA means “0”GarageCars: NA means 0GarageArea: NA means 0 data.count().sort_values().head(20) # 通过 count 可以找出有缺失值的数据 PoolQC 8 MiscFeature 105 Alley 198 Fence 570 FireplaceQu 1495 LotFrontage 2429 GarageCond 2756 GarageYrBlt 2756 GarageFinish 2756 GarageQual 2756 GarageType 2758 BsmtExposure 2833 BsmtCond 2833 BsmtQual 2834 BsmtFinType2 2835 BsmtFinType1 2836 MasVnrType 2891 MasVnrArea 2892 MSZoning 2911 BsmtFullBath 2913 dtype: int64 data_na = (data.isnull().sum() / len(data)) * 100data_na.drop(data_na[data_na==0].index,inplace=True)data_na = data_na.sort_values(ascending=False)f, ax = plt.subplots(figsize=(10, 10))plt.xticks(rotation='90')sns.barplot(x=data_na.index, y=data_na)plt.xlabel('Features', fontsize=10)plt.ylabel('Percent of missing values', fontsize=10)plt.title('Percent missing data by feature', fontsize=10) Text(0.5, 1.0, &apos;Percent missing data by feature&apos;) var = 'Utilities'train_var_count = train_df[var].value_counts()fig = sns.barplot(x=train_var_count.index, y=train_var_count)plt.xticks(rotation=90); var = 'MSZoning'train_var_count = train_df[var].value_counts()fig = sns.barplot(x=train_var_count.index, y=train_var_count)plt.xticks(rotation=90); # 填充nilfeatures_fill_na_none = ['PoolQC','MiscFeature','Alley','Fence','FireplaceQu', 'GarageQual','GarageCond','GarageFinish','GarageType', 'BsmtExposure','BsmtCond','BsmtQual','BsmtFinType1','BsmtFinType2', 'MasVnrType']# 填充0features_fill_na_0 = ['GarageYrBlt', 'GarageArea', 'GarageCars', 'MasVnrArea', 'BsmtFullBath','BsmtHalfBath', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF']# 填众数features_fill_na_mode = ["Functional", "MSZoning", "SaleType", "Electrical", "KitchenQual", "Exterior2nd", "Exterior1st"]for feature_none in features_fill_na_none: data[feature_none].fillna('None',inplace=True) for feature_0 in features_fill_na_0: data[feature_0].fillna(0,inplace=True)for feature_mode in features_fill_na_mode: mode_value = data[feature_mode].value_counts().sort_values(ascending=False).index[0] data[features_fill_na_mode] = data[features_fill_na_mode].fillna(mode_value)# 用中值代替data["LotFrontage"] = data.groupby("Neighborhood")["LotFrontage"].transform( lambda x: x.fillna(x.median()))# 像 Utilities 这种总共才两个值，同时有一个值是作为主要的，这种字段是无意义的，应该删除data.drop(['Utilities'], axis=1,inplace=True) data_na = (data.isnull().sum() / len(data)) * 100data_na.drop(data_na[data_na==0].index,inplace=True)data_na = data_na.sort_values(ascending=False)data_na # data_na 为空 Series([], dtype: float64) 类型转换，将某些实际是类别类型但用数字表示的强制转换成文本，比如有些调查男表示1，女表示0，在这种情况下，如果我们直接通过dataframe类型判断会导致错误，我们要根据实际情况做转换 #MSSubClass=The building classdata['MSSubClass'] = data['MSSubClass'].apply(str)#Changing OverallCond into a categorical variabledata['OverallCond'] = data['OverallCond'].astype(str)#Year and month sold are transformed into categorical features.data['YrSold'] = data['YrSold'].astype(str)data['MoSold'] = data['MoSold'].astype(str) 绘制关系矩阵关系矩阵可以很直观的告诉我们那些变量之间相关，哪些变量并不相关 # 关系矩阵corrmat = train_df.corr()corrmat .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } .rendered_html th, .rendered_html td { text-align: right; vertical-align: middle; padding: 0.5em 0.5em; line-height: normal; white-space: nowrap; width: 80px; border: none; } MSSubClass LotFrontage LotArea OverallQual OverallCond YearBuilt YearRemodAdd MasVnrArea BsmtFinSF1 BsmtFinSF2 ... WoodDeckSF OpenPorchSF EnclosedPorch 3SsnPorch ScreenPorch PoolArea MiscVal MoSold YrSold SalePrice_Log1p MSSubClass 1.000000 -0.408655 -0.142192 0.032416 -0.059277 0.027689 0.040459 0.022800 -0.075268 -0.065598 ... -0.012853 -0.006687 -0.011966 -0.043802 -0.025979 0.007957 -0.007666 -0.013512 -0.021330 -0.075083 LotFrontage -0.408655 1.000000 0.387570 0.225994 -0.055673 0.113913 0.079785 0.162026 0.133704 0.056971 ... 0.077154 0.116131 0.017010 0.075575 0.047832 0.075160 0.005636 0.028042 0.010598 0.363286 LotArea -0.142192 0.387570 1.000000 0.088719 -0.002832 0.006590 0.006930 0.081170 0.173426 0.114691 ... 0.167040 0.061679 -0.016108 0.021505 0.045620 0.033875 0.039192 0.007188 -0.013014 0.258945 OverallQual 0.032416 0.225994 0.088719 1.000000 -0.090692 0.571712 0.550971 0.400028 0.213079 -0.057520 ... 0.232819 0.297803 -0.112407 0.031621 0.067732 0.018121 -0.031068 0.076414 -0.024321 0.819240 OverallCond -0.059277 -0.055673 -0.002832 -0.090692 1.000000 -0.375691 0.074703 -0.130053 -0.042542 0.040015 ... -0.003063 -0.029649 0.070103 0.025419 0.054617 0.008079 0.068729 -0.003135 0.043755 -0.036843 YearBuilt 0.027689 0.113913 0.006590 0.571712 -0.375691 1.000000 0.591906 0.314066 0.248272 -0.048393 ... 0.222690 0.183905 -0.386904 0.031717 -0.049703 -0.014373 -0.034193 0.013881 -0.012593 0.588977 YearRemodAdd 0.040459 0.079785 0.006930 0.550971 0.074703 0.591906 1.000000 0.176067 0.121690 -0.067188 ... 0.204020 0.222649 -0.193348 0.045596 -0.038176 -0.009490 -0.010100 0.022629 0.036597 0.568986 MasVnrArea 0.022800 0.162026 0.081170 0.400028 -0.130053 0.314066 0.176067 1.000000 0.235557 -0.071337 ... 0.149491 0.106073 -0.109453 0.020270 0.065296 -0.016025 -0.029691 0.004019 -0.004880 0.430073 BsmtFinSF1 -0.075268 0.133704 0.173426 0.213079 -0.042542 0.248272 0.121690 0.235557 1.000000 -0.048738 ... 0.201462 0.071851 -0.103053 0.029879 0.070026 0.016380 0.005149 -0.001773 0.018506 0.382710 BsmtFinSF2 -0.065598 0.056971 0.114691 -0.057520 0.040015 -0.048393 -0.067188 -0.071337 -0.048738 1.000000 ... 0.069028 0.005083 0.036269 -0.030090 0.088676 0.053178 0.004871 -0.015726 0.031384 0.006420 BsmtUnfSF -0.140890 0.142075 -0.003774 0.310164 -0.137267 0.148810 0.180972 0.111684 -0.526140 -0.209286 ... -0.006876 0.129148 -0.002336 0.020843 -0.012435 -0.031244 -0.023802 0.035456 -0.040834 0.223248 TotalBsmtSF -0.255441 0.313392 0.221940 0.532666 -0.176000 0.399867 0.294866 0.337869 0.460324 0.116478 ... 0.229984 0.215559 -0.095872 0.041762 0.094511 0.004418 -0.018253 0.030026 -0.012192 0.641553 1stFlrSF -0.265001 0.398400 0.267644 0.462042 -0.145613 0.279929 0.238304 0.316507 0.386453 0.106134 ... 0.230865 0.179049 -0.063074 0.060553 0.097093 0.032088 -0.020801 0.045081 -0.010014 0.613742 2ndFlrSF 0.311294 0.049902 0.037277 0.279745 0.031297 0.002953 0.136103 0.156796 -0.183358 -0.098241 ... 0.083670 0.198407 0.065690 -0.023740 0.043308 0.038375 0.017111 0.039163 -0.024874 0.306605 LowQualFinSF 0.046499 0.042589 0.005675 -0.029826 0.025406 -0.183720 -0.062215 -0.069533 -0.066611 0.014714 ... -0.025114 0.019339 0.060975 -0.004334 0.026713 0.073070 -0.003822 -0.022441 -0.029074 -0.037698 GrLivArea 0.077956 0.341427 0.231887 0.583519 -0.078567 0.192645 0.289264 0.363472 0.121479 -0.004995 ... 0.241827 0.307325 0.016148 0.023967 0.112408 0.064346 -0.000974 0.065328 -0.031898 0.718844 BsmtFullBath 0.003282 0.074686 0.147595 0.104092 -0.053107 0.185009 0.116765 0.080342 0.661933 0.160254 ... 0.174636 0.056251 -0.049034 0.000249 0.024075 0.037039 -0.022877 -0.023770 0.067665 0.238851 BsmtHalfBath -0.002509 -0.009424 0.047391 -0.047172 0.117207 -0.039945 -0.013297 0.012157 0.068869 0.071986 ... 0.034626 -0.024385 -0.007803 0.035565 0.032902 0.027886 -0.007211 0.038478 -0.045303 -0.014974 FullBath 0.132131 0.187048 0.117336 0.543791 -0.194167 0.466710 0.438212 0.266317 0.037159 -0.075291 ... 0.182131 0.252911 -0.113812 0.036304 -0.006557 0.021509 -0.013872 0.058197 -0.016574 0.590919 HalfBath 0.177476 0.037031 0.005981 0.267431 -0.059927 0.240144 0.181136 0.195264 -0.014508 -0.031243 ... 0.104538 0.194921 -0.094317 -0.004590 0.073497 0.001010 0.001589 -0.007127 -0.008853 0.311191 BedroomAbvGr -0.023627 0.269945 0.118960 0.096848 0.013249 -0.072623 -0.041919 0.099176 -0.121893 -0.015134 ... 0.044039 0.093803 0.042402 -0.024263 0.044941 0.064118 0.007965 0.048477 -0.034849 0.204117 KitchenAbvGr 0.281783 -0.002959 -0.016565 -0.184281 -0.087204 -0.174481 -0.149288 -0.036558 -0.082722 -0.040926 ... -0.089670 -0.069738 0.037113 -0.024670 -0.051779 -0.012306 0.062294 0.026340 0.031454 -0.147891 TotRmsAbvGrd 0.040247 0.330249 0.173629 0.415834 -0.055766 0.089207 0.187520 0.265334 0.001877 -0.033490 ... 0.159720 0.219969 0.006790 -0.005908 0.061924 0.041588 0.025640 0.041966 -0.032190 0.533446 Fireplaces -0.046377 0.238140 0.259701 0.387425 -0.022277 0.143162 0.108732 0.236906 0.236219 0.049027 ... 0.194972 0.160647 -0.022885 0.012042 0.187656 0.051221 0.001943 0.053947 -0.022567 0.487126 GarageYrBlt 0.084926 0.058055 -0.033111 0.547320 -0.323836 0.825192 0.641445 0.249917 0.146532 -0.087353 ... 0.222580 0.224239 -0.296517 0.023897 -0.074779 -0.035670 -0.032231 0.006725 -0.000030 0.544005 GarageCars -0.040490 0.289064 0.150977 0.598739 -0.185494 0.536749 0.419573 0.362122 0.224043 -0.037331 ... 0.223010 0.209762 -0.150590 0.036290 0.051622 0.003360 -0.042886 0.041608 -0.037179 0.680408 GarageArea -0.100145 0.318820 0.162183 0.554905 -0.150679 0.477311 0.369590 0.361810 0.268651 -0.016485 ... 0.219967 0.228089 -0.120615 0.036213 0.053732 0.011637 -0.027088 0.034602 -0.025870 0.655212 WoodDeckSF -0.012853 0.077154 0.167040 0.232819 -0.003063 0.222690 0.204020 0.149491 0.201462 0.069028 ... 1.000000 0.053498 -0.125151 -0.032472 -0.073489 0.068309 -0.009287 0.024595 0.023860 0.330573 OpenPorchSF -0.006687 0.116131 0.061679 0.297803 -0.029649 0.183905 0.222649 0.106073 0.071851 0.005083 ... 0.053498 1.000000 -0.092094 -0.005148 0.077261 0.030360 -0.018277 0.072515 -0.056326 0.327038 EnclosedPorch -0.011966 0.017010 -0.016108 -0.112407 0.070103 -0.386904 -0.193348 -0.109453 -0.103053 0.036269 ... -0.125151 -0.092094 1.000000 -0.037427 -0.083154 0.068796 0.018277 -0.029565 -0.010343 -0.148636 3SsnPorch -0.043802 0.075575 0.021505 0.031621 0.025419 0.031717 0.045596 0.020270 0.029879 -0.030090 ... -0.032472 -0.005148 -0.037427 1.000000 -0.031526 -0.006770 0.000326 0.029386 0.018516 0.056065 ScreenPorch -0.025979 0.047832 0.045620 0.067732 0.054617 -0.049703 -0.038176 0.065296 0.070026 0.088676 ... -0.073489 0.077261 -0.083154 -0.031526 1.000000 0.063724 0.031884 0.022863 0.010383 0.123860 PoolArea 0.007957 0.075160 0.033875 0.018121 0.008079 -0.014373 -0.009490 -0.016025 0.016380 0.053178 ... 0.068309 0.030360 0.068796 -0.006770 0.063724 1.000000 0.035480 -0.022901 -0.062640 0.040679 MiscVal -0.007666 0.005636 0.039192 -0.031068 0.068729 -0.034193 -0.010100 -0.029691 0.005149 0.004871 ... -0.009287 -0.018277 0.018277 0.000326 0.031884 0.035480 1.000000 -0.006657 0.004806 -0.019752 MoSold -0.013512 0.028042 0.007188 0.076414 -0.003135 0.013881 0.022629 0.004019 -0.001773 -0.015726 ... 0.024595 0.072515 -0.029565 0.029386 0.022863 -0.022901 -0.006657 1.000000 -0.146229 0.062231 YrSold -0.021330 0.010598 -0.013014 -0.024321 0.043755 -0.012593 0.036597 -0.004880 0.018506 0.031384 ... 0.023860 -0.056326 -0.010343 0.018516 0.010383 -0.062640 0.004806 -0.146229 1.000000 -0.034319 SalePrice_Log1p -0.075083 0.363286 0.258945 0.819240 -0.036843 0.588977 0.568986 0.430073 0.382710 0.006420 ... 0.330573 0.327038 -0.148636 0.056065 0.123860 0.040679 -0.019752 0.062231 -0.034319 1.000000 37 rows × 37 columns mask = np.zeros_like(corrmat) # 返回相同大小的0矩阵mask[np.triu_indices_from(mask)] = True # triu_indices_from: 函数的上三角矩阵mask array([[1., 1., 1., ..., 1., 1., 1.], [0., 1., 1., ..., 1., 1., 1.], [0., 0., 1., ..., 1., 1., 1.], ..., [0., 0., 0., ..., 1., 1., 1.], [0., 0., 0., ..., 0., 1., 1.], [0., 0., 0., ..., 0., 0., 1.]]) # 绘制热力图plt.subplots(figsize=(12,9))sns.heatmap(corrmat, mask=mask, linewidths=.5, vmax=0.9, square=True, cmap="YlGnBu") &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f8c20d156d8&gt; 特征工程对数据做特征变换:对于类别数据，一般采用LabelEncoder的方式，把每个类别的数据变成数值型；也可以采用one-hot变成稀疏矩阵对于数值型的数据，尽量将其变为正态分布。 encode_cat_variables = ('Alley', 'BldgType', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'BsmtQual', 'CentralAir', 'Condition1', 'Condition2', 'Electrical', 'ExterCond', 'ExterQual', 'Exterior1st', 'Exterior2nd', 'Fence', 'FireplaceQu', 'Foundation', 'Functional', 'GarageCond', 'GarageFinish', 'GarageQual', 'GarageType', 'Heating', 'HeatingQC', 'HouseStyle', 'KitchenQual', 'LandContour', 'LandSlope', 'LotConfig', 'LotShape', 'MSSubClass', 'MSZoning', 'MasVnrType', 'MiscFeature', 'MoSold', 'Neighborhood', 'OverallCond', 'PavedDrive', 'PoolQC', 'RoofMatl', 'RoofStyle', 'SaleCondition', 'SaleType', 'Street', 'YrSold')numerical_features = [col for col in data.columns if col not in encode_cat_variables]# for variable in encode_cat_variables:# lbl = LabelEncoder() # lbl.fit(list(data[variable].values)) # data[variable] = lbl.transform(list(data[variable].values))for variable in data.columns: if variable not in encode_cat_variables: data[variable] = data[variable].apply(float) else: data[variable] = data[variable].apply(str)print(data.shape)data = pd.get_dummies(data)print(data.shape) (2915, 78) (2915, 343) # 可以计算一个总面积指标data['TotalSF'] = data['TotalBsmtSF'] + data['1stFlrSF'] + data['2ndFlrSF'] print("Categorical Features: %d"%len(encode_cat_variables))print("Numerical Features: %d"%len(numerical_features)) Categorical Features: 46 Numerical Features: 32 数值型变量的分布 #Boxplot for numerical_featuressns.set_style("whitegrid")f, ax = plt.subplots(figsize=(15, 15))ax.set_xscale("log")ax = sns.boxplot(data=data[numerical_features] , orient="h", palette="ch:2.5,-.2,dark=.3")ax.set(ylabel="Features")ax.set(xlabel="Value")ax.set(title="Distribution")sns.despine(trim=True, left=True) box-cox变换Box-Cox变换是Box和Cox在1964年提出的一种广义幂变换方法，用于连续的响应变量不满足正态分布的情况。Box-Cox变换之后，可以一定程度上减小不可观测的误差和预测变量的相关性。Box-Cox变换的主要特点是引入一个参数，通过数据本身估计该参数进而确定应采取的数据变换形式 # 计算数值型变量的偏态skewed_features = data[numerical_features].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)skewed_features MiscVal 21.932147 PoolArea 18.701829 LotArea 13.123758 LowQualFinSF 12.080315 3SsnPorch 11.368094 KitchenAbvGr 4.298845 BsmtFinSF2 4.142863 EnclosedPorch 4.000796 ScreenPorch 3.943508 BsmtHalfBath 3.942892 MasVnrArea 2.600697 OpenPorchSF 2.529245 WoodDeckSF 1.848285 1stFlrSF 1.253011 LotFrontage 1.092709 GrLivArea 0.977860 BsmtFinSF1 0.974138 BsmtUnfSF 0.920135 2ndFlrSF 0.843237 TotRmsAbvGrd 0.749579 Fireplaces 0.725958 HalfBath 0.698770 TotalBsmtSF 0.662657 BsmtFullBath 0.622820 BedroomAbvGr 0.328129 GarageArea 0.217748 OverallQual 0.181902 FullBath 0.159917 GarageCars -0.219402 YearRemodAdd -0.449113 YearBuilt -0.598087 GarageYrBlt -3.903046 dtype: float64 skewed_features = skewed_features[abs(skewed_features) &gt; 0.75]print("There are &#123;&#125; skewed numerical features to Box Cox transform".format(skewed_features.shape[0]))from scipy.special import boxcox1pskewed_features_name = skewed_features.indexlam = 0.15 # 超参数for feat in skewed_features_name: tranformer_feat = boxcox1p(data[feat], lam) data[feat] = tranformer_featdata[numerical_features].apply(lambda x: skew(x.dropna())).sort_values(ascending=False) There are 20 skewed numerical features to Box Cox transform PoolArea 16.487849 3SsnPorch 8.918476 LowQualFinSF 8.737917 MiscVal 5.592866 BsmtHalfBath 3.798589 KitchenAbvGr 3.695780 ScreenPorch 2.975708 BsmtFinSF2 2.561989 EnclosedPorch 2.023182 TotRmsAbvGrd 0.749579 Fireplaces 0.725958 HalfBath 0.698770 TotalBsmtSF 0.662657 MasVnrArea 0.636713 BsmtFullBath 0.622820 2ndFlrSF 0.329999 BedroomAbvGr 0.328129 WoodDeckSF 0.225571 GarageArea 0.217748 OverallQual 0.181902 LotArea 0.178523 1stFlrSF 0.173668 FullBath 0.159917 GrLivArea 0.102287 OpenPorchSF 0.100679 GarageCars -0.219402 YearRemodAdd -0.449113 BsmtFinSF1 -0.488447 YearBuilt -0.598087 LotFrontage -0.808022 BsmtUnfSF -1.536727 GarageYrBlt -3.922152 dtype: float64 #Boxplot for numerical_featuressns.set_style("whitegrid")f, ax = plt.subplots(figsize=(15, 15))ax.set_xscale("log")ax = sns.boxplot(data=data[numerical_features] , orient="h", palette="ch:2.5,-.2,dark=.3")ax.set(ylabel="Features")ax.set(xlabel="Value")ax.set(title="Distribution")sns.despine(trim=True, left=True) 特征处理完后可以将数据再分割开： train = data[:size_train_df]test = data[size_train_df:] 建模构建算法模型，常用的几个算法模型都试试，然后设置交叉检验: from sklearn.linear_model import ElasticNet, Lasso, BayesianRidge, LassoLarsICfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressorfrom sklearn.kernel_ridge import KernelRidgefrom sklearn.pipeline import make_pipelinefrom sklearn.preprocessing import RobustScalerfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clonefrom sklearn.model_selection import KFold, cross_val_score, train_test_splitfrom sklearn.metrics import mean_squared_errorimport xgboost as xgbimport lightgbm as lgb 定义一个交叉评估函数 #Validation functionn_folds = 5def rmsle_cv(model): kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values) rmse= np.sqrt(-cross_val_score(model, train.values, target_variable, scoring="neg_mean_squared_error", cv = kf)) return(rmse) LASSO回归(LASSO Regression)采用了L1范数，即绝对值之和。注：当数据包含许多异常值，使用均值和方差缩放可能并不是一个很好的选择。这种情况下，可以使用 robust_scale 以及 RobustScaler 作为替代品。 lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))score = rmsle_cv(lasso)print("\nLasso score: &#123;:.4f&#125; (&#123;:.4f&#125;)\n".format(score.mean(), score.std())) Lasso score: 0.1101 (0.0058) 岭回归（Kernel Ridge Regression）采用了L2范数，即平方和。 KRR = make_pipeline(RobustScaler(), KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5))score = rmsle_cv(KRR)print("\nLasso score: &#123;:.4f&#125; (&#123;:.4f&#125;)\n".format(score.mean(), score.std())) Lasso score: 0.1152 (0.0043) 弹性网络回归(Elastic Net Regression)ElasticNet 是一种使用L1和L2先验作为正则化矩阵的线性回归模型,弹性网络是结合了岭回归和Lasso回归，由两者加权平均所得。https://www.jianshu.com/p/65a573b9fe32 ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))score = rmsle_cv(ENet)print("\nLasso score: &#123;:.4f&#125; (&#123;:.4f&#125;)\n".format(score.mean(), score.std())) Lasso score: 0.1100 (0.0059) 组合模型现在常用的组合模型有提升树(Gradient Boosting Regression)、XGBoost、LightGBM 等提升树(Gradient Boosting Regression): GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05, max_depth=4, max_features='sqrt', min_samples_leaf=15, min_samples_split=10, loss='huber', random_state=5)score = rmsle_cv(GBoost)print("\nLasso score: &#123;:.4f&#125; (&#123;:.4f&#125;)\n".format(score.mean(), score.std())) Lasso score: 0.1164 (0.0082) XGBoost model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, learning_rate=0.05, max_depth=3, min_child_weight=1.7817, n_estimators=2200, reg_alpha=0.4640, reg_lambda=0.8571, subsample=0.5213, silent=1, random_state =7, nthread = -1)score = rmsle_cv(model_xgb)print("\nLasso score: &#123;:.4f&#125; (&#123;:.4f&#125;)\n".format(score.mean(), score.std())) Lasso score: 0.1172 (0.0053) LightGBM model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5, learning_rate=0.05, n_estimators=720, max_bin = 55, bagging_fraction = 0.8, bagging_freq = 5, feature_fraction = 0.2319, feature_fraction_seed=9, bagging_seed=9, min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)score = rmsle_cv(model_lgb)print("\nLasso score: &#123;:.4f&#125; (&#123;:.4f&#125;)\n".format(score.mean(), score.std())) Lasso score: 0.1162 (0.0060) 寻找最优参数通过可视化的方式来看看如何寻找模型最优参数 alphas = [0.00005, 0.0001, 0.0005, 0.001, 0.005, 0.01]cv_ridge_score = [rmsle_cv(make_pipeline(RobustScaler(), Lasso(alpha=alpha, random_state=1))).mean() for alpha in alphas] cv_ridge = pd.Series(cv_ridge_score, index = alphas)cv_ridge.plot(title = "Validation - Just Do It")plt.xlabel("alpha")plt.ylabel("rmse") Text(0, 0.5, &apos;rmse&apos;) 几个基础模型预测值的比较: train_size = int(len(train)*0.7)X_train = train.values[:train_size]X_test = train.values[train_size:]y_train = target_variable[:train_size]y_test = target_variable[train_size:]GBoost.fit(X_train, y_train)ENet.fit(X_train, y_train) Pipeline(memory=None, steps=[(&apos;robustscaler&apos;, RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True, with_scaling=True)), (&apos;elasticnet&apos;, ElasticNet(alpha=0.0005, copy_X=True, fit_intercept=True, l1_ratio=0.9, max_iter=1000, normalize=False, positive=False, precompute=False, random_state=3, selection=&apos;cyclic&apos;, tol=0.0001, warm_start=False))]) 残差图 preds = pd.DataFrame(&#123;"preds":GBoost.predict(X_test), "true":y_test&#125;)preds["residuals"] = preds["true"] - preds["preds"]preds.plot(x = "preds", y = "residuals",kind = "scatter") &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f8c1a72aef0&gt; preds = pd.DataFrame(&#123;"preds":ENet.predict(X_test), "true":y_test&#125;)preds["residuals"] = preds["true"] - preds["preds"]preds.plot(x = "preds", y = "residuals",kind = "scatter") &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f8c1a6ed128&gt; xgb_preds = np.expm1(GBoost.predict(X_test))lasso_preds = np.expm1(ENet.predict(X_test))predictions = pd.DataFrame(&#123;"xgb":xgb_preds, "lasso":lasso_preds&#125;)predictions.plot(x = "xgb", y = "lasso", kind = "scatter") &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f8c00ba9d30&gt; 集成学习(模型融合)Stacking models 是指通过将多个模型进行集成以取得更小预测方差的方法, 通过前面的两个模型残差图的分布可以发现具有一定的互补性，所以这才是融合的目的，将他的残差分布变得更均匀。平均模型 class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin): def __init__(self, models): self.models = models # we define clones of the original models to fit the data in def fit(self, X, y): self.models_ = [clone(x) for x in self.models] # Train cloned base models for model in self.models_: model.fit(X, y) return self #Now we do the predictions for cloned models and average them def predict(self, X): predictions = np.column_stack([ model.predict(X) for model in self.models_ ]) return np.mean(predictions, axis=1) averaged_models = AveragingModels(models = (ENet, GBoost, KRR, lasso))score = rmsle_cv(averaged_models)print(" Averaged base models score: &#123;:.4f&#125; (&#123;:.4f&#125;)\n".format(score.mean(), score.std())) Averaged base models score: 0.1081 (0.0056) 堆叠模型(Stacking Averaged Models)其由两部分组成，一部分是基准模型，一部分是回归模型：基准模型和大量数据组合预测一堆结果，然后根据预测结果通过回归模型预测和真实值的差异。具体如下： class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin): def __init__(self, base_models, meta_model, n_folds=5): self.base_models = base_models self.meta_model = meta_model self.n_folds = n_folds def fit(self, X, y): self.base_models_ = [list() for x in self.base_models] self.meta_model_ = clone(self.meta_model) # 复制基准模型，因为这里会有多个模型 kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156) # 训练基准模型，基于基准模型训练的结果导出成特征 # that are needed to train the cloned meta-model out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models))) for i, model in enumerate(self.base_models): for train_index, holdout_index in kfold.split(X, y): #分为预测和训练 instance = clone(model) self.base_models_[i].append(instance) instance.fit(X[train_index], y[train_index]) y_pred = instance.predict(X[holdout_index]) out_of_fold_predictions[holdout_index, i] = y_pred # 将基准模型预测数据作为特征用来给meta_model训练 self.meta_model_.fit(out_of_fold_predictions, y) return self def predict(self, X): meta_features = np.column_stack([ np.column_stack([model.predict(X) for model in base_models]).mean(axis=1) for base_models in self.base_models_ ]) return self.meta_model_.predict(meta_features) from sklearn.linear_model import LinearRegressionmeta_model = LinearRegression()stacked_averaged_models = StackingAveragedModels(base_models = (ENet, GBoost, KRR, lasso), meta_model = meta_model, n_folds=10)score = rmsle_cv(stacked_averaged_models)print("Stacking Averaged models score: &#123;:.4f&#125; (&#123;:.4f&#125;)".format(score.mean(), score.std())) Stacking Averaged models score: 0.1086 (0.0060) 参考资料https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboardhttps://www.kaggle.com/jolasa/eda-anda-data-preparation-7th-placehttps://www.kaggle.com/apapiu/regularized-linear-models]]></content>
      <categories>
        <category>技术博文</category>
        <category>kaggle</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>kaggle</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NLP数据集介绍]]></title>
    <url>%2F2019%2F%E9%9A%90%E8%97%8F%2FNLP%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[中文词向量腾讯AI Lab 词向量 开源中文词向量 实体识别与链指CCKS 2019 中文短文本的实体链指 链接: https://pan.baidu.com/s/1PIqV0l8tr1SLxfBRSpsHJw 提取码: 58i4]]></content>
      <categories>
        <category>技术博文</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>数据集</tag>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HEXO MathJax 部分渲染出错问题解决]]></title>
    <url>%2F2019%2F%E8%BF%90%E7%BB%B4%2Fhexo-mathjax-%E9%83%A8%E5%88%86%E6%B8%B2%E6%9F%93%E5%87%BA%E9%94%99%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[hexo 的部分mathjax 在渲染的时候由于被 markdown 自身的转义会出现渲染错误的情况，比如： $$\alpha_&#123;t' t&#125; = \text&#123;softmax&#125;(\sigma(\boldsymbol&#123;s&#125;_&#123;t' - 1&#125;, \boldsymbol&#123;h&#125;_t))$$ 在hexo中会显示为：$$\alpha{t’ t} = \text{softmax}(\sigma(\boldsymbol{s}{t’ - 1}, \boldsymbol{h}_t))$$ 这是由于hexo在处理转义造成的，_是斜体，但是在latex中，却有下标的意思，就会出现问题，\\的换行，在markdown中，\\会被转义为\,这样也会影响影响mathjax对公式中的\\进行渲染，网上很多人的建议是在配置文件中去改Hexo中的逃逸字符，如：https://segmentfault.com/a/1190000007261752http://wangwlj.com/2017/09/21/markdown_mathjax/ 其实这样的做法并不优雅，如果在某种情况遇到需要用到这种逃逸字符的时候，就会失效，官方推荐的是用{\% raw \%}MathJax{\% endraw \%}来解决 $$\alpha_{t' t} = \text{softmax}(\sigma(\boldsymbol{s}_{t' - 1}, \boldsymbol{h}_t))$$]]></content>
      <categories>
        <category>技术博文</category>
        <category>命令工具</category>
      </categories>
      <tags>
        <tag>入门教程</tag>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈CGO]]></title>
    <url>%2F2019%2F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%2F%E6%B5%85%E8%B0%88CGO%2F</url>
    <content type="text"><![CDATA[C 语言作为最古老的一门编程语言之一，其具有大量的高性能的函数库，很多语言都提供了C 语言的调用接口，GO 作为新时代的开拓者，同时也应该站在巨人的肩膀上， CGO 就是一个提供 GO 和 C 相互调用的桥梁工具。 CGO 的基本语法在 GO 中调用 C：package main//#include &lt;stdio.h&gt;import "C"func main() &#123; C.puts(C.CString("vim-go"))&#125; 直接在go的源码里面加入import &quot;C&quot;就可以导入CGO。在import &quot;C&quot;前面的注释会被默认成 C 代码（不能空行，必须在顶行相连）这里的 “C” 不是包名，而是一种类似名字空间的概念，或可以理解为伪包，C语言所有语法元素均在该伪包下面如C.uint、C.print、C.free等。]]></content>
      <categories>
        <category>技术博文</category>
        <category>编程语言</category>
        <category>GO</category>
      </categories>
      <tags>
        <tag>Golang</tag>
        <tag>CGO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jupyter-notebook做幻灯片]]></title>
    <url>%2F2019%2F%E8%BF%90%E7%BB%B4%2Fjupyter-notebook%E5%81%9A%E5%B9%BB%E7%81%AF%E7%89%87%2F</url>
    <content type="text"><![CDATA[设置幻灯片设置幻灯片： 启动幻灯片服务： jupyter nbconvert notebook.ipynb –to slides –post serve 利用IFrame来加载网页开启跨域请求设置： jupyter notebook –generate-config 在用户目录下找到.jupyter/jupyter_notebook_config.pyc.NotebookApp.tornado_settings = &#123; 'headers': &#123; 'Content-Security-Policy': "frame-ancestors self *; report-uri /api/security/csp-report" &#125; &#125;]]></content>
      <categories>
        <category>技术博文</category>
        <category>系统运维</category>
      </categories>
      <tags>
        <tag>jupyter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[golang性能测试及优化(上)]]></title>
    <url>%2F2019%2F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%2Fgolang%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%8F%8A%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[以斐波那契数列作为测试用例:package fibfunc Fib(n int) int &#123; switch n &#123; case 0: return 0 case 1: return 1 case 2: return 2 default: return Fib(n-1) + Fib(n-2) &#125;&#125; 性能测试Benchmarks的用法和单元测试类似，也是用的testing，性能测试用*testing.B代替*testing.T 单元测试日志 方法 说明 Log 打印日志，同时结束测试 Logf 格式化打印日志，同时结束测试 Error 打印错误日志，同时结束测试 Errorf 格式化打印错误日志，同时结束测试 Fatal 打印致命日志，同时结束测试 Fatalf 格式化打印致命日志，同时结束测试 以上方法testing.B也可以使用。 编写性能测试fib_test.go:package fibimport ( "testing")func BenchmarkFib20(b *testing.B) &#123; for n := 0; n &lt; b.N; n++ &#123; Fib(20) // run the Fib function b.N times &#125;&#125; 运行go test -bench=., 结果： goos: linux goarch: amd64 BenchmarkFib20-8 50000 37932 ns/op PASS Windows 下使用 go test 命令行时，-bench=.应写为-bench=&quot;.&quot; 参数-cpu表示开启CPU的核数，通过GOMAXPROCS进行控制，比如-cpu=1,2,4表示分别开启1核、2核、4核进行测试： $ go test -bench=. -cpu=1,2,4 goos: linux goarch: amd64 BenchmarkFib20 50000 36877 ns/op BenchmarkFib20-2 50000 36843 ns/op BenchmarkFib20-4 30000 36231 ns/op 参数-benchtime可以让我们自己控制测试的时间，比如: $ go test -bench=. -benchtime=3s goos: linux goarch: amd64 BenchmarkFib20-8 100000 46070 ns/op PASS ok _/home/shikanon/study/fib 5.018s 你会发现总的运行时间并不是3s，而且不同的运行其时间会有差异，这主要是因为由于GC活动、后台运行程序、内存位置、CPU的调整频率所影响。 为了获得稳定的统计，我们可以用-count参数来获得多次测试。 $ go test -bench=. -count=10 goos: linux goarch: amd64 BenchmarkFib20-8 50000 38395 ns/op BenchmarkFib20-8 50000 37019 ns/op BenchmarkFib20-8 50000 36974 ns/op BenchmarkFib20-8 50000 41050 ns/op BenchmarkFib20-8 50000 36131 ns/op BenchmarkFib20-8 30000 37317 ns/op BenchmarkFib20-8 30000 42872 ns/op BenchmarkFib20-8 30000 41711 ns/op BenchmarkFib20-8 50000 36517 ns/op BenchmarkFib20-8 50000 40240 ns/op PASS ok _/home/shikanon/study/fib 20.996s 接下来可以利用benchstat包计算平均值，benchstat是官方pref项目中的命令行工具，可以用来做各种性能测试的分析，比如计算多次测试的平均值核方差： $benchstat old.txt name time/op Fib20-8 39.4µs ±13% ps:由于pref是golang/x中的包，我们需要git clone下载下来，然后到benchstat目录下做编译go build -o $GOROOT/bin/benchstat main.go 也可以用来计算两种不同方法进行比较，看他们的p值是否显著。在对比两个或以上的用例时可以用go test -c生成二进制测试文件。 ./fib2.test -bench=. -test.count=10 &gt; old.txt ./fib.test -bench=. -test.count=10 &gt; new.txt $ benchstat old.txt new.txt name old time/op new time/op delta Fib20-8 44.3µs ± 6% 25.6µs ± 2% -42.31% (p=0.000 n=10+10) 关于 golang 的 for range 的性能比较在潜意识中，我们通常会觉得遍历一个数组会更慢，但由于for range遍历的时候不需要对对下标越界的判断，因此性能会比遍历判断更好些。 package mainimport ( "testing")func BenchmarkArray(b *testing.B) &#123; var a = 0 for i := 0; i &lt; b.N; i++ &#123; var times [100][0]int for range times &#123; a += 1 &#125; &#125;&#125;func BenchmarkInt(b *testing.B) &#123; var a = 0 for i := 0; i &lt; b.N; i++ &#123; for i := 0; i &lt; 100; i++ &#123; a += 1 &#125; &#125;&#125; （注：[100][0]int类型的数组由于元素[0]int的内存为0，即使第一维数组有长度也不需要付出额外的代价） 测试结果： go test -bench=. goos: windows goarch: amd64 BenchmarkArray-8 50000000 36.1 ns/op BenchmarkInt-8 20000000 65.9 ns/op PASS 我们可以看出 for range一个空数组比for要快一倍。 切片高效删除指定元素操作利用了零长切片的特性，实现高效删除技巧： func TrimSpaceWithAssignment(s []byte) []byte &#123; var b = make([]byte, len(s)) for i, x := range s &#123; if x != ' ' &#123; b[i] = x &#125; &#125; return b&#125;func TrimSpaceWithNil(s []byte) []byte &#123; var b = make([]byte, 0, len(s)) for _, x := range s &#123; if x != ' ' &#123; b = append(b, x) &#125; &#125; return b&#125;func TrimSpaceWithOrigin(s []byte) []byte &#123; b := s[:0] for _, x := range s &#123; if x != ' ' &#123; b = append(b, x) &#125; &#125; return b&#125;func BenchmarkAssignment(b *testing.B) &#123; s := []byte("asdf asdf sa fd dsa f d") for i := 0; i &lt; b.N; i++ &#123; TrimSpaceWithAssignment(s) &#125;&#125;func BenchmarkNilSlice(b *testing.B) &#123; s := []byte("asdf asdf sa fd dsa f d") for i := 0; i &lt; b.N; i++ &#123; TrimSpaceWithNil(s) &#125;&#125;func BenchmarkOrignSlice(b *testing.B) &#123; s := []byte("asdf asdf sa fd dsa f d") for i := 0; i &lt; b.N; i++ &#123; TrimSpaceWithOrigin(s) &#125;&#125; 测试结果： go test -bench=. goos: windows goarch: amd64 BenchmarkAssignment-8 30000000 43.7 ns/op BenchmarkNilSlice-8 30000000 47.6 ns/op BenchmarkOrignSlice-8 50000000 22.7 ns/op 参考https://dave.cheney.net/high-performance-go-workshop/dotgo-paris.htmlhttps://github.com/chai2010/advanced-go-programming-book/blob/master/ch1-basic/ch1-03-array-string-and-slice.md]]></content>
      <categories>
        <category>技术博文</category>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>Golang</tag>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[汽车大数据:天眼猎产品矩阵介绍]]></title>
    <url>%2F2019%2F%E6%9E%B6%E6%9E%84%2F%E6%B1%BD%E8%BD%A6%E5%A4%A7%E6%95%B0%E6%8D%AE-%E5%A4%A9%E7%9C%BC%E7%8C%8E%E4%BA%A7%E5%93%81%E7%9F%A9%E9%98%B5%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[天眼猎主要由三个产品矩阵组成，提供给经销商、二手车商的天眼猎-潜客分析平台工具，用于提供给用户做用户广告触达的天眼猎-精准投放平台，还有一款2C的产品天眼猎-车车拼小程序。 天眼猎-潜客分析平台为用户提供了市场分析、用户画像、渠道监测等功能。 天眼猎-精准投放平台精准投放平台主要提供了投放车型、社会属性、投放时间段和投放地域等特征。 天眼猎-车车拼小程序车车拼是一款用于沟通“拼团”购入新车的小程序平台，主要用于给经销商做线上活动推广和拼团活动。]]></content>
      <categories>
        <category>随笔日志</category>
        <category>项目管理</category>
      </categories>
      <tags>
        <tag>项目管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[构建自己的Python开源包]]></title>
    <url>%2F2019%2F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%2F%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84Python%E5%BC%80%E6%BA%90%E5%BA%93%2F</url>
    <content type="text"><![CDATA[要融入社区，第一步当然是要撰写一个自己的包。整个过程主要分为五步： 项目创建 搭建虚拟运行环境 编写项目代码 编写安装脚本 上传PyPi GIT 创建项目创建项目，确定项目名称，description, license等： 项目地址：https://github.com/shikanon/BaiduMapAPI 搭建虚拟环境我们在搭建自己的库的时候，是希望有一个干净的项目环境的，这时候virtualenv就很有用了，采用 virtualev 搭建虚拟环境，可以方便为后面生成私有项目的 requirement.txt 依赖包文件。 创建虚拟环境virtualev venv 启用 virtualev :source venv/Script/activate 构建项目代码简单，快速构建框架原型和骨架，记得包之间需要 __init__.py 文件，后面在编写setup.py也会很有用。项目结构： 构建好架构后，可以开始编写单元测试代码，pytest是个简单易用的库，可以帮助我们快速完成单元测试构建。 构建安装脚本，编写 setup.py 文件完成代码构建和测试就可以开始进入构建安装包环节。Python三方库安装常用的主要有两种模式：一种是直接从 github 上 clone 下来用 setup.py 安装，另一种是用 pip install 来安装。两种安装方法都是需要编写 setup.py 文件的。 对于第一种方法我们在安装前一般还要提供安装的依赖包， 也就是requirement.txt文件。在这里我们可以直接用 pip freeze 命令生成： pip freeze &gt; requirement.txt 因为我们是采用新建的虚拟环境开发，所以可以直接把环境中的三方库导入到requirement.txt 文件中。 构建好 requirement.txt后，就可以编写安装脚本。这里采用了setuptools编写安装脚本，Setuptools是一个包开发过程库，其增强Python标准库distutils，使得打包Python项目更简单。 setup.py文件案例： from setuptools import Command, find_packages, setup__lib_name__ = "BaiduMapAPI"__lib_version__ = "0.1.1"__description__ = "The Package of Baidu Map, with unofficial"__url__ = "https://github.com/shikanon/BaiduMapAPI"__author__ = "shikanon"__author_email__ = "account@shikanon.com"__license__ = "MIT"__keywords__ = ["Baidu", "map"]__requires__ = ["requests",]with open("README.rst", "r", encoding="utf-8") as f: __long_description__ = f.read()setup( name = __lib_name__, version = __lib_version__, description = __description__, url = __url__, author = __author__, author_email = __author_email__, license = __license__, packages = find_packages(exclude=("tests", "exmaple")), install_requires = __requires__, zip_safe = False, include_package_data = True, data_files = [("BaiduMapAPI/data", ["BaiduMapAPI/data/BaiduMap_cityCode_1102.txt"])], long_description = __long_description__) name 包名称version 版本号description 包描述url 包地址license 授权信息packages 需要处理的包目录，也就是包含__init__.py的文件夹install_requires 需要安装的依赖包data_files 可以用于引入一些额外的信息文件和数据，如图片、配置文件， [(&#39;文件要放入的文件夹1&#39;,[&#39;file1&#39;,file2&#39;]),(&#39;文件要放入的文件夹2&#39;,[&#39;file3&#39;,file4&#39;])] 第一个元素指最后在文件要放的位置/目录，如果空字符，表示放在根目录，第二个元素指原文件所在的位置。long_description 包的详细描述，后续上传到pypi，可以用于显示在主页上的描述 find_packages():这个函数会默认在和setup.py同一目录下搜索各个含有init.py的包。除了通过data_files添加数据包文件，还可以通过package_data设置可以被find_packages找到添加的文件： packages = find_packages(exclude=("tests", "exmaple")), # 所有包除了tests和exmaplepackage_data = &#123; '': ['*.csv'], # 任何包中含有.csv文件，都包含它 'data': ['data/*.dat'], # 包含data包data文件夹中的 *.dat文件&#125; 写好setup.py文件，可以python setupy install进行安装测试。 注册 pypi 并上传自己的库编写好安装脚本，就可以上传PyPi，当然，上传前要先看看上面是否已经有编写好的相关库了。如果很幸运没有，那么可以开始上传自己的包了，这里我们采用twine协助上传。 首先，完成PyPi的账户注册。 在用户目录下创建.pypirc文件， Linux在$HOME创建.pypirc， Windows在%HOMEDRIVE%下创建.pypirc，加入： [distutils]index-servers = pypi pypitest[pypi]repository: https://upload.pypi.org/legacy/username: 账户password: 密码[pypitest]repository: https://test.pypi.org/legacy/username: 账户password: 密码 安装twine: pip install twine 创建： python setup.py sdist bdist_wheel 上传PyPi: twine upload dist/* 上传成功后可以运行pip install命令测试。 编写文档编写README.md和说明文档docs，这里我们用sphinx库来创建文档架构，sphinx是一个智能、漂亮的文档生成工具。 初始化docs文件夹sphinx-quickstart 编写rst文件，运行make html即可生成html文档, rst文档例子：Welcome to BaiduMapAPI's documentation!=======================================.. toctree:: :caption: Basic concepts :hidden: api dataset Indices and tables==================* :ref:`genindex`* :ref:`modindex`* :ref:`search` 注：如果已经有配置文件了，可以用sphinx-build来指定生成目录sphinx-build -b html source/ build/ 上传github最后上传到 github，这样一个完整的 Python 三方包的开源完成了。 Windows上得中文Python二进制包资源：https://www.lfd.uci.edu/~gohlke/pythonlibs/]]></content>
      <categories>
        <category>技术博文</category>
        <category>编程语言</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>入门教程</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈：Golang 并发]]></title>
    <url>%2F2019%2F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%2F%E6%B5%85%E8%B0%88%EF%BC%9A%E5%B9%B6%E5%8F%91%2F</url>
    <content type="text"><![CDATA[进程与线程概念 在面向进程设计的系统中，进程(process)是程序的基本执行实体；在当代面向线程设计的计算机结构中，进程是线程的容器。进程是程序(指令和数据)的真正运行实例。用户下达运行程序的命令后，就会产生进程。同一程序可产生多个进程（一对多关系），以允许同时有多位用户运行同一程序，却不会相冲突。 线程(thread)是操作系统能够进行运算调度的最小单位，线程分为内核线程、轻量级进程、用户线程；内核线程是指操作系统内核调度的线程，如Win32线程；用户线程是由用户进程自行调度的线程，如Linux平台的POSIX Thread; 轻量级进程(LWP)是建立在内核之上并由内核支持的用户线程。 【内核线程】&lt;-&gt;【轻量级进程】&lt;-&gt;【用户线程】 在用户空间模拟操作系统对进程的调度，来调用一个进程中的线程，每个进程中都会有一个运行时系统，用来调度线程。此时当该进程获取cpu时，进程内再调度出一个线程去执行，同一时刻只有一个线程执行。 内核级线程:切换由内核控制，当线程进行切换的时候，由用户态转化为内核态。切换完毕要从内核态返回用户态。 系统调度 线程本质可以看成是一系列的指令集。 线程一般分为三种状态： 阻塞态：表示线程已经停止，需要等待一些事情发生后才可继续。这有很多种原因，比如需要等待硬件（磁盘或网络），系统调用，或者互斥锁（atomic, mutexes）。这类情况导致的延迟，往往是性能不佳的根本原因。 就绪态：这代表线程想要一个 CPU 核来执行被分配的机器指令。如果你有很多个线程需要 CPU，那么线程就不得不等待更长时间。此时，因为许多的线程都在争用 CPU，每个线程得到的运行时间也就缩短了。 运行态：这表示线程已经被分配了一个 CPU 核，正在执行它的指令。与应用相关的工作正在被完成。这是每个人都想要的状态。 CPU密集型任务和IO密集型任务CPU密集处理任务中线程很少进入阻塞态。它一直都需要使用 CPU，因此线程的切换并没有用，甚至会产生负面效果，主要通过多核并行来解决问题。这种工作通常都是数学计算。比如计算圆周率的第 n 位的工作就属于 CPU密集型的工作。IO密集任务线程会经常进入阻塞态，比如网络请求资源，或者系统调用。一个需要访问数据库的线程属于 IO密集的。互斥锁的使用也属于这种。这时候线程的切换来提升并发量。 线程调度存在的问题昂贵的代价 上下文切换 Cache Line 命中率 上下文切换上下文切换是指调度器把一个线程从CPU核上拿下来，把另一个就绪态的线程放到CPU核上。线程的上下文切换时间一般是50~100ns，这是为什么如果对于计算密集型的任务频繁切换反而会导致效果更差。 Cache Line 命中率由于访问主内存很耗时间，CPU大部分会访问cache，现代CPU缓存一般分为了三层。离CPU越远的，其访问速度越慢。因此提高 Cache Line 命中率是提高性能的很重要的而一种方法，一般来说优化缓存可从三个方面入手：一、减少命中时间；二、降低失效率；三、减轻失效代价。但是，对于多核系统来说，多线程在每个核都有一份它自己所需要数据的拷贝，随着 CPU 核上运行的线程的改变，不同的线程需要访问的数据不同，从而导致同一个 cache line 中的数据被修改了，其他所有核上的 cache line 拷贝都标记为“不可用”，当其他核上的线程试图访问或修改这个数据时，需要重新从主内存上拷贝最新的数据到自己的 cache 中。 Goroutine 的模型设计 P：是一个逻辑处理器的概念，当P有任务时需要创建或者唤醒一个系统线程来执行它队列里的任务，所以P/M绑定构成一个执行单元。当你的 Go 程序启动之初，它会被分配一个逻辑处理器，每一个 P 会被分配一个系统线程(M)。这个 M 会被操作系统调度，操作系统把线程(M)放到一个 CPU Core 上去执行，在执行的时候，每个线程都被绑定上了一个独立的 P 。 M：是一个线程或称为Machine，所有M是有线程栈的。 G：表示一个Goroutine。 执行队列在 Go 调度器中有 2 个不同的执行队列：全局队列（Global Run Queue, 简称 GRQ）和本地队列（Local Run Queue，简称 LRQ）。每一个 P 都会有一个 LRQ 来管理分配给 P 上的 Goroutine。这些 Goroutine 轮流被交付给 M 执行。GRQ 是用来保存还没有被分配到 P 的 Goroutine。LRQ是 Lock-Free 的，处理速度快；GRQ为保证数据竞争问题，需要加锁处理，速度比LRQ慢，因此 P 处理完LRQ的时候会先找其他 P 的LRQ，最后再去找GRQ。 goroutine队列调度runtime.schedule() &#123; // only 1/61 of the time, check the global runnable queue for a G. // if not found, check the local queue. // if not found, // try to steal from other Ps. // if not, check the global runnable queue. // if not found, poll network.&#125; Goroutine调度为何更好？ Go的调度是基于用户态事件而非抢占式的，比如关键字go、垃圾回收、同步互斥操作如Lock() Unlock()。 Go通过尽可能多在M上来运行goroutine，从而提高CPU的利用率，Go通过”spinning threads”最小化系统线程的切换。 利用gorountine可以避免系统线程的切换，从而提高Cache Line 命中率。 线程的stack size更大(≥ 1MB)，而gorountine得stack size只有2KB，启动更慢。 参考文献https://www.cnblogs.com/Eva-J/articles/8306047.html#_label7 http://www.imooc.com/article/42071 http://baijiahao.baidu.com/s?id=1587634508058779877&amp;wfr=spider&amp;for=pc https://rakyll.org/scheduler/ https://www.ardanlabs.com/blog/2018/08/scheduling-in-go-part2.html]]></content>
      <categories>
        <category>技术博文</category>
        <category>编程语言</category>
        <category>GO</category>
      </categories>
      <tags>
        <tag>编程语言</tag>
        <tag>Golang</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅聊关于 nginx 的 rewrite]]></title>
    <url>%2F2019%2F%E8%BF%90%E7%BB%B4%2F%E6%B5%85%E8%81%8A%E5%85%B3%E4%BA%8E-nginx-%E7%9A%84-rewrite%2F</url>
    <content type="text"><![CDATA[rewrite用法rewrite用法Syntax: rewrite regex replacement [flag];Context: server, location, if rewrite的主要放在server、location或者if中。 语法： rewrite 正则表达式 替换内容 [标识符] rewrite标识符主要包含四种：- laststops processing the current set of ngx_http_rewrite_module directives and starts a search for a new location matching the changed URI;完成该rewrite规则的执行后，停止处理后续rewrite指令集；然后查找匹配改变后URI的新location；- breakstops processing the current set of ngx_http_rewrite_module directives as with the break directive;完成该rewrite规则的执行后，停止处理后续rewrite指令集，并不再重新查找；但是当前location内剩余非rewrite语句和location外的的非rewrite语句可以执行；- redirectreturns a temporary redirect with the 302 code; used if a replacement string does not start with “http://”, “https://”, or “$scheme”;返回302临时重定向，地址栏会显示跳转后的地址；- permanentreturns a permanent redirect with the 301 code.返回301永久重定向，地址栏会显示跳转后的地址；即表示如果客户端不清理浏览器缓存，那么返回的结果将永久保存在客户端浏览器中了。 1）last一般写在server和if中，而break一般使用在location中；2）last不终止重写后的url匹配，即新的url会再从server走一遍匹配流程，而break终止重写后的匹配；3）break和last都能组织继续执行后面的rewrite指令。 正则表达式和变量替换内容$1和$2表示前面匹配的第一个括号和第二个括号的内容，类似于Python的re模块的findall命令，比如下面例子rewrite '^/([0-9]&#123;4&#125;)/\d+/\d+/(.*)$' '/$1/$2' last; $1表示([0-9]{4})匹配所得到的值;$2表示(.*)匹配所得到的值； ^表示以此为开头的完全匹配$表示以此为结尾的完全匹配]]></content>
      <categories>
        <category>技术博文</category>
        <category>系统运维</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[随笔:创业这一年那些事(1)]]></title>
    <url>%2F2019%2F%E6%88%98%E7%95%A5%2F%E9%9A%8F%E7%AC%94-%E5%88%9B%E4%B8%9A%E8%BF%99%E4%B8%80%E5%B9%B4%E9%82%A3%E4%BA%9B%E4%BA%8B-1%2F</url>
    <content type="text"><![CDATA[2018年初，那时候“三点钟”群一时之间炒爆了全国，所有人都带着狂热，市场一片欣欣向荣的光景，年轻人们都被“优秀的同龄人”的焦虑所缠绕。。。 大年初三，大家还都荡漾在开春的喜悦中，Rio找到我，说希望可以研究下区块链技术，那时候正好对区块链感兴趣，年前还整理过一份区块链技术培训的资料，就答应下来了。过完年，Rio就约我过去开会，会后给我介绍了Frankie，之前一个跟电信合作的公司的老板，之前有过一面之缘，互换过名片，但影响并不是很深刻。Frankie见到我一过来就开门见山，跟我说希望你可以加入我们公司… Frankie找到我，说希望能加入他们公司一起创业，做汽车互联网。其实对于汽车这个行业我一直不是很了解，虽然作为一个直男，但我是很少了解有了解关注汽车，在影响中好像只知道宝马大众之类的。但那时候已经有换新工作的想法了，毕竟在useease呆了三年多了，而且同期进来的伙伴们也都闯南走北去了，想了大半个月，期间也去过公司简单考察过就答应下来了。其实，最后让下决心是两个因素，一个是Frankie给人感觉还可以，虽然在技术上不是很懂，但也愿意听取意见；一个是自己想出去闯闯，毕竟“外面”闹得这么热腾，而且也想锤炼下自己的全局能力，毕竟在useease管理过团队也研究过技术，但一直没尝试过从产品到研发和运营的一整套打法。 定基调到公司第一件事，我做了战略框架的梳理，首先向Frankie、Jason两位创始人了解了公司的定位——成为一家类似于埃森哲的集广告与营销于一身的咨询类科技公司。既然定下了基调，那么先确定核心的优势，从哪里重点切入？其实，在当时我们已经跟运营商合作开发了半年多了，这是一块很大的资本，所以，在那时归纳起来就是数据，那么，我把技术基调定位构建一套规模庞大而有用的汽车大数据中心。 其实，这中间还有一个小插曲。这里暂时不介绍。 小插曲就说到这，后面也做些前期的技术规划和总结。 搭建技术团队及技术选型第一次以一家创业公司技术负责人身份来思考团队架构和目标。 之前在useease担任研发技术经理，主要是管理项目和制定产品，人员上以小规模团队作战为主，由于业务和目标明确，较少需要思考团队组织架构和资源规划。（由于是内部项目，人员资源不足可以向上面协调和借调，而且像产品、美工、测试公司都是统一使用的，设备也是在统一的集群资源上分配） 首先从设备选型、方案设计、核心算法选择、可靠性、安全性的考虑，以及风险管理进行组织规划。 设备选型因为前期计划是先做RTB程序化广告系统的，对延迟性和并发有要求，在单机选型上选了 Dell PowerEdge R730， 2U 的机架结构和他那强劲的CPU Xeon E5-2640 v4 象征着力量与实力，内存是4条 16G 的内存条，配备 8TB 硬盘 （后来在数据处理的时候发现硬盘读写存在瓶颈，又加了2TB固态硬盘），在单机性能上还算是过得去了。 硬盘存储方案选择 RAID 5，在数据保障和磁盘利用率之前折中 8TB 硬盘实际变成 6T 多，系统选用了 Centos 7 ，Red Hat 以稳定性著称，也适合线上环境运行。 系统目录结构分配：/dev/mapper/centos-root 1.2T 4.9G 1.2T 1% /devtmpfs 32G 0 32G 0% /devtmpfs 32G 0 32G 0% /dev/shmtmpfs 32G 92M 32G 1% /runtmpfs 32G 0 32G 0% /sys/fs/cgroup/dev/sda2 94G 231M 93G 1% /boot/dev/mapper/centos-home 3.2T 2.7G 3.1T 1% /home/dev/mapper/centos-var 917G 152G 719G 18% /var/dev/mapper/fastDevice-docker 689G 154G 501G 24% /var/lib/dockertmpfs 6.3G 4.0K 6.3G 1% /run/user/42tmpfs 6.3G 48K 6.3G 1% /run/user/1000 fastDevice-docker是后面加入的固态硬盘，主要用于扩充 docker 存储，给程序做读写加速。 方案设计 虚拟化方案 容器化和虚拟化不管对于小团队作战也好，大规模应用开发也好，都是团队不错的选择。对于小团队，特别是服务器资源有限的团队，进行虚拟化可以更方便协调团队资源，划分多环境开发，同时虚拟化也更容易进行风控，更安全。后期随着规模逐步扩大，也可以非常方便地转型成微服务应用，帮忙大团队以小团队的效率进行开发迭代。因此底层采用虚拟化方案将硬件和资源进行分离。 虚拟化方案选择了更轻量的 Docker 代替虚拟机，容器管理选择 Kubernetes，主要经历了 2017 的容器编码大战之后，Kubernetes 项目已经成为了构建容器化平台体系的默认选择，是一个非常优秀的容器应用的部署、扩展和管理的解决方案，也可以作为企业实现原生云(Cloud Native)概念的支持。 数据层 关系型数据库采用MySQL，这里主要采购了腾讯云的MySQL高可用解决方案。 缓存层采用Redis,主要用于缓存用户请求信息。 Hadoop作为底层的分布式数据库，主要用于存储运营商传过来的DPI分析结果数据。每天的规模在2~3G，kafka作为消息中间件。 计算层 计算层主要分为两部分，一部分是对数据做传统的统计分析或者运用传统的机器学习模型进行建模，主要用Spark使用；一部分是基于深度学习框架进行建模，这里分为两个工具，一个是用于算法研发阶段使用的：PyTorch，一个是用于生产环境，成熟稳定的：Tensorflow。 应用层 最后一层是应用层。每个应用以容器的形式运行在系统上，与作为中台的计算层进行交互。 风险管控技术风控上有几点： 第一个是语言选型。前期团队语言选择Python，有几个原因，（1）Python简单，而且我作为技术负责人也是最擅长；（2）便于前期快速迭代开发，招人也相对简单；（3）可以很好的和数据分析、机器学习等进行整合，使用统一的技术栈。前段选用Vue，（1）小团队开发以语言易用，易招聘为根本；（2）Vue作为国人贡献的产品，中文支持力度好。我觉得前期的技术选型，简单易用是技术风控最关键的。 服务器安全管理。要控制好风险，服务器的安全管控和项目上线流程要梳理好，（1）对各级开发者的账号权限的管理，严格控制sudo权限;（2）采用严格的安全策略，禁止远程密码登陆，换ssh端口，对所有对外开启的端口进行记录，数据库限制为只能内网访问，采用keeweb记录密码和管理密钥。 问题研发人员少，主力工程师研发、运维一把抓 功能增加，复杂性逐渐变高 频繁改动，系统脏、乱、差 团队基础设施搭建在创业初期，团队的基础工具集搭建是十分重要的，是效率和生产力的保证。在这里我主要搭建了代码管理平台gitlab、持续集成工具git-runner、部署采用了容器化技术、在后续的架构升级中也引入了容器编排工具kubernetes，项目管理用的腾讯的TAPD。 在构思技术选型中重要的是想清楚：1、在什么阶段，解决的是什么问题2、有哪些解决方案，为什么选择A而不选择B，取舍的关键是什么3、突破的创新是什么，如果不做会怎么样，如何平衡创新和业务的关系4、如何保持持续的维护性和创新性]]></content>
      <categories>
        <category>随笔日志</category>
        <category>创业</category>
      </categories>
      <tags>
        <tag>创业</tag>
        <tag>项目管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[随笔:创业这一年那些事(2)]]></title>
    <url>%2F2019%2F%E6%88%98%E7%95%A5%2F%E9%9A%8F%E7%AC%94-%E5%88%9B%E4%B8%9A%E8%BF%99%E4%B8%80%E5%B9%B4%E9%82%A3%E4%BA%9B%E4%BA%8B-2%2F</url>
    <content type="text"><![CDATA[管理篇在创业过程中，最核心的是“人”，因此团队搭建的重要性不言而喻。 团队搭建问题总结： 1、员工间的薪资平衡有时候会严重影响对优秀人才的引进和团队升级。 其实这个点就是传说中新人进来工资倒挂问题，由于团队比较小，大家经常混迹在一起，如果员工之间的待遇从暗地里走到明面上的话，那么当需要招聘一个更优秀的新人的时候，团队的结构就会开始变得不稳定。特别对于创业初期，整个团队结构十分得扁平化得时候，A和B干得是相似得活，如果B比A高出了一截，那么A必然会愤愤不平，虽然在潜力上B比A要好很多。 2、大量使用实习生，虽物美价廉，但如果没有管理好人和代码质量，在平凡离职招聘循环中会给团队带来大量得隐性成本损失 创业团队在前期使用实习生可以很好的控制成本，但在这个过程中其实存在着隐性成本，包括两大块：技术培训成本、离职交接成本；技术培训成本其实就是常说的带人，如果一个团队中很多核心部分也逐渐交给实习生，那么就不能放任他们自己去做，需要在代码规范、编程范式、技术选型上做好把控，而这样就需要有经验的程序员持续地跟进，而老程序员在这个过程中的指导成本是一块很大的隐性成本。第二块比较大的隐性成本来至于不稳定导致的离职率高，特别是在春招和秋招之季，如果团队的凝聚力不够那么会有一大波的离职潮。因此，在招大量任用实习生的时候]]></content>
      <categories>
        <category>随笔日志</category>
        <category>创业</category>
      </categories>
      <tags>
        <tag>创业</tag>
        <tag>项目管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Helm包管理-入门]]></title>
    <url>%2F2019%2F%E8%BF%90%E7%BB%B4%2FHelm%E5%8C%85%E7%AE%A1%E7%90%86-%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[结构简介Helm 是一个用于 kubernetes 的包管理器，每个包称为一个 Chart，一个 Chart 是一个目录，对于应用发布者而言，可以通过Helm打包应用，管理应用依赖关系，管理应用版本并发布应用到软件仓库。 对于使用者而言，使用Helm后不用需要了解 Kubernetes 的 Yaml 语法并编写应用部署文件，可以通过Helm下载并在kubernetes上安装需要的应用。 Helm Helm 是一个命令行下的客户端工具。主要用于 Kubernetes 应用程序 Chart 的创建、打包、发布以及创建和管理本地和远程的 Chart 仓库。 Tiller Tiller 是 Helm 的服务端，部署在 Kubernetes 集群中。Tiller 用于接收 Helm 的请求，并根据 Chart 生成 Kubernetes 的部署文件（ Helm 称为 Release ），然后提交给 Kubernetes 创建应用。Tiller 还提供了 Release 的升级、删除、回滚等一系列功能。 Chart Helm 的软件包，采用 TAR 格式。类似于 APT 的 DEB 包或者 YUM 的 RPM 包，其包含了一组定义 Kubernetes 资源相关的 YAML 文件。 Repoistory Helm 的软件仓库，Repository 本质上是一个 Web 服务器，该服务器保存了一系列的 Chart 软件包以供用户下载，并且提供了一个该 Repository 的 Chart 包的清单文件以供查询。Helm 可以同时管理多个不同的 Repository。 安装下载二进制包安装：# 从官网下载最新版本的二进制安装包到本地：https://github.com/kubernetes/helm/releases# 解压tar -zxvf helm-v2.12.0-linux-amd64.tar.gz# 移动到bin目录cp linux-amd64/helm /usr/local/bin/helm 初始化 helm init --service-account=user-shikanon --stable-repo-url https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts]]></content>
      <categories>
        <category>技术博文</category>
        <category>容器技术</category>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>入门教程</tag>
        <tag>kubernetes</tag>
        <tag>运维</tag>
        <tag>Helm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes dashboard 安装及介绍]]></title>
    <url>%2F2019%2F%E8%BF%90%E7%BB%B4%2Fkubernetes-dashboard-%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[通过Dashboard，用户可以查看集群中应用的运行情况，同时也能够基于Dashboard创建或修改部署、任务、服务等Kubernetes的资源，通过部署向导，用户能够对部署进行扩缩容，进行滚动更新、重启Pod和部署新应用。 安装 dashboard UIkubectl create -f https://raw.githubusercontent.com/kubernetes/dashboard/master/aio/deploy/recommended/kubernetes-dashboard.yaml 查看是否安装成功：kubectl get svc,pod --all-namespacesNAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE...kube-system service/kubernetes-dashboard ClusterIP 10.110.187.255 &lt;none&gt; 443/TCP 86mNAMESPACE NAME READY STATUS RESTARTS AGE...kube-system pod/kubernetes-dashboard-57df4db6b-jjqhf 1/1 Running 8 86m 注:如果出现image pull错误，可以用私有仓库先查看images:cat kubernetes-dashboard.yaml | grep image image: k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1 然后将”k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1” 替换为 “mirrorgooglecontainers/kubernetes-dashboard-amd64:v1.10.1”，用docker下载下来然后上传私有仓库，具体可参考（https://mp.weixin.qq.com/s/cV74onbtzTubrrhOl_Qi8w）。 Argument name Default value Description insecure-port 9090 The port to listen to for incoming HTTP requests. port 8443 The secure port to listen to for incoming HTTPS requests. insecure-bind-address 127.0.0.1 The IP address on which to serve the –port (set to 0.0.0.0 for all interfaces). bind-address 0.0.0.0 The IP address on which to serve the –secure-port (set to 0.0.0.0 for all interfaces). default-cert-dir /certs Directory path containing ‘–tls-cert-file’ and ‘–tls-key-file’ files. Used also when auto-generating certificates flag is set. Relative to the container, not the host. tls-cert-file - File containing the default x509 Certificate for HTTPS. tls-key-file - File containing the default x509 private key matching –tls-cert-file. apiserver-host - The address of the Kubernetes Apiserver to connect to in the format of protocol://address:port, e.g., http://localhost:8080. If not specified, the assumption is that the binary runs inside a Kubernetes cluster and local discovery is attempted. api-log-level DEFAULT Set or disable API request logging.DEFAULT sanitizes potentially sensitive URLSDEBUG outputs all request output (even if sensitive)NONE disables all request logging heapster-host - The address of the Heapster to connect to in the format of protocol://address:port, e.g., http://localhost:8082. If not specified, the assumption is that the binary runs inside a Kubernetes cluster and service proxy will be used. kubeconfig - Path to kubeconfig file with authorization and master location information. token-ttl 15 minutes Expiration time (in seconds) of JWE tokens generated by dashboard. Default: 15 min. 0 - never expires. authentication-mode token Enables authentication options that will be reflected on login screen. Supported values: token, basic. Note that basic option should only be used if apiserver has ‘–authorization-mode=ABAC’ and ‘–basic-auth-file’ flags set. metric-client-check-period 30 seconds Time in seconds that defines how often configured metric client health check should be run. auto-generate-certificates false When set to true, Dashboard will automatically generate certificates used to serve HTTPS. enable-insecure-login false When enabled, Dashboard login view will also be shown when Dashboard is not served over HTTPS. Still, it requires frontend to be accessed over HTTPS (i.e. secure nginx proxy). system-banner - When non-empty displays message to Dashboard users. Accepts simple HTML tags. system-banner-severity INFO Severity of system banner. Should be one of ‘INFO,WARNING,ERROR’. disable-settings-authorizer false When enabled, Dashboard settings page will not require user to be logged in and authorized to access settings page. enable-skip-login false When enabled, the skip button on the login page will be shown. 通过kube-proxy访问kubectl proxy – 为Kubernetes API server启动代理服务器:Options: --accept-hosts='^localhost$,^127\.0\.0\.1$,^\[::1\]$': Regular expression for hosts that the proxy should accept. --accept-paths='^.*': Regular expression for paths that the proxy should accept. --address='127.0.0.1': The IP address on which to serve on. --api-prefix='/': Prefix to serve the proxied API under. --disable-filter=false: If true, disable request filtering in the proxy. This is dangerous, and can leave youvulnerable to XSRF attacks, when used with an accessible port. --keepalive=0s: keepalive specifies the keep-alive period for an active network connection. Set to 0 to disablekeepalive. -p, --port=8001: The port on which to run the proxy. Set to 0 to pick a random port. --reject-methods='^$': Regular expression for HTTP methods that the proxy should reject (example--reject-methods='POST,PUT,PATCH'). --reject-paths='^/api/.*/pods/.*/exec,^/api/.*/pods/.*/attach': Regular expression for paths that the proxy shouldreject. Paths specified here will be rejected even accepted by --accept-paths. -u, --unix-socket='': Unix socket on which to run the proxy. -w, --www='': Also serve static files from the given directory under the specified prefix. -P, --www-prefix='/static/': Prefix to serve static files under, if static file directory is specified.Usage: kubectl proxy [--port=PORT] [--www=static-dir] [--www-prefix=prefix] [--api-prefix=prefix] [options] 因为为了在不同服务器上可以访问到，因此要设置--accept-hosts和--address两个参数。 kubectl proxy --address='0.0.0.0' --port=8001 --accept-hosts='^localhost$,^192\.168\.1\.122$' 构建登陆访问权限打开地址http://192.168.1.122:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/: 可以在浏览器访问，官方提供了两种认证方式，一种是kubeconfig，一种是令牌token。 token令牌登陆k8s各服务有自己的token：kubectl get secret -n kube-systemNAME TYPE DATA AGEattachdetach-controller-token-8kh8n kubernetes.io/service-account-token 3 21hbootstrap-signer-token-htm5l kubernetes.io/service-account-token 3 21hbootstrap-token-ngcxcv bootstrap.kubernetes.io/token 7 21hcalico-node-token-4wkts kubernetes.io/service-account-token 3 20hcertificate-controller-token-dzvlt kubernetes.io/service-account-token 3 21hclusterrole-aggregation-controller-token-qpvfv kubernetes.io/service-account-token 3 21hcoredns-token-hdk66 kubernetes.io/service-account-token 3 21hcronjob-controller-token-tmvgn kubernetes.io/service-account-token 3 21hdaemon-set-controller-token-wxfbl kubernetes.io/service-account-token 3 21hdefault-token-67lzs kubernetes.io/service-account-token 3 21hdeployment-controller-token-ps2sn kubernetes.io/service-account-token 3 21hdisruption-controller-token-qhncp kubernetes.io/service-account-token 3 21hendpoint-controller-token-mq29n kubernetes.io/service-account-token 3 21hexpand-controller-token-qv82t kubernetes.io/service-account-token 3 21hgeneric-garbage-collector-token-4bklk kubernetes.io/service-account-token 3 21hhorizontal-pod-autoscaler-token-4nn7k kubernetes.io/service-account-token 3 21hjob-controller-token-hmjcx kubernetes.io/service-account-token 3 21hkube-proxy-token-phvpr kubernetes.io/service-account-token 3 21hkubernetes-dashboard-certs Opaque 0 143mkubernetes-dashboard-csrf Opaque 1 143mkubernetes-dashboard-key-holder Opaque 2 76mkubernetes-dashboard-token-tpvvp kubernetes.io/service-account-token 3 143mnamespace-controller-token-9jm46 kubernetes.io/service-account-token 3 21hnode-controller-token-lvw87 kubernetes.io/service-account-token 3 21hpersistent-volume-binder-token-sn2zf kubernetes.io/service-account-token 3 21hpod-garbage-collector-token-gmwb6 kubernetes.io/service-account-token 3 21hpv-protection-controller-token-r566m kubernetes.io/service-account-token 3 21hpvc-protection-controller-token-sh8x9 kubernetes.io/service-account-token 3 21hreplicaset-controller-token-bd724 kubernetes.io/service-account-token 3 21hreplication-controller-token-h7bt6 kubernetes.io/service-account-token 3 21hresourcequota-controller-token-qrj5l kubernetes.io/service-account-token 3 21hservice-account-controller-token-5brbw kubernetes.io/service-account-token 3 21hservice-controller-token-ln82n kubernetes.io/service-account-token 3 21hstatefulset-controller-token-b9jlj kubernetes.io/service-account-token 3 21htoken-cleaner-token-9lzqb kubernetes.io/service-account-token 3 21httl-controller-token-58rdc kubernetes.io/service-account-token 3 21h 我们通过kubectl describe secret可以看到具体服务的token：kubectl describe secret deployment-controller-token-ps2sn -n kube-systemName: deployment-controller-token-ps2snNamespace: kube-systemLabels: &lt;none&gt;Annotations: kubernetes.io/service-account.name: deployment-controller kubernetes.io/service-account.uid: e3dff2a1-2095-11e9-b54b-5254003008abType: kubernetes.io/service-account-tokenData====ca.crt: 1025 bytesnamespace: 11 bytestoken: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkZXBsb3ltZW50LWNvbnRyb2xsZXItdG9rZW4tcHMyc24iLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGVwbG95bWVudC1jb250cm9sbGVyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiZTNkZmYyYTEtMjA5NS0xMWU5LWI1NGItNTI1NDAwMzAwOGFiIiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOmRlcGxveW1lbnQtY29udHJvbGxlciJ9.d_GQotLp38_5GOMCHy2sn9zvgTThnSo4cUN5PkRbKyLtT16zl1MtFadOogLc7iVllNgDGAzHHAbo73m35gi1j0H_o0A742wZq4gLS-06r4UPfhpU9IoGhYZusYOY-RvBkjm7PZbKhudxwStdP44HhwaqdoX2wMwZgT8mrVd74VEs988zPEaM-QAKYLhYgOEAlEFvXnFfzm2dRD9LtK7m1JrlmevmtONfucEPpJiVuAhYBYq31KZ6YOya0Py8tInd8S-9_pmBmNVCYE2MzyFLWJ5uJhmdefqNWwTgKaKHWOsczqDecnRaSuF97Qje7udwVeVjNTeCwUzOZAfPlHLe-Q 但每个服务的token都权限都不同，不一定符合我们的需求，因此我们需要建立自己的ClusterRole，并赋予权限。 创建user-shikanon.yaml文件：apiVersion: v1kind: ServiceAccountmetadata: name: user-shikanon namespace: kube-system---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: user-shikanonroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects:- kind: ServiceAccount name: user-shikanon namespace: kube-system 启动服务： [root@master ~]# kubectl create -f user-shikanon.yamlserviceaccount/user-shikanon createdclusterrolebinding.rbac.authorization.k8s.io/user-shikanon created 查看user-shikanon服务的token：[root@master ~]# kubectl describe secret user-shikanon --namespace=kube-systemName: user-shikanon-token-6t5rdNamespace: kube-systemLabels: &lt;none&gt;Annotations: kubernetes.io/service-account.name: user-shikanon kubernetes.io/service-account.uid: f290b948-2149-11e9-a469-5254003008abType: kubernetes.io/service-account-tokenData====ca.crt: 1025 bytesnamespace: 11 bytestoken: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJ1c2VyLXNoaWthbm9uLXRva2VuLTZ0NXJkIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6InVzZXItc2hpa2Fub24iLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJmMjkwYjk0OC0yMTQ5LTExZTktYTQ2OS01MjU0MDAzMDA4YWIiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06dXNlci1zaGlrYW5vbiJ9.Ap6MY85X38mVGXqEe7T8UW-RHNXWWJZ06eKKXMKutRJUKDNcfKKV0Y1o_CsWLfSNjqNjRCoTYs4x73vHwo6LkrXrzKoyh7VZytcMxpwV7FiLAMU0OFia179WROAIEpvZ1AsK94X2NM3zBS4I3pVNK_OLM4wuOBLcX9bkFscBRufs3SvgtA64t8_vq4udgoQdERdnK3EiPBgpZEjnGQIK_o-kgGKviXhS892r2QD9y_YlrFyY6Gu4xPRew_k2jPpFpZNyjYp3pKWw6DnGKBN39M7T5igLnSXJEQGp1mXgYrgWBL-IQeWtRTVcpBIeRFa5AoPMfPcv5x4AsWHK_rF1_A kubeconfig登陆在.kube/config找到kubeconfig文件，或者重新创建一个kubeconfig文件，在config文件末尾加上一个token字段即可： apiVersion: v1clusters:- cluster: certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRFNU1ERXlOVEV4TXpneU1Wb1hEVEk1TURFeU1qRXhNemd5TVZvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBTERlCnVEYkNXSTVnMUhjaithdFVDdmlEK3dlM054VnVkV28rVWMvbWJFV3lyemM3WFp1RGdJZHNqNXRpV3hmMWNDVGYKeW9qU21OcC9ldmtUa2YxSGIzSmJOYjhFNG5oSE1TdzMwQkpNd1JxbTZaMVdQRnArNkRUdlZzT25CVnlDY1FRNwo0MEJWTnpyOTdXMTlkRi9JYXp4ODBqblRVT3NJNFczMXE3QkEvZ2E0anZVRnZQbnY3TVU5dm1XeCt4NWRJVmoyCjRDY1NzV0hBNVpiNm1RU050WlNtTWIxYnFZa0NHVGdPbWkrWDhDQzVaZmRtU1BmWmRUdlhOMlJVdzdmVXRZdlMKYTJuL3JwZFFzZ0s0NEthQXRHSmhta1dFci9hbkpVa1FlTEpMdjRpYVZXVnpHWEV0SkRqZkY1T0x6YVlvd2JpbApwT3hjMUIyTzk2TWV4NzljOHVVQ0F3RUFBYU1qTUNFd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFHcC92MURIUlV1ODBiSjVKQy81eHRJVEVCelYKeVZZd1d2NUpsNDRkMFhVdlJqV2FOUXF5TUYwRVJYYXBjMWdSVjV1WitROWxUN3JPcVgvWlozNHFoSS9tdmhNRgpyRUh6NW9yK09waS9HNFYwK20xYysxOE9ya3h2ZHJjcFVYa1ArVW5kM09lV0VrUjNHREhxcU5YVHlEcWZybWR2Cmh2NTNwQ0F2NkFOKzRJUWJxd3RsWU5GZWhHN09IdEl4ZDdGSFJHcGZKTTFlUXJ3M09sYzhreDVkSkltS0tPYXgKZm9uVzBkOXdOTmVhVlVDMmh4cFFWVFlJbjBXamUxcGtVTEdUaTVqcjZZL2tBZ0hhU1BKNTR5TFhzbzhMTHBvVApGMEN0TnRWOG8zczQ2Z0ZvMW1uQUQxYXh1WjlnTTNUZTcrSkNnRVlhTlgxak1SMVFwWFpraysydGYzRT0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo= server: https://192.168.1.120:6443 name: kubernetescontexts:- context: cluster: kubernetes user: kubernetes-admin name: kubernetes-admin@kubernetescurrent-context: kubernetes-admin@kuberneteskind: Configpreferences: &#123;&#125;users:- name: kubernetes-admin user: client-certificate-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUM4akNDQWRxZ0F3SUJBZ0lJVHB1b3ZjbElYdVV3RFFZSktvWklodmNOQVFFTEJRQXdGVEVUTUJFR0ExVUUKQXhNS2EzVmlaWEp1WlhSbGN6QWVGdzB4T1RBeE1qVXhNVE00TWpGYUZ3MHlNREF4TWpVeE1UTTRNakphTURReApGekFWQmdOVkJBb1REbk41YzNSbGJUcHRZWE4wWlhKek1Sa3dGd1lEVlFRREV4QnJkV0psY201bGRHVnpMV0ZrCmJXbHVNSUlCSWpBTkJna3Foa2lHOXcwQkFRRUZBQU9DQVE4QU1JSUJDZ0tDQVFFQTBPMlZMVDhENlIwVFMyRFoKb0tOZGlBcVJ3amVkWlo4Y29FdVBneTZpNlVReU9qQUt4OVZaeVJ6bWIyTWU1aFpHSXdLVGcyNW92YWw3ZWY4RApwc2FqYUhOa2NZSVd6S0Y0Yks0ZGtndlRudE5yUGxpazA5WFQxWTAwZUF0ZmpySjMrZWwzcEd1eGFPWENzZVQ3CjVLR0pINkdWWllpeGhMekF4bnpGd3lpdlFFcDVjVFl1RVhvZUZnOXBTekRhRFV5M2orUnBqRWhEdjdraVZpWGQKTE5yVGg0ZFB2ZWZhd21KTE8yYk9qUkI5MDB4dkpLMkF2NmtiV0M0U2wzQnF1SjhyVERoM21IeDQzOXVSNnpDZgpsNkYrbC9qRVBBRFJQQzVrTEJhUzVMT3JmcFlBM244MWNKYVRVeWROeGtIbDkzVTZiSnNQNXhPblBrOFpxUC9iClNhaWVrd0lEQVFBQm95Y3dKVEFPQmdOVkhROEJBZjhFQkFNQ0JhQXdFd1lEVlIwbEJBd3dDZ1lJS3dZQkJRVUgKQXdJd0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFJRVl0MjBQVDJnWm1UMmx3amYyYjIvdGc0OUJMNFJObTl4dgp1RkVmK3F1SklqcHJpMFV0TVJUZE5lV2ZiZTJvZWMrbm1SNk5CSGhUMnlhYVMrQjJ5SUZvOVVWckZENXdYVUsrCnVVN0NCRk55cHZRTzlHVXJYaGFYa1lKUkJNQ21XM2d6T1RqdXVFaGNMd0lHZGRWdlI4Wkh5M245Y084czAzU2sKUmtuMlZmL0hjQnRvbnRUWENGTXpidFA0UnZnYXlMN2c5NGpsN25OQ1hBVEU1K1h5OHZKcm5NSXhUbVQwTnVFNgpBVG43RG1Hb2V0Q2kySnJqZFpqcUR5N3FqbjhOZGQ1Qmh4OWkvWThyTXVWTC9GTWIrRVk4SzM3U2IxTmM1U21rCkNtUjNGakZZYjJUVDRZeHdtMWFPM0Rvd0lOWDVDdkd4aTNHS0F4QjJydGZQSUpLOEhydz0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo= client-key-data: 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 token: eyJhbGciOiJSUzI1NiIsIm RBAC权限控制Role 和 ClusterRole类型的权限控制Role 只能用于授予对单个命名空间中的资源访问权限，在 RBAC API 中，Role 表示一组规则权限，权限只会增加(累加权限)，不存在一个资源一开始就有很多权限而通过 RBAC 对其进行减少的操作。Role 可以定义在一个 namespace 中，如果想要跨 namespace 则可以创建 ClusterRole， ClusterRole 是集群级别的。 Role:kind: RoleapiVersion: rbac.authorization.k8s.io/v1metadata: namespace: default name: pod-readerrules:- apiGroups: [""] # "" indicates the core API group resources: ["pods"] verbs: ["get", "watch", "list"] ClusterRole:kind: ClusterRoleapiVersion: rbac.authorization.k8s.io/v1metadata: # "namespace" omitted since ClusterRoles are not namespaced name: secret-readerrules:- apiGroups: [""] resources: ["secrets"] verbs: ["get", "watch", "list"] RoleBinding 和 ClusterRoleBinding 类型的权限控制RoloBinding 可以将角色中定义的权限授予用户或用户组，RoleBinding 包含一组权限列表(subjects)，权限列表中包含有不同形式的待授予权限资源类型(users, groups, or service accounts)；RoloBinding 同样包含对被 Bind 的 Role 引用；RoleBinding 适用于某个命名空间内授权，而 ClusterRoleBinding 适用于集群范围内的授权。 RoleBinding:# This role binding allows "dave" to read secrets in the "development" namespace.kind: RoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: read-secrets namespace: development # This only grants permissions within the "development" namespace.subjects:- kind: User name: dave apiGroup: rbac.authorization.k8s.ioroleRef: kind: ClusterRole name: secret-reader apiGroup: rbac.authorization.k8s.io ClusterRoleBinding: # This cluster role binding allows anyone in the "manager" group to read secrets in any namespace.kind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: read-secrets-globalsubjects:- kind: Group name: manager apiGroup: rbac.authorization.k8s.ioroleRef: kind: ClusterRole name: secret-reader apiGroup: rbac.authorization.k8s.io]]></content>
      <categories>
        <category>技术博文</category>
        <category>容器技术</category>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>运维</tag>
        <tag>dashboard</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes部署:基于kubeadm的国内镜像源安装]]></title>
    <url>%2F2019%2F%E8%BF%90%E7%BB%B4%2Fkubernetes%E9%83%A8%E7%BD%B2-%E5%9F%BA%E4%BA%8Ekubeadm%E7%9A%84%E5%9B%BD%E5%86%85%E9%95%9C%E5%83%8F%E6%BA%90%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[基于kubeadm工具的kubernetes1.13.2部署中国区镜像部署安装实践。 1、kubernetes架构Kubernetes主要由以下几个核心组件组成： etcd保存了整个集群的状态； apiserver提供了资源操作的唯一入口，并提供认证、授权、访问控制、API注册和发现等机制； controller manager负责维护集群的状态，比如故障检测、自动扩展、滚动更新等； scheduler负责资源的调度，按照预定的调度策略将Pod调度到相应的机器上； kubelet负责维护容器的生命周期，同时也负责Volume（CVI）和网络（CNI）的管理； Container runtime负责镜像管理以及Pod和容器的真正运行（CRI）； kube-proxy负责为Service提供cluster内部的服务发现和负载均衡； 除了核心组件，还有一些推荐的Add-ons： kube-dns负责为整个集群提供DNS服务 Ingress Controller为服务提供外网入口 Heapster提供资源监控 Dashboard提供GUI Federation提供跨可用区的集群 Fluentd-elasticsearch提供集群日志采集、存储与查询 下面介绍如何安装。 2、安装kubeadm采用国内阿里云镜像源，安装kubelet、kubeadm、kubectl: cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgexclude=kube*EOF# Set SELinux in permissive mode (effectively disabling it)setenforce 0sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/configyum install -y kubelet kubeadm kubectl --disableexcludes=kubernetessystemctl enable kubelet centos7用户还需要设置路由：cat &lt;&lt;EOF &gt; /etc/sysctl.d/k8s.confnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1EOFsysctl --system Kubernetes 1.8开始要求关闭系统的Swap，如果不关闭，默认配置下kubelet将无法启动，关闭系统的Swap方法如下:swapoff -a 修改 /etc/fstab 文件，注释掉 SWAP 的自动挂载，使用free -m确认swap已经关闭。swappiness参数调整，修改/etc/sysctl.d/k8s.conf添加下面一行：vm.swappiness=0 执行sysctl -p /etc/sysctl.d/k8s.conf使修改生效。 注：kubeadm init 启动一个 Kubernetes 主节点kubeadm join 启动一个 Kubernetes 工作节点并且将其加入到集群kubeadm upgrade 更新一个 Kubernetes 集群到新版本kubeadm config 如果使用 v1.7.x 或者更低版本的 kubeadm 初始化集群，您需要对集群做一些配置以便使用 kubeadm upgrade 命令kubeadm token 管理 kubeadm join 使用的令牌kubeadm reset 还原 kubeadm init 或者 kubeadm join 对主机所做的任何更改 3、用kubeadm安装masterkubeadm init这个命令帮助你启动跟Master相关的组件APIServer、Etcd、Scheduler、Controller-Manager等 kubeadm init的参数：--apiserver-advertise-address stringAPI Server将要广播的监听地址。如指定为 `0.0.0.0` 将使用缺省的网卡地址。--apiserver-bind-port int32 缺省值: 6443API Server绑定的端口--apiserver-cert-extra-sans stringSlice可选的额外提供的证书主题别名（SANs）用于指定API Server的服务器证书。可以是IP地址也可以是DNS名称。--cert-dir string 缺省值: "/etc/kubernetes/pki"证书的存储路径。--config stringkubeadm配置文件的路径。警告：配置文件的功能是实验性的。--cri-socket string 缺省值: "/var/run/dockershim.sock"指明要连接的CRI socket文件--dry-run不会应用任何改变；只会输出将要执行的操作。--feature-gates string键值对的集合，用来控制各种功能的开关。可选项有:Auditing=true|false (当前为ALPHA状态 - 缺省值=false)CoreDNS=true|false (缺省值=true)DynamicKubeletConfig=true|false (当前为BETA状态 - 缺省值=false)-h, --help获取init命令的帮助信息--ignore-preflight-errors stringSlice忽视检查项错误列表，列表中的每一个检查项如发生错误将被展示输出为警告，而非错误。 例如: 'IsPrivilegedUser,Swap'. 如填写为 'all' 则将忽视所有的检查项错误。--kubernetes-version string 缺省值: "stable-1"为control plane选择一个特定的Kubernetes版本。--node-name string指定节点的名称。--pod-network-cidr string指明pod网络可以使用的IP地址段。 如果设置了这个参数，control plane将会为每一个节点自动分配CIDRs。--service-cidr string 缺省值: "10.96.0.0/12"为service的虚拟IP地址另外指定IP地址段--service-dns-domain string 缺省值: "cluster.local"为services另外指定域名, 例如： "myorg.internal".--skip-token-print不打印出由 `kubeadm init` 命令生成的默认令牌。--token string这个令牌用于建立主从节点间的双向受信链接。格式为 [a-z0-9]&#123;6&#125;\.[a-z0-9]&#123;16&#125; - 示例： abcdef.0123456789abcdef--token-ttl duration 缺省值: 24h0m0s令牌被自动删除前的可用时长 (示例： 1s, 2m, 3h). 如果设置为 '0', 令牌将永不过期。 在运行 kubeadm init 之前可以先执行 kubeadm config images pull 来测试与 gcr.io 的连接，kubeadm config images pull尝试是否可以拉取镜像，由于国内访问”k8s.gcr.io”, “gcr.io”, “quay.io” 有困难，这里采用自建docker register的方式 通过私有仓库拉取k8s.gcr.io等镜像构建私有镜像：docker pull registrydocker run --restart=always -d -p 15000:5000 -v /mnt/date/registry:/var/lib/registry registry 可以使用使用准备好的harbor仓库 百度云盘-harbor私有仓库k8s.gcr.io/coredns:1.2.6k8s.gcr.io/etcd:3.2.24k8s.gcr.io/kube-apiserver:v1.13.0k8s.gcr.io/kube-controller-manager:v1.13.0k8s.gcr.io/kube-proxy:v1.13.0k8s.gcr.io/kube-scheduler:v1.13.0k8s.gcr.io/pause:3.1k8s.gcr.io/addon-resizer:1.8.4k8s.gcr.io/metrics-server-amd64:v0.3.1k8s.gcr.io/traefik:1.7.5k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.0gcr.io/kubernetes-helm/tiller:v2.12.0quay.io/calico/cni:v3.3.2quay.io/calico/node:v3.3.2quay.io/calico/typha:v3.3.2 下载下来后导入即可：docker load -i /path/to/k8s-repo-1.13.0docker run --restart=always -d -p 80:5000 --name repo harbor.io:1180/system/k8s-repo:v1.13.0 构建私有仓库并上传镜像的方法（安装不需要看这部）从docker上拉取镜像： docker pull mirrorgooglecontainers/kube-apiserver:v1.13.2docker pull mirrorgooglecontainers/kube-proxy:v1.13.2docker pull mirrorgooglecontainers/kube-controller-manager:v1.13.2docker pull mirrorgooglecontainers/kube-scheduler:v1.13.2docker pull mirrorgooglecontainers/coredns:1.2.6docker pull mirrorgooglecontainers/etcd:3.2.24docker pull mirrorgooglecontainers/pause:3.1docker pull mirrorgooglecontainers/kubernetes-dashboard-amd64:v1.10.0docker pull shikanon096/traefik:1.7.5docker pull shikanon096/gcr.io.kubernetes-helm.tiller:v2.12.0docker pull mirrorgooglecontainers/addon-resizer:1.8.4docker pull mirrorgooglecontainers/metrics-server-amd64:v0.3.1docker pull quay.io/calico/cni:v3.3.2docker pull quay.io/calico/node:v3.3.2docker pull quay.io/calico/typha:v3.3.2... 切换tag 切换tag,方便后面直接push本地仓库:docker tag mirrorgooglecontainerso/kube-controller-manager:v1.13.2 192.168.1.118:80/kube-controller-manager:v1.13.2docker tag mirrorgooglecontainers/kube-proxy:v1.13.2 192.168.1.118:80/kube-proxy:v1.13.2docker tag mirrorgooglecontainers/kube-scheduler:v1.13.2 192.168.1.118:80/kube-scheduler:v1.13.2docker tag mirrorgooglecontainers/kube-apiserver:v1.13.2 192.168.1.118:80/kube-apiserver:v1.13.2... 由于是registry用的是http，需要设置docker的daemon 在/etc/docker/daemon.json中加入：&#123; ... "insecure-registries": ["192.168.1.118:80"]&#125; push 到仓库push 到私有仓库： docker push 192.168.1.118:80/kube-scheduler:v1.13.2docker push 192.168.1.118:80/kube-apiserver:v1.13.2docker push 192.168.1.118:80/kube-proxy:v1.13.2docker push 192.168.1.118:80/kube-controller-manager:v1.13.2... 配置仓库地址master配置新的仓库地址：# 将源设置为insercuremkdir -p /etc/dockerecho -e '&#123;\n"insecure-registries":["k8s.gcr.io", "gcr.io", "quay.io"]\n&#125;' &gt; /etc/docker/daemon.jsonsystemctl restart docker # 此处为registry所在机器的IPREGISTRY_HOST="192.168.1.118"# 设置Hosts，让所有上面域名转到本地yes | cp /etc/hosts /etc/hosts_bakcat /etc/hosts_bak|grep -vE '(gcr.io|harbor.io|quay.io)' &gt; /etc/hostsecho """$REGISTRY_HOST gcr.io harbor.io k8s.gcr.io quay.io """ &gt;&gt; /etc/hosts 测试：kubeadm config images pullI0125 01:41:57.398374 5002 version.go:94] could not fetch a Kubernetes version from the internet: unable to get URL "https://dl.k8s.io/release/stable-1.txt": Get https://storage.googleapis.com/kubernetes-release/release/stable-1.txt: net/http: request canceled (Client.Timeout exceeded while awaiting headers)I0125 01:41:57.398536 5002 version.go:95] falling back to the local client version: v1.13.2[config/images] Pulled k8s.gcr.io/kube-apiserver:v1.13.2[config/images] Pulled k8s.gcr.io/kube-controller-manager:v1.13.2[config/images] Pulled k8s.gcr.io/kube-scheduler:v1.13.2[config/images] Pulled k8s.gcr.io/kube-proxy:v1.13.2[config/images] Pulled k8s.gcr.io/pause:3.1[config/images] Pulled k8s.gcr.io/etcd:3.2.24[config/images] Pulled k8s.gcr.io/coredns:1.2.6 成功后可以直接使用kubeadm init：kubeadm init \ --kubernetes-version=v1.13.2 \ --pod-network-cidr=10.244.0.0/16 注：如果中途出错可以用kubeadm reset来进行回退 在使用kubeadm的时候出现kubelet node found bug：E1002 23:32:36.072441 49157 kubelet.go:2236] node "master01" not foundE1002 23:32:36.172630 49157 kubelet.go:2236] node "master01" not foundE1002 23:32:36.273892 49157 kubelet.go:2236] node "master01" not found 这主要由于--api-server引起，可以去掉这个参数试试。 kebeadm init 成功后结果kubeadm init --kubernetes-version=v1.13.2 --pod-network-cidr=10.244.0.0/16[init] Using Kubernetes version: v1.13.2[preflight] Running pre-flight checks[preflight] Pulling images required for setting up a Kubernetes cluster[preflight] This might take a minute or two, depending on the speed of your internet connection[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"[kubelet-start] Activating the kubelet service[certs] Using certificateDir folder "/etc/kubernetes/pki"[certs] Generating "ca" certificate and key[certs] Generating "apiserver" certificate and key[certs] apiserver serving cert is signed for DNS names [node10 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.1.120][certs] Generating "apiserver-kubelet-client" certificate and key[certs] Generating "front-proxy-ca" certificate and key[certs] Generating "front-proxy-client" certificate and key[certs] Generating "etcd/ca" certificate and key[certs] Generating "etcd/server" certificate and key[certs] etcd/server serving cert is signed for DNS names [node10 localhost] and IPs [192.168.1.120 127.0.0.1 ::1][certs] Generating "etcd/healthcheck-client" certificate and key[certs] Generating "etcd/peer" certificate and key[certs] etcd/peer serving cert is signed for DNS names [node10 localhost] and IPs [192.168.1.120 127.0.0.1 ::1][certs] Generating "apiserver-etcd-client" certificate and key[certs] Generating "sa" key and public key[kubeconfig] Using kubeconfig folder "/etc/kubernetes"[kubeconfig] Writing "admin.conf" kubeconfig file[kubeconfig] Writing "kubelet.conf" kubeconfig file[kubeconfig] Writing "controller-manager.conf" kubeconfig file[kubeconfig] Writing "scheduler.conf" kubeconfig file[control-plane] Using manifest folder "/etc/kubernetes/manifests"[control-plane] Creating static Pod manifest for "kube-apiserver"[control-plane] Creating static Pod manifest for "kube-controller-manager"[control-plane] Creating static Pod manifest for "kube-scheduler"[etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests"[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory "/etc/kubernetes/manifests". This can take up to 4m0s[kubelet-check] Initial timeout of 40s passed.[apiclient] All control plane components are healthy after 59.004591 seconds[uploadconfig] storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace[kubelet] Creating a ConfigMap "kubelet-config-1.13" in namespace kube-system with the configuration for the kubelets in the cluster[patchnode] Uploading the CRI Socket information "/var/run/dockershim.sock" to the Node API object "node10" as an annotation[mark-control-plane] Marking the node node10 as control-plane by adding the label "node-role.kubernetes.io/master=''"[mark-control-plane] Marking the node node10 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule][bootstrap-token] Using token: ngcxcv.5b60k99xhckulox4[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles[bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials[bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token[bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster[bootstraptoken] creating the "cluster-info" ConfigMap in the "kube-public" namespace[addons] Applied essential addon: CoreDNS[addons] Applied essential addon: kube-proxyYour Kubernetes master has initialized successfully!To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/configYou should now deploy a pod network to the cluster.Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/You can now join any number of machines by running the following on each nodeas root: kubeadm join 192.168.1.120:6443 --token ngcxcv.5b60k99xhckulox4 --discovery-token-ca-cert-hash sha256:630385738470e6ad0fa065a92eb6519d9a05e593b3896fccadef4f39e025f273 设置普通账户权限：mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config root 用户，则可以运行:export KUBECONFIG=/etc/kubernetes/admin.conf 4、用kubeadm部署node，把其加入master用上面kubeadm init 安装完成后给的命令即可： kubeadm join 192.168.1.120:6443 --token xmjnn0.39xbep2zpyh0rjam --discovery-token-ca-cert-hash sha256:9c2dc63bab2a1392e797bca8104eac3ce115589af0486259a06d3277eb21b4cb 为了能使用kubectl,可以从master拷贝过来：scp root@&lt;master ip&gt;:/etc/kubernetes/admin.conf .kubectl --kubeconfig ./admin.conf get nodes 测试：kubectl get nodesNAME STATUS ROLES AGE VERSIONmaster NotReady &lt;none&gt; 2m3s v1.13.2node10 NotReady master 6m7s v1.13.2 5、安装网络插件安装网络插件需要注意保证docker register私有仓库中已经有该镜像，或者网络可以访问quay.io等国外网站。 Flannelkubectl apply -f https://raw.githubusercontent.com/coreos/flannel/bc79dd1505b0c8681ece4de4c0d86c5cd2643275/Documentation/kube-flannel.yml Calicokubectl apply -f https://docs.projectcalico.org/v3.3/getting-started/kubernetes/installation/hosted/rbac-kdd.yamlkubectl apply -f https://docs.projectcalico.org/v3.3/getting-started/kubernetes/installation/hosted/kubernetes-datastore/calico-networking/1.7/calico.yaml 注：应用层网络（覆盖网络）是指建立在另一个网络上的网络。该网络中的结点可以看作通过虚拟或逻辑链路而连接起来的。虽然在底层有很多条物理链路，但是这些虚拟或逻辑链路都与路径一一对应。Flannel实质上是一种“覆盖网络(overlay network)”，也就是将TCP数据包装在另一种网络包里面进行路由转发和通信 Minikube简易安装也可以基于minikube进行简易安装：下载minikube:curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 \ &amp;&amp; chmod +x minikube 安装：minikube start --driver=&lt;driver_name&gt; driver可以是kvm或者docker，比如：基于kvm启动：minikube start --vm-driver=kvm 基于docker启动：minikube start --vm-driver=docker 查看minikube是否启动：minikube status 停掉集群：minikube stop]]></content>
      <categories>
        <category>技术博文</category>
        <category>容器技术</category>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>运维</tag>
        <tag>kubeadm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes 设置CA双向数字证书认证]]></title>
    <url>%2F2019%2F%E8%BF%90%E7%BB%B4%2Fkubernetes-%E8%AE%BE%E7%BD%AECA%E5%8F%8C%E5%90%91%E6%95%B0%E5%AD%97%E8%AF%81%E4%B9%A6%E8%AE%A4%E8%AF%81%2F</url>
    <content type="text"><![CDATA[Kubernetes 认证方式Kubernetes 系统提供了三种认证方式：CA 认证、Token 认证 和 Base 认证。 CA 双向认证方式是最为严格和安全的集群安全配置方式，也是我们今天要介绍的主角。 我们先来了解下什么是 CA 认证：CA认证，即电子认证服务，证书颁发机构（CA, Certificate Authority）即颁发数字证书的机构。是负责发放和管理数字证书的权威机构，并作为电子商务交易中受信任的第三方，承担公钥体系中公钥的合法性检验的责任。CA中心为每个使用公开密钥的用户发放一个数字证书，数字证书的作用是证明证书中列出的用户合法拥有证书中列出的公开密钥。CA机构的数字签名使得攻击者不能伪造和篡改证书。在SET交易中，CA不仅对持卡人、商户发放证书，还要对获款的银行、网关发放证书。 主要配置流程如下： 生成根证书、API Server 服务端证书、服务端私钥、各个组件所用的客户端证书和客户端私钥。 修改 Kubernetes 各个服务进程的启动参数，启用双向认证模式。 opensshopessl中RSA算法指令主要有三个: 指令 功能 genrsa 生成并输入一个RSA私钥 rsa 处理RSA密钥的格式转换等问题 rsautl 使用RSA密钥进行加密、解密、签名和验证等运算 genrsa [args] [numbits] //密钥位数，建议1024及以上 -des encrypt the generated key with DES in cbc mode //生成的密钥使用des方式进行加密 -des3 encrypt the generated key with DES in ede cbc mode (168 bit key) //生成的密钥使用des3方式进行加密 -seed encrypt PEM output with cbc seed //生成的密钥还是要seed方式进行 -aes128, -aes192, -aes256 encrypt PEM output with cbc aes //生成的密钥使用aes方式进行加密 -camellia128, -camellia192, –camellia256 encrypt PEM output with cbc camellia //生成的密钥使用camellia方式进行加密 -out file output the key to 'file //生成的密钥文件，可从中提取公钥 -passout arg output file pass phrase source //指定密钥文件的加密口令，可从文件、环境变量、终端等输入 -f4 use F4 (0x10001) for the E value //选择指数e的值，默认指定该项，e值为65537 -3 use 3 for the E value //选择指数e的值，默认值为65537，使用该选项则指数指定为3 -engine e use engine e, possibly a hardware device. //指定三方加密库或者硬件 -rand file:file:... load the file (or the files in the directory) into //产生随机数的种子文件 the random number generator req 命令：使用已有私钥生成证书请求openssl req [-inform PEM|DER] [-outform PEM|DER] [-in filename] [-passin arg] [-out filename] [-passout arg] [-text] [-pubkey] [-noout] [-verify] [-modulus] [-new] [-rand file(s)] [-newkey rsa:bits][-newkey alg:file] [-nodes] [-key filename] [-keyform PEM|DER] [-keyout filename] [-keygen_engine id] [-[digest]] [-config filename] [-subj arg] [-multivalue-rdn] [-x509] [-days n] [-set_serial n][-asn1-kludge] [-no-asn1-kludge] [-newhdr] [-extensions section] [-reqexts section] [-utf8] [-nameopt] [-reqopt] [-subject] [-subj arg] [-batch] [-verbose] [-engine id] -new :说明生成证书请求文件 -x509 :说明生成自签名证书 -key :指定已有的秘钥文件生成秘钥请求，只与生成证书请求选项-new配合。 -newkey :-newkey是与-key互斥的，-newkey是指在生成证书请求或者自签名证书的时候自动生成密钥， 然后生成的密钥名称由-keyout参数指定。当指定newkey选项时，后面指定rsa:bits说明产生 rsa密钥，位数由bits指定。 如果没有指定选项-key和-newkey，默认自动生成秘钥。 -out :-out 指定生成的证书请求或者自签名证书名称 -config :默认参数在ubuntu上为 /etc/ssl/openssl.cnf, 可以使用-config指定特殊路径的配置文件 -nodes :如果指定-newkey自动生成秘钥，那么-nodes选项说明生成的秘钥不需要加密，即不需要输入passphase. -batch :指定非交互模式，直接读取config文件配置参数，或者使用默认参数值 下文中相关名词简写CSR - Certificate Signing Request,即证书签名请求,这个并不是证书,而是向权威证书颁发机构获得签名证书的申请,其核心内容是一个公钥(当然还附带了一些别的信息),在生成这个申请的时候,同时也会生成一个私钥,私钥要自己保管好 CRT - CRT应该是certificate的三个字母,其实还是证书的意思。 双向签名数字证书认证创建CA证书和私钥相关文件(1) 生成客户端的密钥，即客户端的公私钥对//生成私钥文件# openssl genrsa -out ca.key 2048Generating RSA private key, 2048 bit long modulus.......................+++................................................+++e is 65537 (0x10001) (2) 生成自签名证书：用自己的私钥为证书请求文件签名，生成证书文件openssl req -x509 -new -nodes -key ca.key -subj "/CN=master" -days 7000 -out ca.crt (3) kube-apiservice的私钥:openssl genrsa -out server.key 2048 (4) 通过配置文件生成签名请求证书：创建一个master-ssl.cnf配置文件，用来生成书证签名请求文件和证书文件：[req]req_extensions = v3_reqdistinguished_name = req_distinguished_name[req_distinguished_name][v3_req]basicConstraints = CA:FALSEkeyUsage = nonRepudiation, digitalSignature, keyEnciphermentsubjectAltName = @alt_name[alt_name]DNS.1 = kubernetesDNS.2 = kubernetes.defaultDNS.3 = kubernetes.default.svcDNS.4 = kubernetes.default.svc.cluster.local# master hostnameDNS.5 = master# master IPIP.1 = 192.168.1.122# kubernetes.default's ClusterIPIP.2 = 10.254.0.1 查看kubernetes.default的cluster IP:# kubectl get svc kubernetes -o yamlapiVersion: v1kind: Servicemetadata: creationTimestamp: 2019-01-10T08:31:18Z labels: component: apiserver provider: kubernetes name: kubernetes namespace: default resourceVersion: "18" selfLink: /api/v1/namespaces/default/services/kubernetes uid: 1a258e01-14b2-11e9-86b7-525400bea75cspec: clusterIP: 10.254.0.1 ports: - name: https port: 443 protocol: TCP targetPort: 6443 sessionAffinity: ClientIP type: ClusterIPstatus: loadBalancer: &#123;&#125; 基于mstaer_ssl.cnf创建server.csr和server.crt文件. 创建证书签名请求文件：openssl req -new -key server.key -subj "/CN=master" -config master_ssl.cnf -out server.csr 创建证书文件：openssl x509 -req -in server.csr -CA ca.crt -CAkey ca.key -CAcreateserial -days 7000 -extensions v3_req -extfile master_ssl.cnf -out server.crt 下面生成server.crt 和ca.srl (5) 设置kube-apiserver启动参数KUBE_API_ARGS="--client-ca-file=/var/run/kubernetes/ca.crt --tls-private-key-file=/var/run/kubernetes/server.key --tls-cert-file=/var/run/kubernetes/server.crt --secure-port=6443" --client-ca-file表示CA根证书文件、--tls-private-key-file服务端证书文件、--tls-cert-file服务端私钥文件; 重启kube-apiserver服务：systemctl restart kube-apiserver 设置 kube-controller-manager 的客户端(1) 生成证书签名请求文件和证书文件私钥文件：openssl genrsa -out cs_client.key 2048 证书签名请求（Certificate Signing Request）文件：openssl req -new -key cs_client.key -subj "/CN=master" -out cs_client.csr 证书文件：openssl x509 -req -in cs_client.csr -CA ca.crt -CAkey ca.key -CAcreateserial -days 7000 -out cs_client.crt (2) 创建kubeconfigapiVersion: v1kind: Configusers:- name: controllermanager user: client-certificate: /var/run/kubernetes/cs_client.crt client-key: /var/run/kubernetes/cs_client.keyclusters:- name: local cluster: certificate-authority: /var/run/kubernetes/ca.crtcontexts:- context: cluster: local user: controllermanager name: my-contextcurrent-context: my-context (3) 配置参数，重新启动kube-controller-manager/etc/kubernetes/controller-manager# Add your own!KUBE_CONTROLLER_MANAGER_ARGS="--master=https://192.168.1.122:6443 --service-account-key-file=/var/run/kubernetes/server.key --root-ca-file=/var/run/kubernetes/ca.crt --kubeconfig=/etc/kubernetes/kubeconfig" 重启服务systemctl restart kube-controller-manager kube-scheduler配置重启# Add your own!KUBE_SCHEDULER_ARGS="--address=0.0.0.0 --master=https://192.168.1.122:6443 --kubeconfig=/etc/kubernetes/kubeconfig" 重启服务：systemctl restart kube-scheduler Node节点设置从master复制ca.crt和ca.key到Node节点上，按照前面的方式生成证书签名请求和证书文件。 kubelet客户端私钥：openssl genrsa -out kubelet_client.key 2048 证书签名请求文件：openssl req -new -key kubelet_client.key -subj "/CN=node2" -out kubelet_client.csr 证书文件：openssl x509 -req -in kubelet_client.csr -CA ca.crt -CAkey ca.key -CAcreateserial -days 7000 -out kubelet_client.crt 设置kubelet启动：KUBELET_ARGS="--certificate-authority=/var/run/kubernetes/ssl_keys/ca.crt --client-certificate=/var/run/kubernetes/ssl_keys/cs_client.crt --client-key=/var/run/kubernetes/ssl_keys/cs_client.key" # Add your own!KUBELET_ARGS="--kubeconfig=/etc/kubernetes/keubeconfig" 重启:systemctl restart kubelet kube-proxyKUBE_PROXY_ARGS="--bind-address=0.0.0.0 --master=https://192.168.1.122:6443 --kubeconfig=/etc/kubernetes/kubeconfig" 重启：systemctl restart kube-proxy 在设置完成之后master注意开启6443端口：#添加端口firewall-cmd --zone=public --add-port=6443/tcp --permanent#重新载入firewall-cmd --reload 测试是否成功：# kubectl --server=https://192.168.1.122:6443 --certificate-authority=/var/run/kubernetes/ssl_keys/ca.crt --client-certificate=/var/run/kubernetes/ssl_keys/cs_client.crt --client-key=/var/run/kubernetes/ssl_keys/cs_client.key get nodesNAME STATUS AGEnode1 Ready 5dnode2 Ready 5d]]></content>
      <categories>
        <category>技术博文</category>
        <category>容器技术</category>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>运维</tag>
        <tag>证书认证</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim指令]]></title>
    <url>%2F2019%2F%E8%BF%90%E7%BB%B4%2Fvim%E6%8C%87%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[vim 是一个基于【动词】 + 【名词】 建立的语法表。 Vim 中常用的名词方位名词表 基于字符的移动：h：左j：下k：上l：右 ^ | k 提示： h 的键位于左边，每次按下就会向左移动。 &lt;- h l -&gt; l 的键位于右边，每次按下就会向右移动。 j | j 键看起来很象一支尖端方向朝下的箭头。 v 基于单词(a-zA-Z0-9_)的移动：w 移到下一个英文类单词的开头e 移到下一个英文类单词的末尾b 移到前一个英文类单词的开头ge 移到前一个英文类单词的末尾 这里的英文类单词是基于a-zA-Z0-9_这类英文的单词，如果我们希望基于其他语言带空格分割我们可以用大写代替：W 移到下一个单词的开头E 移到下一个单词的末尾B 移到前一个单词的开头gE 移到前一个单词的末尾 基于行(sentence)的移动：0 移动到当前行的第一个字符；^ 移动到当前行中的第一个非空字符；g_ 移动到当前行的最后一个非空白字符；$ 移动到当前行的最后一个字符；n| 移动到当前行的第 n 列。G 移动光标到文档尾行 Vim 中常见的动词（操作符）y 复制文本d 删除文本，并保存到寄存器c 删除文本，保存到寄存器，并开启「插入」模式 操作符可以和名词进行组合，即操作符+名词，比如:y$ 把当前位置到当前行最后一个字符进行复制dw 从当前位置删除到下一个单词的开头y2h 向左复制两个字符 特殊的，操作符也可以通过两次来执行行操作，比如：yy表示复制当前整行内容。 文本对象Vim有一种用文本对象捕获这种结构的方法。文本对象与运算符一起使用。有两种类型的文本对象：i + 文本对象 文本对象内部a + 文本对象 包含外部的文本对象 文本对象列表：w 一个单词p 一个段落s 一个句子( or ) 一对小括号 ( )&#123; or &#125; 一对大括号 &#123; &#125;[ or ] 一对中括号 [ ]&lt; or &gt; 一对尖括号 &lt; &gt;t XML标签" 一对双引号 " "' 一对单号 ' '` 一对 ` ` i(表示 () 内部的文本，di( 表示删除 () 内部的内容；da(则表示连同括号和里面的内容一起删除。dit表示删除一个XML标签，例如：&lt;div&gt; &lt;h1&gt;Header1&lt;/h1&gt; &lt;p&gt;Paragraph1&lt;/p&gt;&lt;/div&gt; 光标在Header1的位置，使用dit会把Header1删除，dat会把 &lt;h1&gt;Header1&lt;/h1&gt; 删除。 组合性语法在 Vim 中可以组合较简单的命令执行复杂的命令。当 Vim 与外部程序集成时，可组合性的真正威力就显露出来了。 假如你有一个非常混乱的文本，如下所示，你想把它变成列表形式： Id|Name|Cuteness01|Puppy|Very02|Kitten|Ok03|Bunny|Ok 可以用终端 column 命令组合 Vim 命令完成，运行!}column -t -s &quot;|&quot;，即可得到：Id Name Cuteness01 Puppy Very02 Kitten Ok03 Bunny Ok 上述的操作过程可分解成这样：动词为!(过滤操作符)，名词为}(转到下一段)。过滤器操作符!接受另一个参数，一个终端命令column -t -s &quot;|&quot;。 快捷设置文件中移动为了方便使用相对行可以设置：:set relativenumber number 同时开启相对行和真实行，这样就知道自己在哪个相对的行了，例如：2j向下移动两行]]></content>
      <categories>
        <category>技术博文</category>
        <category>命令工具</category>
      </categories>
      <tags>
        <tag>入门教程</tag>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go mod 在使用私有gitlab做nginx转发时“go-get=1”错误解决]]></title>
    <url>%2F2019%2F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%2Fgo-mod-%E5%9C%A8%E4%BD%BF%E7%94%A8%E7%A7%81%E6%9C%89gitlab%E6%97%B6goget%E9%94%99%E8%AF%AF%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[nginx配置文件中加入：if ($condition = gogetpath) &#123; return 200 "&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta content='gitlab.data-spark.cn/$1/$2 git http://gitlab.data-spark.cn/$1/$2.git' name='go-import'&gt;&lt;/head&gt;&lt;/html&gt;";&#125; 具体： server&#123; listen 80; listen 443 ssl; server_name gitlab.data-spark.cn; if ($args ~* "^go-get=1") &#123; set $condition goget; &#125; if ($uri ~ ^/([a-zA-Z0-9_-]+)/([a-zA-Z0-9_-]+)/.*$) &#123; set $condition "$&#123;condition&#125;path"; &#125; if ($condition = gogetpath) &#123; return 200 "&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta content='gitlab.data-spark.cn/$1/$2 git http://gitlab.data-spark.cn/$1/$2.git' name='go-import'&gt;&lt;/head&gt;&lt;/html&gt;"; &#125; ssl on; ssl_certificate /etc/nginx/conf.d/ssl/gitlab.data-spark.cn_bundle.crt; ssl_certificate_key /etc/nginx/conf.d/ssl/gitlab.data-spark.cn.key; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; ssl_ciphers EECDH+CHACHA20:EECDH+AES128:RSA+AES128:EECDH+AES256:RSA+AES256:EECDH+3DES:RSA+3DES:!MD5; # avoid ssl stripping add_header Strict-Transport-Security "max-age=31536000; includeSubdomains;"; location / &#123; proxy_pass http://localhost:18080/; &#125; error_page 497 https://$host$uri?$args;&#125; 加入了if ($args ~* "^go-get=1") &#123; set $condition goget;&#125;if ($uri ~ ^/([a-zA-Z0-9_-]+)/([a-zA-Z0-9_-]+)/.*$) &#123; set $condition "$&#123;condition&#125;path"; &#125;if ($condition = gogetpath) &#123; return 200 "&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta content='your.domain.com/$1/$2 git http://your.domain.com/$1/$2.git' name='go-import'&gt;&lt;/head&gt;&lt;/html&gt;";&#125; go mod 其他问题问题一：依赖的包下载到哪里了？使用Go的包管理方式，依赖的第三方包被下载到了$GOPATH/pkg/mod路径下。如果你成功运行了本例，可以在您的$GOPATH/pkg/mod 下找到一个这样的包 github.com/astaxie/beego@v1.11.1 问题二： 依赖包的版本是怎么控制的？在上一个问题里，可以看到最终下载在$GOPATH/pkg/mod 下的包 github.com/astaxie/beego@v1.11.1 最后会有一个版本号 1.11.1，也就是说，$GOPATH/pkg/mod里可以保存相同包的不同版本。版本是在go.mod中指定的。如果，在go.mod中没有指定，go命令会自动下载代码中的依赖的最新版本，本例就是自动下载最新的版本。如果，在go.mod用require语句指定包和版本 ，go命令会根据指定的路径和版本下载包，指定版本时可以用latest，这样它会自动下载指定包的最新版本 问题三： 可以把项目放在$GOPATH/src下吗？可以。但是go会根据GO111MODULE的值而采取不同的处理方式默认情况下，GO111MODULE=auto 自动模式auto 自动模式下，项目在$GOPATH/src里会使用$GOPATH/src的依赖包，在$GOPATH/src外，就使用go.mod 里 require的包on 开启模式，1.12后，无论在$GOPATH/src里还是在外面，都会使用go.mod 里 require的包off 关闭模式，就是老规矩。 问题三： 依赖包中的地址失效了怎么办？比如 http://golang.org/x/… 下的包都无法下载怎么办？在go快速发展的过程中，有一些依赖包地址变更了。以前的做法修改源码，用新路径替换import的地址git clone 或 go get 新包后，copy到$GOPATH/src里旧的路径下无论什么方法，都不便于维护，特别是多人协同开发时。使用go.mod就简单了，在go.mod文件里用 replace 替换包，例如replace golang.org/x/text =&gt; github.com/golang/text latest这样，go会用 http://github.com/golang/text 替代http://golang.org/x/text，原理就是下载http://github.com/golang/text 的最新版本到 $GOPATH/pkg/mod/golang.org/x/text下。 问题四： init生成的go.mod的模块名称有什么用？本例里，用 go mod init hello 生成的go.mod文件里的第一行会申明module hello因为我们的项目已经不在$GOPATH/src里了，那么引用自己怎么办？就用模块名+路径。例如，在项目下新建目录 utils，创建一个tools.go文件:package utilsimport “fmt”func PrintText(text string) &#123; fmt.Println(text)&#125; 在根目录下的hello.go文件就可以 import “hello/utils” 引用utilspackage mainimport ("hello/utils""github.com/astaxie/beego")func main() &#123; utils.PrintText("Hi") beego.Run()&#125; 问题五：以前老项目如何用新的包管理如果用auto模式,把项目移动到$GOPATH/src外进入目录，运行 go mod init + 模块名称,go build 或者 go run 一次]]></content>
      <categories>
        <category>技术博文</category>
        <category>系统运维</category>
      </categories>
      <tags>
        <tag>Golang</tag>
        <tag>gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Golang徒手写个转发代理服务]]></title>
    <url>%2F2019%2F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%2F%E5%9F%BA%E4%BA%8Ego%E5%BE%92%E6%89%8B%E5%86%99%E4%B8%AA%E8%BD%AC%E5%8F%91%E4%BB%A3%E7%90%86%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[由于公司经常需要异地办公，在调试的时候需要用到内网环境，因此手动写了个代理转发服务器給兄弟们用，项目地址是：socks5proxy。 选型上，语言上就选择了Go，简单清晰，转发协议选择了socks5。 SOCKS5协议介绍SOCKS是一种网络传输协议，主要用于客户端与外网服务器之间通讯的中间传递，SOCKS是”SOCKetS”的缩写。SOCKS5是SOCKS4的升级版，其主要多了鉴定、IPv6、UDP支持。 SOCKS5协议可以分为三个部分： (1) 协议版本及认证方式 (2) 根据认证方式执行对应的认证 (3) 请求信息 （1）协议版本及认证方式创建与SOCKS5服务器的TCP连接后客户端需要先发送请求来协议版本及认证方式， VER NMETHODS METHODS 1 1 1-255 VER是SOCKS版本，这里应该是0x05； NMETHODS是METHODS部分的长度； METHODS是客户端支持的认证方式列表，每个方法占1字节。当前的定义是： 0x00 不需要认证 0x01 GSSAPI 0x02 用户名、密码认证 0x03 - 0x7F由IANA分配（保留） 0x80 - 0xFE为私人方法保留 0xFF 无可接受的方法 服务器回复客户端可用方法： VER METHOD 1 1 VER是SOCKS版本，这里应该是0x05； METHOD是服务端选中的方法。如果返回0xFF表示没有一个认证方法被选中，客户端需要关闭连接。 代码实现： type ProtocolVersion struct &#123; VER uint8 NMETHODS uint8 METHODS []uint8&#125;func (s *ProtocolVersion) handshake(conn net.Conn) error &#123; b := make([]byte, 255) n, err := conn.Read(b) if err != nil &#123; log.Println(err) return err &#125; s.VER = b[0] //ReadByte reads and returns a single byte，第一个参数为socks的版本号 s.NMETHODS = b[1] //nmethods是记录methods的长度的。nmethods的长度是1个字节 if n != int(2+s.NMETHODS) &#123; return errors.New("协议错误, sNMETHODS不对") &#125; s.METHODS = b[2:2+s.NMETHODS] //读取指定长度信息，读取正好len(buf)长度的字节。如果字节数不是指定长度，则返回错误信息和正确的字节数 if s.VER != 5 &#123; return errors.New("该协议不是socks5协议") &#125; //服务器回应客户端消息: //第一个参数表示版本号为5，即socks5协议， // 第二个参数表示服务端选中的认证方法，0即无需密码访问, 2表示需要用户名和密码进行验证。 resp :=[]byte&#123;5, 0&#125; conn.Write(resp) return nil&#125; （2）根据认证方式执行对应的认证SOCKS5协议提供5种认证方式： 0x00 不需要认证 0x01 GSSAPI 0x02 用户名、密码认证 0x03 - 0x7F由IANA分配（保留） 0x80 - 0xFE为私人方法保留 这里就主要介绍用户名、密码认证。在客户端、服务端协商使用用户名密码认证后，客户端发出用户名密码： 鉴定协议版本 用户名长度 用户名 密码长度 密码 1 1 动态 1 动态 服务器鉴定后发出如下回应： 鉴定协议版本 鉴定状态 1 1 其中鉴定状态 0x00 表示成功，0x01 表示失败。 代码实现：type Socks5Auth struct &#123; VER uint8 ULEN uint8 UNAME string PLEN uint8 PASSWD string&#125;func (s *Socks5Auth) authenticate(conn net.Conn) error &#123; b := make([]byte, 128) n, err := conn.Read(b) if err != nil&#123; log.Println(err) return err &#125; s.VER = b[0] if s.VER != 5 &#123; return errors.New("该协议不是socks5协议") &#125; s.ULEN = b[1] s.UNAME = string(b[2:2+s.ULEN]) s.PLEN = b[2+s.ULEN+1] s.PASSWD = string(b[n-int(s.PLEN):n]) log.Println(s.UNAME, s.PASSWD) if username != s.UNAME || passwd != s.PASSWD &#123; return errors.New("账号密码错误") &#125; /** 回应客户端,响应客户端连接成功 The server verifies the supplied UNAME and PASSWD, and sends the following response: +----+--------+ |VER | STATUS | +----+--------+ | 1 | 1 | +----+--------+ A STATUS field of X'00' indicates success. If the server returns a `failure' (STATUS value other than X'00') status, it MUST close the connection. */ resp := []byte&#123;0x05, 0x00&#125; conn.Write(resp) return nil&#125; 但其实，现在大家都习惯自己采用加密流的方式进行加密，很少采用用户名密码的形式进行加密，后面章节会介绍一种对SOCKS的混淆加密方式。 （3）请求信息认证结束后客户端就可以发送请求信息。如果认证方法有特殊封装要求，请求必须按照方法所定义的方式进行封装解密，其原始格式如下： VER CMD RSV ATYP DST.ADDR DST.PORT 1 1 0x00 1 动态 2 VER是SOCKS版本，这里应该是0x05； CMD是SOCK的命令码 0x01表示CONNECT请求 0x02表示BIND请求 0x03表示UDP转发 RSV 0x00，保留 ATYP DST.ADDR类型 DST.ADDR 目的地址 0x01 IPv4地址，DST.ADDR部分4字节长度 0x03 域名，DST.ADDR部分第一个字节为域名长度，DST.ADDR剩余的内容为域名，没有\0结尾。 0x04 IPv6地址，16个字节长度。 DST.PORT 网络字节序表示的目的端口 代码实现：type Socks5Resolution struct &#123; VER uint8 CMD uint8 RSV uint8 ATYP uint8 DSTADDR []byte DSTPORT uint16 DSTDOMAIN string RAWADDR *net.TCPAddr&#125;func (s *Socks5Resolution) lstRequest(conn net.Conn) error &#123; b := make([]byte, 128) n, err := conn.Read(b) if err != nil || n &lt; 7 &#123; log.Println(err) return errors.New("请求协议错误") &#125; s.VER = b[0] if s.VER != 5 &#123; return errors.New("该协议不是socks5协议") &#125; s.CMD = b[1] if s.CMD != 1 &#123; return errors.New("客户端请求类型不为代理连接, 其他功能暂时不支持.") &#125; s.RSV = b[2] //RSV保留字端，值长度为1个字节 s.ATYP = b[3] switch s.ATYP &#123; case 1: // IP V4 address: X'01' s.DSTADDR = b[4 : 4+net.IPv4len] case 3: // DOMAINNAME: X'03' s.DSTDOMAIN = string(b[5:n-2]) ipAddr, err := net.ResolveIPAddr("ip", s.DSTDOMAIN) if err != nil &#123; return err &#125; s.DSTADDR = ipAddr.IP case 4: // IP V6 address: X'04' s.DSTADDR = b[4 : 4+net.IPv6len] default: return errors.New("IP地址错误") &#125; s.DSTPORT = binary.BigEndian.Uint16(b[n-2:n]) // DSTADDR全部换成IP地址，可以防止DNS污染和封杀 s.RAWADDR = &amp;net.TCPAddr&#123; IP: s.DSTADDR, Port: int(s.DSTPORT), &#125; /** 回应客户端,响应客户端连接成功 +----+-----+-------+------+----------+----------+ |VER | REP | RSV | ATYP | BND.ADDR | BND.PORT | +----+-----+-------+------+----------+----------+ | 1 | 1 | X'00' | 1 | Variable | 2 | +----+-----+-------+------+----------+----------+ */ resp := []byte&#123;0x05, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00&#125; conn.Write(resp) return nil&#125; （4）最后将信息进行转发即可代码实现: wg := new(sync.WaitGroup) wg.Add(2) go func() &#123;defer wg.Done()defer dstServer.Close() io.Copy(dstServer, client) &#125;() go func() &#123;defer wg.Done() defer client.Close() io.Copy(client, dstServer) &#125;() wg.Wait()]]></content>
      <categories>
        <category>技术博文</category>
        <category>编程语言</category>
        <category>GO</category>
      </categories>
      <tags>
        <tag>编程语言</tag>
        <tag>Golang</tag>
        <tag>代理转发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vue小项目]]></title>
    <url>%2F2019%2F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%2Fvue%E5%B0%8F%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[创建vue项目通过ui创建项目用vue ui打开浏览器页面进行项目创建和管理。 通过命令行创建项目用vue create 创建项目vue create baidumap， 生成以下目录结构： tree /F│ .gitignore│ babel.config.js│ package-lock.json│ package.json│ README.md│├─public│ favicon.ico│ index.html│└─src │ App.vue │ main.js │ ├─assets │ logo.png │ └─components HelloWorld.vue 定义页面]]></content>
      <categories>
        <category>技术博文</category>
        <category>前端</category>
      </categories>
      <tags>
        <tag>vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IPVS: IP虚拟服务器]]></title>
    <url>%2F2018%2F%E8%BF%90%E7%BB%B4%2FIPVS-IP%E8%99%9A%E6%8B%9F%E6%9C%8D%E5%8A%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[IPVS，也叫IP虚拟服务器（IP Virtual Server，简写为IPVS），主要有Direct Routing、NAT模式、FULLNAT模式、TUN模式四种模式。 ipvs称之为IP虚拟服务器（IP Virtual Server，简写为IPVS），主要有Direct Routing、NAT模式、FULLNAT模式、TUN模式四种模式。 DR模式（Direct Routing） DR模式下，客户端的请求包到达负载均衡器的虚拟服务IP端口后，负载均衡器不会改写请求包的IP和端口，但是会改写请求包的MAC地址为后端RS的MAC地址，然后将数据包转发；真实服务器处理请求后，响应包直接回给客户端，不再经过负载均衡器。所以DR模式的转发效率是最高的，特别适合下行流量较大的业务场景，比如请求视频等大文件。 DR模式的特点： 数据包在LB转发过程中，源/目的IP端口都不会变化。LB只是将数据包的MAC地址改写为RS的MAC地址，然后转发给相应的RS。 每台RS上都必须在环回网卡上绑定LB的虚拟服务IP。因为LB转发时并不会改写数据包的目的IP，所以RS收到的数据包的目的IP仍是LB的虚拟服务IP。为了保证RS能够正确处理该数据包，而不是丢弃，必须在RS的环回网卡上绑定LB的虚拟服务IP。这样RS会认为这个虚拟服务IP是自己的IP，自己是能够处理这个数据包的。否则RS会直接丢弃该数据包 RS上的业务进程必须监听在环回网卡的虚拟服务IP上，且端口必须和LB上的虚拟服务端口一致。因为LB不会改写数据包的目的端口，所以RS服务的监听端口必须和虚拟服务端口一致，否则RS会直接拒绝该数据包。 RS处理完请求后，响应直接回给客户端，不再经过LB。因为RS收到的请求数据包的源IP是客户端的IP，所以理所当然RS的响应会直接回给客户端，而不会再经过LB。这时候要求RS和客户端之间的网络是可达的。 LB和RS须位于同一个子网。因为LB在转发过程中需要改写数据包的MAC为RS的MAC地址，所以要能够查询到RS的MAC。而要获取到RS的MAC，则需要保证二者位于一个子网，否则LB只能获取到RS网关的MAC地址。 注释：回环网卡（Loopback adaptor），是一种特殊的网络接口，不与任何实际设备连接，而是完全由软件实现。与回环地址（127.0.0.0/8 或 ::1/128）不同，回环网卡对系统“显示”为一块硬件。任何发送到该网卡上的数据都将立刻被同一网卡接收到。例子有 Linux 下的 lo 接口 NAT模式（Network Address Translation） NAT模式下，请求包和响应包都需要经过LB处理。当客户端的请求到达虚拟服务后，LB会对请求包做目的地址转换（DNAT），将请求包的目的IP改写为RS的IP。当收到RS的响应后，LB会对响应包做源地址转换（SNAT），将响应包的源IP改写为LB的IP。 NAT模式的特点： LB会修改数据包的地址。对于请求包，会进行DNAT；对于响应包，会进行SNAT。 LB会透传客户端IP到RS（DR模式也会透传）。虽然LB在转发过程中做了NAT转换，但是因为只是做了部分地址转发，所以RS收到的请求包里是能看到客户端IP的。 需要将RS的默认网关地址配置为LB的浮动IP地址。因为RS收到的请求包源IP是客户端的IP，为了保证响应包在返回时能走到LB上面，所以需要将RS的默认网关地址配置为LB的虚拟服务IP地址。当然，如果客户端的IP是固定的，也可以在RS上添加明细路由指向LB的虚拟服务IP，不用改默认网关。 LB和RS须位于同一个子网，并且客户端不能和LB/RS位于同一子网。因为需要将RS的默认网关配置为LB的虚拟服务IP地址，所以需要保证LB和RS位于同一子网。又因为需要保证RS的响应包能走回到LB上，则客户端不能和RS位于同一子网。否则RS直接就能获取到客户端的MAC，响应包就直接回给客户端了，不会走网关，也就走不到LB上面了。这时候由于没有LB做SNAT，客户端收到的响应包源IP是RS的IP，而客户端的请求包目的IP是LB的虚拟服务IP，这时候客户端无法识别响应包，会直接丢弃。 FULLNAT模式 FULLNAT模式下，LB会对请求包和响应包都做SNAT+DNAT。 FULLNAT模式的特点： LB完全作为一个代理服务器.FULLNAT下，客户端感知不到RS，RS也感知不到客户端，它们都只能看到LB。此种模式和七层负载均衡有点相似，只不过不会去解析应用层协议，而是在TCP层将消息转发 LB和RS对于组网结构没有要求。不同于NAT和DR要求LB和RS位于一个子网，FULLNAT对于组网结构没有要求。只需要保证客户端和LB、LB和RS之间网络互通即可。 三种转发模式性能从高到低：DR &gt; NAT &gt;FULLNAT。 虽然FULLNAT模式的性能比不上DR和NAT，但是FULLNAT模式没有组网要求，允许LB和RS部署在不同的子网中，这给运维带来了便利。并且 FULLNAT模式具有更好的可拓展性，可以通过增加更多的LB节点，提升系统整体的负载均衡能力 TUN模式 采用三角模式，数据从director进入，响应从real server直接回到client；real server和director都要配置IP tunnel，real server需要配置外部IP并且绑定VIP；real server可以分布在互联网络的任何位置；请求的源IP可以被real server获取；不可以进行端口转换；director只需要处理请求数据包、ReqPS是最重要的指标。]]></content>
      <categories>
        <category>技术博文</category>
        <category>容器技术</category>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>IPVS</tag>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go采坑记: Golang 空接口的小技巧应用]]></title>
    <url>%2F2018%2F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%2FGo%E9%87%87%E5%9D%91%E8%AE%B0-Golang-%E7%A9%BA%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%B0%8F%E6%8A%80%E5%B7%A7%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[最近在用golang写一个框架，希望可以比较灵活地构建一个方法，可以接受任意类型的输入，这样首先想到的是使用空接口interface{},因为在golang里面没有泛型。空接口例子一： type download interface &#123; Download(interface&#123;&#125;)&#125;type dl struct &#123; t string&#125;func (d dl) Download(a interface&#123;&#125;) &#123; switch a.(type) &#123; case string: v := a.(string) log.Println(v) case int: v := a.(int) log.Println(v * v) default: &#125;&#125; 空接口例子二： type pool struct &#123; function interface&#123;&#125; flag string&#125;func (p *pool) RUN() &#123; s := p.function.(download) s.Download("a") s.Download(1)&#125;func main() &#123; p := &amp;pool&#123; function: &amp;dl&#123;&#125;, &#125; p.RUN()&#125;]]></content>
      <categories>
        <category>技术博文</category>
        <category>编程语言</category>
        <category>GO</category>
      </categories>
      <tags>
        <tag>编程语言</tag>
        <tag>Golang</tag>
        <tag>空接口</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[系统分区，创建LVM，挂载使用]]></title>
    <url>%2F2018%2F%E8%BF%90%E7%BB%B4%2F%E7%B3%BB%E7%BB%9F%E5%88%86%E5%8C%BA%EF%BC%8C%E5%88%9B%E5%BB%BALVM%EF%BC%8C%E6%8C%82%E8%BD%BD%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[新硬盘回来，需要在现有的系统挂载使用。 分区/格式化fdisk /dev/sdb输入：Command (m for help): n #### 创建新的分区Command action e extended p primary partition (1-4)p #### 创建主分区Partition number (1-4):1 #### 分区IDFirst cylinder (1-65270, default 1): Using default value 1Last cylinder, +cylinders or +size&#123;K,M,G&#125; (1-65270, default 65270): Using default value 65270Command (m for help):t #### 修改分区类型Command (m for help):8e #### Linux lvmCommand (m for help):w #### 保存修改 partedparted /dev/sdb 可以用于修改 Disk label type, 比如把dos 改为 gpt:mklabel gpt新增分区：mkpart查看分区 ：p (parted) mklabel gpt # 将MBR磁盘格式化为GPT(parted) mkpart primary ext4 0% 100% 将所有容量分为一个主分区(parted) p #打印当前分区(parted) q #退出 创建物理卷物理卷就是指硬盘分区或从逻辑上与磁盘分区具有同样功能的设备(如RAID)，是LVM的基本存储逻辑块，但和基本的物理存储介质（如分区、磁盘等）比较，却包含有与LVM相关的管理参数 pvcreate /dev/sdb1 创建逻辑组由一个或多个物理卷组成一个整体，即称为卷组，在卷组中可以动态的添加或移除物理卷，许多个物理卷可以分别组成不同的卷组，卷组名称由用户自行定义。 vgcreate fastDevice /dev/sdb1 创建逻辑卷逻辑卷是建立在卷组之上的，与物理卷无直接关系，对于逻辑卷来说，每一个卷组就是一个整体，从这个整体中切出一小块空间，作为用户创建文件系统的基础，这一小块空间就称为逻辑卷，使用mkfs等工具在逻辑卷之上建立文件系统以后，即可挂载到Linux系统中的目录下使用。 使用600G空间从fastDevice创建一个名叫datalvcreate -L 600G -n data fastDevice 使用剩余空闲空间的100%lvcreate -l 100%Free -n runtime fastDevice 创建文件系统使用mkfs.ext4命令在逻辑卷data上创建ext4文件系统mkfs.ext4 /dev/fastDevice/data 设置挂载和开机自动挂载挂在分区到本地目录mount /dev/fastDevice/data /home/data 设置开机挂载vi /etc/fstab #### 修改fstab 开机自动挂载-----------UUID=94e4e384-0ace-437f-bc96-057dd64f42ee / ext4 defaults,barrier=0 1 1tmpfs /dev/shm tmpfs defaults 0 0devpts /dev/pts devpts gid=5,mode=620 0 0sysfs /sys sysfs defaults 0 0proc /proc proc defaults 0 0/dev/VolGroup01/lvmServer /server ext4 defaults 0 0 新硬盘扩容将新的物理卷加入卷组: vgextend data /dev/vdc 卸载要扩充逻辑卷：umount /home/data 扩充逻辑卷:lvextend -L +100G /dev/data/data 检查逻辑卷及重新设置大小:e2fsck -f /dev/data/dataresize2fs /dev/data/data 挂载：mount /dev/data/data /home/data 数据迁移如果做数据迁移可以先将逻辑卷挂到一个临时目录：mount /dev/data/data /home/tmp 然后将数据拷贝到临时目录：rsync -avx /home/data/ /home/tmp 到/home/tmp下查看，没问题后将源目录重命名，将硬盘挂载过来：mv /home/data /home/data.bakumount /dev/data/datamount /dev/data/data /home/data]]></content>
      <categories>
        <category>技术博文</category>
        <category>系统运维</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>LVM</tag>
        <tag>系统分区</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker container 动态修改内存限制]]></title>
    <url>%2F2018%2F%E8%BF%90%E7%BB%B4%2Fdocker-container-%E5%8A%A8%E6%80%81%E4%BF%AE%E6%94%B9%E5%86%85%E5%AD%98%E9%99%90%E5%88%B6%2F</url>
    <content type="text"><![CDATA[docker动态修改配置用docker update,用法：docker update -hFlag shorthand -h has been deprecated, please use --helpUsage: docker update [OPTIONS] CONTAINER [CONTAINER...]Update configuration of one or more containersOptions: --blkio-weight uint16 Block IO (relative weight), between 10 and 1000, or 0 to disable (default 0) --cpu-period int Limit CPU CFS (Completely Fair Scheduler) period --cpu-quota int Limit CPU CFS (Completely Fair Scheduler) quota --cpu-rt-period int Limit the CPU real-time period in microseconds --cpu-rt-runtime int Limit the CPU real-time runtime in microseconds -c, --cpu-shares int CPU shares (relative weight) --cpuset-cpus string CPUs in which to allow execution (0-3, 0,1) --cpuset-mems string MEMs in which to allow execution (0-3, 0,1) --help Print usage --kernel-memory string Kernel memory limit -m, --memory string Memory limit --memory-reservation string Memory soft limit --memory-swap string Swap limit equal to memory plus swap: '-1' to enable unlimited swap --restart string Restart policy to apply when a container exits 当前要做的是把一个运行着gitlab 的容器内存限制在2048M以内，尝试用:docker update -m 2048m gitlab 报错：Memory limit should be smaller than already set memoryswap limit, update the memoryswap at the same time 发现问题，docker 默认没有启用memory-swap交换内存，直接设置了内存问题会出问题，也就是说宿主 swap 支持使用多少则容器即可使用多少，如果 –memory-swap 设置小于 –memory则设置不生效。 将memory-swap 设置值为 -1，表示容器程序使用内存受限，而 swap 空间使用不受限制。docker update --memory 2048m --memory-swap -1 gitlab 问题解决。]]></content>
      <categories>
        <category>技术博文</category>
        <category>容器技术</category>
        <category>Dokcer</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>Docker</tag>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go采坑记: sync.WaitGroup 指针引用问题]]></title>
    <url>%2F2018%2F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%2FGo%E9%87%87%E5%9D%91%E8%AE%B0-sync-WaitGroup-%E6%8C%87%E9%92%88%E5%BC%95%E7%94%A8%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[WaitGroup：主要包括Add,Done,Wait三个方法，Add表示添加一个goroutine，Done等于Add(-1)，表示一个goroutine结束，wait表示主线程一直等到所有的goroutine执行完成，并且阻塞主线程的执行，直到所有的goroutine执行完成。 但在使用的时候发现进程一直阻塞，代码如下：func Exec(url string, wg sync.WaitGroup) error&#123; statusCode, body, err := fasthttp.Get(nil, url) if err != nil&#123; log.Fatalf("err,%s", err) return err &#125; if statusCode != fasthttp.StatusOK &#123; log.Fatalf("Unexpected status code: %d") return err &#125; ParseBody(body) wg.Done() return nil&#125;func main()&#123; var URL string URL = "http://192.168.2.112:61208/" num := 100 var wg sync.WaitGroup wg.Add(num) startTime := time.Now() for i:=0; i&lt;num; i++&#123; go Exec(URL, wg) &#125; wg.Wait() endTime := time.Now() spendTime := endTime.Sub(startTime) log.Println(spendTime)&#125; 将sync.WaitGroup放在main中做done就可以正常运行：func main()&#123; var URL string URL = "http://192.168.2.112:61208/" num := 100 var wg sync.WaitGroup wg.Add(num) startTime := time.Now() for i:=0; i&lt;num; i++&#123; go func()&#123; statusCode, body, err := fasthttp.Get(nil, url) if err != nil&#123; log.Fatalf("err,%s", err) &#125; if statusCode != fasthttp.StatusOK &#123; log.Fatalf("Unexpected status code: %d") &#125; ParseBody(body) wg.Done() &#125; &#125; wg.Wait() endTime := time.Now() spendTime := endTime.Sub(startTime) log.Println(spendTime)&#125; 一直阻塞应该是死锁了，也就是wg.Done()没起作用，原来是wg 给拷贝传递到了 goroutine 中，导致只有 Add 操作，其实 Done操作是在 wg 的副本执行导致的~~将wg 的传入类型改为 *sync.WaitGrou,这样就能引用到正确的WaitGroup了 func Exec(url string, wg *sync.WaitGroup) error&#123; statusCode, body, err := fasthttp.Get(nil, url) if err != nil&#123; log.Fatalf("err,%s", err) return err &#125; if statusCode != fasthttp.StatusOK &#123; log.Fatalf("Unexpected status code: %d") return err &#125; ParseBody(body) wg.Done() return nil&#125;func main()&#123; var URL string URL = "http://192.168.2.112:61208/" num := 100 var wg sync.WaitGroup wg.Add(num) startTime := time.Now() for i:=0; i&lt;num; i++&#123; go Exec(URL, &amp;wg) &#125; wg.Wait() endTime := time.Now() spendTime := endTime.Sub(startTime) log.Println(spendTime)&#125;]]></content>
      <categories>
        <category>技术博文</category>
        <category>编程语言</category>
        <category>GO</category>
      </categories>
      <tags>
        <tag>编程语言</tag>
        <tag>Golang</tag>
        <tag>指针</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tmux命令快捷键]]></title>
    <url>%2F2018%2F%E8%BF%90%E7%BB%B4%2Ftmux%E5%91%BD%E4%BB%A4%E5%BF%AB%E6%8D%B7%E9%94%AE%2F</url>
    <content type="text"><![CDATA[Tmux 快捷键 &amp; 速查表启动新会话：tmux [new -s 会话名 -n 窗口名] 恢复会话：tmux at [-t 会话名] 列出所有会话：tmux ls 关闭会话：tmux kill-session -t 会话名 关闭所有会话：tmux ls | grep : | cut -d. -f1 | awk '&#123;print substr($1, 0, length($1)-1)&#125;' | xargs kill 在 Tmux 中，按下 Tmux 前缀 ctrl+b，然后： 会话:new&lt;回车&gt; 启动新会话s 列出所有会话$ 重命名当前会话 窗口 (标签页)c 创建新窗口w 列出所有窗口n 后一个窗口p 前一个窗口f 查找窗口, 重命名当前窗口&amp; 关闭当前窗口 调整窗口排序swap-window -s 3 -t 1 交换 3 号和 1 号窗口swap-window -t 1 交换当前和 1 号窗口move-window -t 1 移动当前窗口到 1 号 窗格（分割窗口）% 垂直分割" 水平分割o 交换窗格x 关闭窗格⍽ 空格键 - 切换布 局q 显示每个窗格是第几个，当数字出现的时候按数字几就选中第几个窗格&#123; 与上一个窗格交换位置&#125; 与下一个窗格交换位置z 切换窗格最大化/最小化 同步窗格这么做可以切换到想要的窗口，输入 Tmux 前缀和一个冒号呼出命令提示行，然后输入：:setw synchronize-panes 你可以指定开或关，否则重复执行命令会在两者间切换。这个选项值针对某个窗口有效，不会影响别的会话和窗口。完事儿之后再次执行命令来关闭。帮助 调整窗格尺寸如果你不喜欢默认布局，可以重调窗格的尺寸。虽然这很容易实现，但一般不需要这么干。这几个命令用来调整窗格：PREFIX : resize-pane -D 当前窗格向下扩大 1 格PREFIX : resize-pane -U 当前窗格向上扩大 1 格PREFIX : resize-pane -L 当前窗格向左扩大 1 格PREFIX : resize-pane -R 当前窗格向右扩大 1 格PREFIX : resize-pane -D 20 当前窗格向下扩大 20 格PREFIX : resize-pane -t 2 -L 20 编号为 2 的窗格向左扩大 20 格 文本复制模式：按下前缀 [进入文本复制模式。可以使用方向键在屏幕中移动光标。默认情况下，方向键是启用的。在配置文件中启用 Vim 键盘布局来切换窗口、调整窗格大小。Tmux 也支持 Vi 模式。要是想启用 Vi 模式，只需要把下面这一行添加到 .tmux.conf 中：setw -g mode-keys vi 启用这条配置后，就可以使用 h、j、k、l 来移动光标了。 想要退出文本复制模式的话，按下回车键就可以了。一次移动一格效率低下，在 Vi 模式启用的情况下，可以辅助一些别的快捷键高效工作。 例如，可以使用 w 键逐词移动，使用 b 键逐词回退。使用 f 键加上任意字符跳转到当前行第一次出现该字符的位置，使用 F 键达到相反的效果。vi emacs 功能^ M-m 反缩进Escape C-g 清除选定内容Enter M-w 复制选定内容j Down 光标下移h Left 光标左移l Right 光标右移L 光标移到尾行M M-r 光标移到中间行H M-R 光标移到首行k Up 光标上移d C-u 删除整行D C-k 删除到行末$ C-e 移到行尾: g 前往指定行C-d M-Down 向下滚动半屏C-u M-Up 向上滚动半屏C-f Page down 下一页w M-f 下一个词p C-y 粘贴C-b Page up 上一页b M-b 上一个词q Escape 退出C-Down or J C-Down 向下翻C-Up or K C-Up 向下翻n n 继续搜索? C-r 向前搜索/ C-s 向后搜索0 C-a 移到行首Space C-Space 开始选中 C-t 字符调序 杂项：d 退出 tmux（tmux 仍在后台运行）t 窗口中央显示一个数字时钟? 列出所有快捷键: 命令提示符 配置选项： 鼠标支持 - 设置为 on 来启用鼠标 setw -g mode-mouse off set -g mouse-select-pane off set -g mouse-resize-pane off set -g mouse-select-window off 设置默认终端模式为 256colorset -g default-terminal “screen-256color” 启用活动警告setw -g monitor-activity onset -g visual-activity on 居中窗口列表set -g status-justify centre 最大化/恢复窗格unbind Up bind Up new-window -d -n tmp \; swap-pane -s tmp.1 \; select-window -t tmpunbind Downbind Down last-window \; swap-pane -s tmp.1 \; kill-window -t tmp]]></content>
      <categories>
        <category>技术博文</category>
        <category>系统运维</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>Linux</tag>
        <tag>快捷键</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Andorid逆向工程:jeb初探(上)]]></title>
    <url>%2F2018%2F%E5%AE%89%E5%85%A8%2FAndorid%E9%80%86%E5%90%91%E5%B7%A5%E7%A8%8B-jeb%E5%88%9D%E6%8E%A2-%E4%B8%8A%2F</url>
    <content type="text"><![CDATA[JEB是一个功能强大的为安全专业人士设计的Android应用程序的反编译工具。用于逆向工程或审计APK文件，可以提高效率减少许多工程师的分析时间, jeb的常用功能: 1.反编译apk,dex 2.包名树状图 3.查看指定类的smali代码 4.转换成java语言 5.java代码中双击函数 进入函数方法的定义 ，查看方法的调用 6.查看AndroidManifest.xml 进入正题~~~~用jeb逆向寻找加密网络请求参数加密方法 1、通过【黑猫酱】介绍，在52pojie下载了个jeb，安装好正式开干。 或者从百度网盘直接下载,提取码：6ft3。 2、首先，在Bytecode node 里面找到网络请求模块http 3、按Q反编译得到HttpMethod 4、按x检索调用它的模块，找到request方法 5、一直向上检索，直到找到netease模块，netease我们都知道是网易的英文名，也就是说下面就是主模块了 6、我们看到这里好多字符串都是乱码像加密一样~，没错了，就是加密滴，为什么？因为，因为我听【黑猫酱】说的(￣▽￣)” 7、双击进去方法，找到解密函数，获得解密流程，先用base64解码字符串，然后遍历字符串与关键字进行异或： 待续….]]></content>
      <categories>
        <category>技术博文</category>
        <category>信息安全</category>
      </categories>
      <tags>
        <tag>Andorid</tag>
        <tag>逆向工程</tag>
        <tag>jeb</tag>
        <tag>入门教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RTBkit 精准营销系统部署]]></title>
    <url>%2F2018%2F%E8%BF%90%E7%BB%B4%2FRTBkit-%E7%B2%BE%E5%87%86%E8%90%A5%E9%94%80%E7%B3%BB%E7%BB%9F%E9%83%A8%E7%BD%B2%E5%8F%8A%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[背景项目地址： https://github.com/rtbkit/rtbkit/wiki/What-is-RTBkit%3F RTBkit是一个开源软件包，通过将问题分解为明确定义的组件，可以完成创建实时广告投放的大部分困难的工程工作。其开放的、面向服务的架构可用于满足简单或者复杂的投放需求。RTBkit可以通过自定义配置文件或者开发接口的形式进行策略制定和扩展。 RTBkit架构 部署准备操作系统：ubuntu:14.04.1 安装RTBkit: apt-get -y updateapt-get install -y linux-tools-generic libbz2-dev python-dev scons unzip\ libtool liblzma-dev libblas-dev make automake \ ccache ant openjdk-7-jdk libcppunit-dev doxygen \ libcrypto++-dev libACE-dev gfortran liblapack-dev \ libevent-dev libssh2-1-dev libicu-dev libv8-dev \ g++ google-perftools libgoogle-perftools-dev \ zlib1g-dev git pkg-config valgrind autoconf \ libcurl4-openssl-dev cmake libsigc++-2.0-devmkdir -p $HOME/local/binPATH="$HOME/local/bin:$PATH" mkdir -p $HOME/local/libexport LD_LIBRARY_PATH="$HOME/local/lib:$LD_LIBRARY_PATH" export PKG_CONFIG_PATH="$HOME/local/lib/pkgconfig/:$HOME/local/lib/pkg-config/"source ~/.profileenv | grep PATHgit clone https://github.com/rtbkit/rtbkit-deps.gitcd rtbkit-depssed -i 's/git@github.com:/https:\/\/github.com\//g' .gitmodulesgit submodule update --initmake all NODEJS_ENABLED=0export PATH=/root/local/bin:$PATHcd /git clone https://github.com/rtbkit/rtbkit.gitcd rtbkitcp jml-build/sample.local.mk local.mkmake compile NODEJS_ENABLED=0export LD_LIBRARY_PATH='/root/local/share;/root/local/lib' 构建基于docker的服务zookeeper集群服务 使用 docker-compose 来启动 ZK 集群，创建一个名为 docker-compose.yml 的文件：version: '3'services: zook1: image: zookeeper restart: always container_name: zk1 networks: - rtbkit-network ports: - "2181:2181" environment: ZOO_MY_ID: 1 ZOO_SERVERS: server.1=zk1:2888:3888 server.2=zk2:2888:3888 server.3=zk3:2888:3888 zook2: image: zookeeper restart: always container_name: zk2 networks: - rtbkit-network ports: - "2182:2181" environment: ZOO_MY_ID: 2 ZOO_SERVERS: server.1=zk1:2888:3888 server.2=zk2:2888:3888 server.3=zk3:2888:3888 zook3: image: zookeeper restart: always container_name: zk3 networks: - rtbkit-network ports: - "2183:2181" environment: ZOO_MY_ID: 3 ZOO_SERVERS: server.1=zk1:2888:3888 server.2=zk2:2888:3888 server.3=zk3:2888:3888 redis: image: daocloud.io/library/redis:3.2.9 restart: always container_name: redis02 networks: - rtbkit-network ports: - "16379:6379" volumes: - "/home/dataspark/rtbcode/rtbkit/rtbkit/sample.redis.conf:/usr/local/etc/redis/redis.conf" Graphite: image: graphiteapp/graphite-statsd restart: always container_name: graphite_test networks: - rtbkit-network ports: - "6080:80" - "8003-8004:2003-2004" - "8023-8024:2023-2024" - "14125:8125/udp" - "14126:8126" networks: rtbkit-network: driver: bridge ZOO_MY_ID 和 ZOO_SERVERS 是搭建 ZK 集群需要设置的两个环境变量, 其中 ZOO_MY_ID 表示 ZK 服务的 id, 它是1-255 之间的整数, 必须在集群中唯一. ZOO_SERVERS 是ZK 集群的主机列表.server.A=B：C：D：其中 A 是一个数字，表示这个是第几号服务器；B 是这个服务器的 ip 地址；C 表示的是这个服务器与集群中的 Leader 服务器交换信息的端口；D 表示的是万一集群中的 Leader 服务器挂了，需要一个端口来重新进行选举，选出一个新的 Leader，而这个端口就是用来执行选举时服务器相互通信的端口。如果是伪集群的配置方式，由于 B 都是一样，所以不同的 Zookeeper 实例通信端口号不能一样，所以要给它们分配不同的端口号。 运行docker compose: COMPOSE_PROJECT_NAME=rtbkit_cluster docker-compose -f rtbkit-compose.yml up -d docker compose 会创建一个新的网桥rtbkit_cluster_default 修改sample.bootstrap.json文件中的zookeeper端口配置"zookeeper-user":"localhost:2181"改为"zookeeper-user":"zk1:2181,zk2:2181,zk3:2181", Graphite docker run -d \ –name graphite \ –restart=always \ -p 5080:80 \ -p 7003-7004:2003-2004 \ -p 7023-7024:2023-2024 \ -p 13125:8125/udp \ -p 13126:8126 \graphiteapp/graphite-statsd 修改sample.bootstrap.json文件中的carbon端口配置"carbon-uri": ["carbon1.kittens.org:2003", "carbonA.kittens.org:2003"]改为"carbon-uri": ["graphite:2003"] redis服务 docker run -p 6379:6379 -v /home/dataspark/rtbcode/rtbkit/rtbkit/sample.redis.conf:/usr/local/etc/redis/redis.conf –name redis01 -d daocloud.io/library/redis:3.2.9 redis-server /usr/local/etc/redis/redis.conf 修改rtbkit/sample.launch.json里面的’banker’将其参数”-B”, “rtbkit/sample.bootstrap.json”, “-r”, “localhost:6379”改为 “redis02:6379” 启动主服务rtbkit docker run -it –name rtbkit01 –link graphite:graphite –link redis01:redis -p 5212:22 rtbkit bash ./build/x86_64/bin/launcher –node localhost –script ./launch.sh –bin ./build/x86_64/bin –launch rtbkit/sample.launch.json Banker模块的JSON API说明GET / 类似于help命令，用法：curl http://localhost:9985/ GET /ping 检查Banker服务是否对HTTP有效，有效返回“pong” GET /v1/accounts 获取用户账号信息，如果没有参数默认返回全部，后面参数可以跟maxDepth和accountPrefix。 maxDepth: an integer describing the maximum length at which keys will be sought (default: unlimited) accountPrefix: a string that specifies the prefix against which the returned account names will be matched POST /v1/accounts POST为创建用户。后面参数跟accountType和accountName。 GET /v1/accounts/ 返回指定用户的信息 POST,PUT /v1/accounts//balance 从父账号转换预算给子账号以平衡请求数量参数为accountType，POST内容为”{ “USD/1M”: 金额 }” body: The body for that command must contain an amount encoded in a JSON Object. For example:: “{ “USD/1M”: 123456 }” (123456 micro USD) parameters: accountType: If the account does not exist, this parameter defines the type of account to be created (“spend” or “budget”) POST,PUT /v1/accounts//budget 通过请求为用户设置预算金额，只允许为顶级账户设置。POST内容为 “{ “USD/1M”: 金额 }” ，表示加入XX美元。用法：curl http://localhost:9985/v1/accounts/hello/budget -d ‘{ “USD/1M”: 123456789 }’ GET /v1/accounts//children 返回指定账户的子账号列表。参数为depth表示返回深度，默认为不限。（效果未知） POST,PUT /v1/accounts//shadow 更新响应的支付账号的spend和commitment body: The body for that command must contain a representation of the shadow account in JSON. GET /v1/accounts//subtree 返回指定账号和其子账号的属性表示。参数为depth表示返回深度，默认为不限。 GET /v1/accounts//close 关闭一个账号和其所有子账号。 GET /v1/accounts//summary 账号的汇总信息 GET /v1/summary 所有账号的汇总信息]]></content>
      <categories>
        <category>技术博文</category>
        <category>系统运维</category>
      </categories>
      <tags>
        <tag>入门教程</tag>
        <tag>运维</tag>
        <tag>RTB</tag>
        <tag>DSP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[性能测试: Python3 利用asynico协程系统构建生产消费模型]]></title>
    <url>%2F2018%2F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%2F%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95-Python3-%E5%88%A9%E7%94%A8asynico%E5%8D%8F%E7%A8%8B%E7%B3%BB%E7%BB%9F%E6%9E%84%E5%BB%BA%E7%94%9F%E4%BA%A7%E6%B6%88%E8%B4%B9%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[今天研究了下python3的新特性 asynico ，试了试 aiohttp 协程效果，单核QPS在500~600之间，性能还可以。 ab测试工具ab测试工具全名叫Apache Bench，主要用来做网站压力和性能测试。 ab命令：$ ab -hUsage: ab [options] [http[s]://]hostname[:port]/pathOptions are: -n requests Number of requests to perform -c concurrency Number of multiple requests to make at a time -t timelimit Seconds to max. to spend on benchmarking This implies -n 50000 -s timeout Seconds to max. wait for each response Default is 30 seconds -b windowsize Size of TCP send/receive buffer, in bytes -B address Address to bind to when making outgoing connections -p postfile File containing data to POST. Remember also to set -T -u putfile File containing data to PUT. Remember also to set -T -T content-type Content-type header to use for POST/PUT data, eg. 'application/x-www-form-urlencoded' Default is 'text/plain' -v verbosity How much troubleshooting info to print -w Print out results in HTML tables -i Use HEAD instead of GET -x attributes String to insert as table attributes -y attributes String to insert as tr attributes -z attributes String to insert as td or th attributes -C attribute Add cookie, eg. 'Apache=1234'. (repeatable) -H attribute Add Arbitrary header line, eg. 'Accept-Encoding: gzip' Inserted after all normal header lines. (repeatable) -A attribute Add Basic WWW Authentication, the attributes are a colon separated username and password. -P attribute Add Basic Proxy Authentication, the attributes are a colon separated username and password. -X proxy:port Proxyserver and port number to use -V Print version number and exit -k Use HTTP KeepAlive feature -d Do not show percentiles served table. -S Do not show confidence estimators and warnings. -q Do not show progress when doing more than 150 requests -g filename Output collected data to gnuplot format file. -e filename Output CSV file with percentages served -r Don't exit on socket receive errors. -h Display usage information (this message) -Z ciphersuite Specify SSL/TLS cipher suite (See openssl ciphers) -f protocol Specify SSL/TLS protocol (SSL3, TLS1, TLS1.1, TLS1.2 or ALL) 比如开启一个10并发的1000次请求：ab -c 10 -n 1000 http://www.tensorbytes.com/ 添加头信息：ab -c 1 -n 1 -w \ -H 'User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.105 Safari/537.36' \ -H 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9' \ -H 'Accept-Language: zh-CN,zh;q=0.9,en;q=0.8' \ http://www.tensorbytes.com/ 案例代码代码：import aiohttpimport asyncioimport hashlibimport timefrom asyncio import Queueclass Fetch: def __init__(self): self.work_queue = Queue() self.max_loop = 10000 self.host = "http://14.29.5.29/XXXX" self.payload = &#123;"planId": 10000007, "activityId": 1002, "label": 1, "key": "98214ecfe6b9ae8855e3ac6509ad940f", "keyType": "imei", "batchId": 1, "token": "395La7f9x9x"&#125; async def get_url(self, host, payload): async with aiohttp.ClientSession() as session: async with session.post(host, data=payload) as resp: text = await resp.text() if "1" in text: print(text, payload["key"]) async def consumer(self): while True: param = await self.work_queue.get() if param: await self.get_url(self.host, param) self.work_queue.task_done() else: break async def producer(self): i = 0 string = '866260035710238' while 1: if i: md5_str = hashlib.md5(string.encode('utf-8')) self.payload["key"] = md5_str.hexdigest() string = str(int(string) + 1) await self.work_queue.put(self.payload.copy()) #必须要 i += 1 if i &gt; self.max_loop: break async def run(self): await self.producer() print('start consumer...') tasks = [ loop.create_task(self.consumer()) for i in range(10) ] await self.work_queue.join() print('end join') for task in tasks: task.cancel()t1 = time.time()loop = asyncio.get_event_loop()test = Fetch()loop.run_until_complete(test.run())loop.close()print(time.time() - t1)]]></content>
      <categories>
        <category>技术博文</category>
        <category>编程语言</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>并发</tag>
        <tag>asynico</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DSP 及 RTB 基本概念、原理、理论及应用介绍]]></title>
    <url>%2F2018%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2FDSP-%E5%8F%8A-RTB-%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E5%8F%8A%E7%90%86%E8%AE%BA%E5%BA%94%E7%94%A8%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[这是一份关于精准广告投放技术的演示稿，从基本概念、到原理实现到具体的市面上的大厂框架进行了详细的剖析。 正文 IR researchers, for example, are facing the challenge of deﬁning the relevancy of underlying audiences given a campaign goal, and consequently, developing techniques to ﬁnd and ﬁlter them out in the real time bid request data. For data miners, a fundamental task is identifying repeated patterns over the large-scale streaming data of bid requests, winning bids and ad. For machine learners, an emerging problem is telling a machine to react to a data stream, i.e., learning to bid cleverly on behalf of advertisers and brands to maximise conversions while keeping costs to a minimum Behavioral targeting（行为定位广告） comprises a range of technologies and techniques used by online website brands, publishers and advertisers aimed at increasing the effectiveness of marketing and advertising using user web-browsing behavior information. RTB的定义RTB通过透明公平的拍卖机制，把对的广告展示给对的用户，整个竞价过程发生在广告展示前的一瞬间。在RTB环境中，不论是对广告主还是对开发者而言，拍卖都被认为是一种公平而透明的方式。它能自动在正确的时间，将合适的广告以拍卖双方达成一致的合理价格推送给正确的受众。 拍卖的定义拍卖是一个过程，即：潜在的竞价者对某一商品提交自己的出价，然后由拍卖方从所有出价中选出最高价，该出价者将成为获得商品的中标者。广告交易平台和供应方平台（SSP）与多个需求方平台（DSP）对接，利用拍卖，尤其是次高价投标拍卖（Second-price auction）机制，实时抛售广告展示机会，实现市场的供需平衡。 第一种，也是最基础的一种交易方式被称为PDB，即Private Direct Buy（私有直接购买），这种方式简单讲，是一对一（1v1）的购买方式。这种购买方式，与我们传统的广告采买方式基本上没有区别，即广告主找媒体确定好广告位置和价格，然后按照排期规定的时间进行广告投放。在传统方式中，广告排期（spot plan）是这个交易过程的关键，而在PDB中，也完全如此。 PDB这种方式，是广告主最容易接受的方式。首先，与传统采买方式一致意味着广告位资源是预先保证的，一旦排期确定，PO（purchase order）下达，广告位资源就肯定不可能易主。再者，不改变传统的广告采买过程意味着内部的组织和工作流程都不需要发生什么变化，因此也就没有“政治”问题（你懂的）。更何况，在此之上还能实现程序化的好处，有百利而无一害，何乐不为。 PDB方式支持传统的CPD（Cost Per Day）的广告采买方式，也支持CPM（Cost Per Milli，即广告被千次曝光所需的成本）和CPC（Cost Per Click）的方式。 Data exchanges(DX),also called Data Management Platforms(DMP), serve DSP, SSP and ADX by providing user historical data (usually in real-time) for better matching. Supply side platforms (SSP) serve publishers by registering their inventories (impressions) from multiple ad networks and accepting bids and placing ads automatically; Demand side platforms (DSP) serve advertisers or ad agencies by bidding for their campaigns in multiple ad networks automatically; When a user visits a webpage, an impression is created on publisher’s website. While the page loads, 1. An ad request is sent to an ad exchange through an ad network or a SSP; 2. The ad exchange queries DSPs for advertisers’ bids; 3. The DSP can contact data exchanges for the 3rd party user data; 4. If the advertiser decides to bid, the bid is generated and submitted (for example, the user is interested in travel, a travel related advertiser, e.g. booking.com, could expect the user to convert to their campaign and may be willing to bid higher); 5. The winner is selected at ad exchanges (largely based on the second price auction), then selected at SSP if the SSP sends the bid request to multiple ad exchanges; 6. The winning notice is sent to the advertiser; 7. Following the reversed path, the winner’s ad (creative, i.e., the text, picture,or video that the advertiser wants to show to users)is displayed on the webpage for the speciﬁc user; 8. The tracker collects the user’s feedback, determining whether the user clicked the ad and whether the ad led to any conversion. Different visitors behave differently on your website. The traffic you get on your website is composed of visitors with different intentions: some are on your website for purchasing your products, some are there for joining your organization (finding careers page), some are there for simply researching, and others are probably there by mistake and have not even tiny interest in what you are selling. Most websites and landing pages on the Internet are same for all these different kinds of visitors. That is why we see websites crammed with multiple call-to-actions (buy now, sign up for newsletter, free trial, like us on Facebook, and what not). These websites try appealing to all sorts of visitors, but finally, end up appealing nobody. 追踪用户行为：DSP公司通常会在广告主的网站上埋点（即放上一个1×1的不可见像素），这样当互联网用户第一次访问广告主的网站时，就会得到DSP公司的一个cookie，这样DSP公司就可以追踪到这个网民的在广告主网站上的行为了(这些数据也叫action data)。DSP公司还会和第三方的网站合作（例如：新浪，腾讯），在他们的网站上也埋点，或者向DMP购买网民行为数据，这样就可以追踪到网民在这些网站上的行为了(这些数据也叫mapping data)。这里值得一提的是，DSP公司对某一个用户记录的cookie和第三方网站或DMP或exchange记录的cookie是不一样的，这里需要一个叫Cookie Mapping的过程，这不是本文重点，以下假设DSP已经做好了Cookie Mapping，每个用户有一个唯一的id标识。 受众选择（audience selection）: m6d对每一个campaign(即每一个广告主的每个推广活动), 训练一个audience selection model, 该模型以在广告主的网站上发生转化行为（转化行为可以是注册成为用户，点击某个特定页面，购买产品。每个广告主对转化的定义不一样）的用户为正例，没有发生转化行为的用户为负例（是的，正负例很不均匀，通常要做采样和结果修正）。得到模型后，对所有的用户预估对这个campaign的转化概率p(c | u),即该用户u有多大的概率会在广告主的网站上发生转化行为（c表示conversion），去掉大多数转化概率非常小的用户，将目标用户根据转化概率高低分到不同的segments中。这样我们对每个campaign就找到了很多的目标用户，而且这些用户根据他们的质量高低，被分别放在不同的segments中。 通知exchange: DSP将这些目标用户的cookie告诉exchange，这样当有这些cookie的请求来的时候，exchange才会来向DSP的服务器发送请求。 Segment管理： 通常DSP公司会有账户管理员（运营人员），他们人工来对每个campaign的做一些设定。他们根据每个campaign所属的行业特点，经济状况，决定开启哪些segments，关掉哪些segments。例如：对没钱的小公司的campaign, 那些用户转化概率小一些的segment就不要投广告了。他们还需要对每个segment设定一个基础出价（base price）。账户管理员可以拿到每个segment的平均预估转化概率，来辅助他们设定基础出价。这一步也是人工影响投放策略最主要的地方。 进行实时竞价：当exchange把请求发过来的时候，DSP会拿到以下信息：当前广告位的信息，当前用户的cookie和基本信息。DSP需要在100ms内，根据对当前用户的理解，并且考虑当前广告位，根据自己的bidding算法，来要决定是否要买这次展现，投放哪个campaign的广告，出价是多少（bidding），并向exchange返回出价信息？如果超过时间DSP没有响应，则exchange默认DSP放弃这次竞价。 展现广告：如果赢得了展现机会，则DSP返回创意，用户就会在该广告位看到该创意。 追踪转化：因为DSP在广告主的网站上埋了点，就能知道用户是否在这次展现之后进行了转化行为。根据这些数据统计转化率，每个转化平均成本等指标，汇总成报告给广告主。 A user is typically identiﬁed by an HTTP cookie.A cookie, in the form of a small piece of data, is sent from a website and stored in the user’s Web browser the ﬁrst time the user browses a website.In the context of display advertising, each service provider would act as a single domain tobuilduptheirownuserIDsystemsacrossanumberoftheirclientwebsites SSP强制发送一个重定向请求，该重定向请求带上新网站的cookie IDcookie-sync发生在竞价之后而不是之前的原因主要是考虑到时延和用户体验。如果用户user123 需要访问10个DSP， 等待所有的DSP为自己创建cookie并将SSP cookie ID 和 DSP cookie ID的映射保存到DSP自己的数据库中，然后在开始广告竞价，这将显著地延缓整个竞价过程。 in step (1), the browser makes a request from the pixel tag to ad.bidder.com and includes in this request any tracking cookies set by ad.bidder.com. If the user is new to ad.bidder.com, it sets its ad.bidder.com cookie. In step (2), the tracker from ad.bidder. com retrieves its tracking ID from the cookie and, instead of returning the required 1x1 pixel, redirects the browser to ad.exchange.com using http 302 redirect and encoding the tracking ID into the URL as a parameter. (3) The browser then makes a request to ad.exchange.com, which includes thefullURLad.bidder.comredirectedtoaswellas ad.exchange.com’sown trackingcookie(ifoneexists). (4)ad.exchange.comreturnstherequired1x1 pixel and can now link its own ID associated with the user to ad.bidder. com’s ID and create a record in its match table. 广义二阶定价次价密封投标拍卖：出最高价者所得，但支付价格是第二个开价人做开的价格。优点：传统的竞价的最优出价都取决于他对其他人出价的预期，所以常常不会展示自己对拍卖物的真实评价。 占优策略的定义：在不考虑其他竞标者如何竞价的情况下，占优策略是对竞价者更有利的策略。 降低出价的定义：指竞价者对商品的出价低于他们认为真正合理的估值。在程序化交易中，这个商品就是指广告展示机会。 哈佛大学工商管理专业副教授Benjamin Edelman在题为《Internet Advertising and the Generalized Second Price Auction: Selling Billions of Dollars Worth of Keywords》中的研究报告中指出，“讲真话”来源于传统的次高价投标拍卖以及在搜索广告中被广泛使用的VGC拍卖。 哥伦比亚大学商科助理教授Santiago Balseiro在《Competition and Yield Optimization in Ad Exchange》中表示，在次高价投标拍卖中，“讲真话”对于广告主而言可能并不是一个占优策略。 竞价愿景预测(bid landscape forecasting)是指对于给定的一个广告计划,预测出不同价格能够竞价到的流量的分布。广告定向特征通常有url, 媒体, 广告位置，用户信息，地理位置信息等 百度DSP开发手册：https://cloud.baidu.com/doc/DSP/Pricing.html#.E8.AE.A1.E8.B4.B9.E8.A7.84.E5.88.99-1 文献Books/Monographs Display Advertising with Real-Time Bidding (RTB) and Behavioural Targeting by Jun Wang, Weinan Zhang and Shuai Yuan. ArXiv 2016. Tutorials Learning, Prediction and Optimisation in RTB Display Advertising by Weinan Zhang and Jian Xu. CIKM 2016. Real-Time Bidding based Display Advertising: Mechanisms and Algorithms by Jun Wang, Shuai Yuan and Weinan Zhang. ECIR 2016. Real-Time Bidding: A New Frontier of Computational Advertising Research by Shuai Yuan and Jun Wang. WSDM 2015. Research Frontier of Real-Time Bidding based Display Advertising by Weinan Zhang. Beijing 2015. Review Papers A Survey on Real Time Bidding Advertising by Yong Yuan. Service Operations and Logistics 2014. Real-time Bidding for Online Advertising: Measurement and Analysis by Shuai Yuan, Jun Wang, Xiaoxue Zhao. ADKDD 2013. Ad Exchanges: Research Issues by S. Muthukrishnan. Internet and network economics 2009. Demand-Side Platform (DSP) TechniquesCTR/CVR Estimation A Nonparametric Delayed Feedback Model for Conversion Rate Prediction by Yuya Yoshikawa and Yusaku Imai. ArXiv 2018. Robust Factorization Machines for User Response Prediction by Surabhi Punjabi and Priyanka Bhatt. WWW 2018. Field-weighted Factorization Machines for Click-Through Rate Prediction in Display Advertising by Junwei Pan et al. WWW 2018. Deep &amp; Cross Network for Ad Click Predictions by Ruoxi Wang et al. ADKDD &amp; TargetAd 2017. Ranking and Calibrating Click-Attributed Purchases in Performance Display Advertising by Sougata Chaudhuri et al. ADKDD 2017. A Practical Framework of Conversion Rate Prediction for Online Display Advertising by Quan Lu et al. ADKDD 2017. An Ensemble-Based Approach to Click-Through Rate Prediction for Promoted Listings at Etsy by Kamelia Aryafar et al. ADKDD 2017. Deep Interest Network for Click-Through Rate Prediction by Guorui Zhou et al. ArXiv 2017. DeepFM: A Factorization-Machine based Neural Network for CTR Prediction by Huifeng Guo et al. IJCAI 2017 Learning Piece-wise Linear Models from Large Scale Data for Ad Click Prediction by Kun Gai, Xiaoqiang Zhu, Han Li, et al. Arxiv 2017. SEM: A Softmax-based Ensemble Model for CTR Estimation in Real-Time Bidding Advertising by Wen-Yuan Zhu et al. BigComp 2017. Neural Feature Embedding for User Response Prediction in Real-Time Bidding (RTB) by Enno Shioji, Masayuki Arai. ArXiv 2017. Field-aware Factorization Machines in a Real-world Online Advertising System by Yuchin Juan, Damien Lefortier, Olivier Chapelle. ArXiv 2017. Product-based Neural Networks for User Response Prediction by Yanru Qu et al. ICDM 2016. Sparse Factorization Machines for Click-through Rate Prediction by Zhen Pan et al. ICDM 2016. Deep CTR Prediction in Display Advertising by Junxuan Chen et al. MM 2016. Bid-aware Gradient Descent for Unbiased Learning with Censored Data in Display Advertising by Weinan Zhang, Tianxiong Zhou, Jun Wang, Jian Xu. KDD 2016. Large Scale CVR Prediction through Dynamic Transfer Learning of Global and Local Features by Hongxia Yang et al. BIGMINE 2016. Predicting ad click-through rates via feature-based fully coupled interaction tensor factorization by Lili Shan, Lei Lin, Chengjie Sun, Xiaolong Wang. Electronic Commerce Research and Applications 2016. Simple and Scalable Response Prediction for Display Advertising by Olivier Chapelle Criteo, Eren Manavoglu, Romer Rosales. ACM TIST 2014. Cost-sensitive Learning for Utility Optimization in Online Advertising Auctions by Flavian Vasile, Damien Lefortier, Olivier Chapelle. Extension under-review of the paper presented at the Workshop on E-Commerce, NIPS 2015. User Response Learning for Directly Optimizing Campaign Performance in Display Advertising by Kan Ren, Weinan Zhang, Yifei Rong, Haifeng Zhang, Yong Yu, Jun Wang. CIKM 2016. A Convolutional Click Prediction Model by Qiang Liu, Feng Yu, Shu Wu, Liang Wang. CIKM 2015. Factorization Machines with Follow-The-Regularized-Leader for CTR prediction in Display Advertising by Anh-Phuong Ta. BigData 2015. Deep Learning over Multi-field Categorical Data: A Case Study on User Response Prediction by Weinan Zhang, Tianming Du, Jun Wang. ECIR 2016. Offline Evaluation of Response Prediction in Online Advertising Auctions by Olivier Chapelle. WWW 2015. Predicting Response in Mobile Advertising with Hierarchical Importance-Aware Factorization Machine by Richard J. Oentaryo et al. WSDM 2014. Scalable Hierarchical Multitask Learning Algorithms for Conversion Optimization in Display Advertising by Amr Ahmed et al. WSDM 2014. Estimating Conversion Rate in Display Advertising from Past Performance Data by Kuang-chih Lee et al. KDD 2012. Scalable Hands-Free Transfer Learning for Online Advertising by Brian Dalessandro et al. KDD 2014. Evaluating and Optimizing Online Advertising: Forget the click, but there are good proxies by Brian Dalessandro et al. SSRN 2012. Modeling Delayed Feedback in Display Advertising by Olivier Chapelle. KDD 2014. Ad Click Prediction: a View from the Trenches by H. Brendan McMahan. KDD 2013. Practical Lessons from Predicting Clicks on Ads at Facebook by Xinran He et al. ADKDD 2014. Bid Landscape Predicting Winning Price in Real Time Bidding with Censored Data by Wush Chi-Hsuan Wu, Mi-Yen Yeh, Ming-Syan Chen. KDD 2015. Handling Forecast Errors While Bidding for Display Advertising by Kevin J. Lang, Benjamin Moseley, Sergei Vassilvitskii. WWW 2012. Bid Landscape Forecasting in Online Ad Exchange Marketplace by Ying Cui et al. KDD 2011. Functional Bid Landscape Forecasting for Display Advertising by Yuchen Wang et al. ECML-PKDD 2016. Bidding Strategies Optimal Bidding Strategy for Brand Advertising by Takanori Maehara et al. IJCAI 2018. Bidding Machine: Learning to Bid for Directly Optimizing Profits in Display Advertising by Kan Ren et al. TKDE 2018. Budget Constrained Bidding by Model-free Reinforcement Learning in Display Advertising by Di Wu et al. ArXiv 2018. Real-Time Bidding with Multi-Agent Reinforcement Learning in Display Advertising by Junqi Jin et al. ArXiv 2018. Deep Reinforcement Learning for Sponsored Search Real-time Bidding by Jun Zhao et al. ArXiv 2018. LADDER: A Human-Level Bidding Agent for Large-Scale Real-Time Online Auctions by Yu Wang et al. ArXiv 2017. Improving Real-Time Bidding Using a Constrained Markov Decision Process by Manxing Du et al. ADMA 2017. Attribution Modeling Increases Efficiency of Bidding in Display Advertising by Eustache Diemert et al. ADKDD 2017. Profit Maximization for Online Advertising Demand-Side Platforms by Paul Grigas et al. ArXiv 2017. Real-Time Bidding by Reinforcement Learning in Display Advertising by Han Cai et al. WSDM 2017. Managing Risk of Bidding in Display Advertising by Haifeng Zhang et al. WSDM 2017. Optimized Cost per Click in Taobao Display Advertising by Han Zhu et al. ArXiv 2017. Combining Powers of Two Predictors in Optimizing Real-Time Bidding Strategy under Constrained Budget by Chi-Chun Lin et al. CIKM 2016. Joint Optimization of Multiple Performance Metrics in Online Video Advertising by Sahin Cem Geyik et al. KDD 2016. Optimal Real-Time Bidding for Display Advertising by Weinan Zhang. PhD Thesis 2016. Bid-aware Gradient Descent for Unbiased Learning with Censored Data in Display Advertising by Weinan Zhang, Tianxiong Zhou, Jun Wang, Jian Xu. KDD 2016. Lift-Based Bidding in Ad Selection by Jian Xu et al. AAAI 2016. Feedback Control of Real-Time Display Advertising by Weinan Zhang et al. WSDM 2016. Optimal Real-Time Bidding Strategies by Joaquin Fernandez-Tapia, Olivier Guéant, Jean-Michel Lasry. ArXiv 2015. Programmatic Buying Bidding Strategies with Win Rate and Winning Price Estimation in Real Time Mobile Advertising by Xiang Li and Devin Guan. PAKDD 2014. Statistical modeling of Vickrey auctions and applications to automated bidding strategies by Joaquin Fernandez-Tapia. Working paper. Statistical Arbitrage Mining for Display Advertising by Weinan Zhang, Jun Wang. KDD 2015. Real-Time Bidding rules of thumb: analytically optimizing the programmatic buying of ad-inventory by Joaquin Fernandez-Tapia. SSRN 2015. Optimal Real-Time Bidding for Display Advertising by Weinan Zhang, Shuai Yuan, Jun Wang. KDD 2014. Bid Optimizing and Inventory Scoring in Targeted Online Advertising by Claudia Perlich et al. KDD 2012. Real-Time Bidding Algorithms for Performance-Based Display Ad Allocation by Ye Chen et al. KDD 2011. Budget Pacing &amp; Frequency/Recency Capping Exploring Optimal Frequency Caps in Real Time Bidding Advertising by Rui Qin et al. SocialCom 2016. Research on the Frequency Capping Issue in RTB Advertising：A Computational Experiment Approach by Rui Qin et al. CAC 2015. From 0.5 Million to 2.5 Million: Efficiently Scaling up Real-Time Bidding by Jianqian Shen et al. ICDM 2015. Smart Pacing for Effective Online Ad Campaign Optimization by Jian Xu et al. KDD 2015. An analytical solution to the budget-pacing problem in programmatic advertising by Joaquin Fernandez-Tapia. Working paper. Adaptive Targeting for Online Advertisement by Andrey Pepelyshev, Yuri Staroselskiy, Anatoly Zhigljavsky. Machine Learning, Optimization, and Big Data 2015. Real Time Bid Optimization with Smooth Budget Delivery in Online Advertising by Kuang-Chih Lee, Ali Jalali, Ali Dasdan. ADKDD 2013. Budget Pacing for Targeted Online Advertisements at LinkedIn by Deepak Agarwal et al. KDD 2014. Frequency Capping in Online Advertising by Niv Buchbinder et al. WADS 2011. Adaptive bidding for display advertising by Ghosh, A., Rubinstein, B. I, Vassilvitskii, S., and Zinkevich, M. 2009 Fraud Detection Independent Auditing of Online Display Advertising Campaigns by Patricia Callejo et al. HotNets 2016. Using Co-Visitation Networks For Classifying Non-Intentional Traffic by Ori Stitelman et al. Dstillery 2013. Impression Fraud in On-line Advertising via Pay-Per-View Networks by Kevin Springborn, Paul Barford. USENIX Security Symposium 2013. Understanding Fraudulent Activities in Online Ad Exchanges by Brett Stone-Grosset et al. IMC 2011. Market Segmentation Optimizing the Segmentation Granularity for RTB Advertising Markets with a Two-stage Resale Model By Rui Qin et al. SMC 2016. Optimizing Market Segmentation Granularity in RTB Advertising: A Computational Experimental Study by Rui Qin et al. SocialCom 2016. Analyzing the Segmentation Granularity of RTB Advertising Markets：A Computational Experiment Approach by Rui Qin et al. SMP 2015. Supply-Side Platform (SSP) Techniques Learning Algorithms for Second-Price Auctions with Reserve by Mehryar Mohri and Andres Munoz Medina. JMLR 2016. Optimal Reserve Prices in Upstream Auctions: Empirical Application on Online Video Advertising by Miguel Angel Alcobendas, Sheide Chammas and Kuang-chih Lee. KDD 2016. Optimal Allocation of Ad Inventory in Real-Time Bidding Advertising Markets by Juanjuan Li et al. SMC 2016. A Dynamic Pricing Model for Unifying Programmatic Guarantee and Real-Time Bidding in Display Advertising by Bowei Chen, Shuai Yuan and Jun Wang. ADKDD 2014. An Empirical Study of Reserve Price Optimisation in Real-Time Bidding by Shuai Yuan et al. KDD 2014. Information Disclosure in Real-Time Bidding Advertising Markets by Juanjuan Li, Yong Yuan, Rui Qin. SOLI 2014. Data Management Platform (DMP) Techniques A Sub-linear, Massive-scale Look-alike Audience Extension Systemby Qiang Ma, Musen Wen, Zhen Xia, Datong Chen. KDD 2016 / PMLR 2016 Audience Expansion for Online Social Network Advertising by Haishan Liu et al. KDD 2016. Implicit Look-alike Modelling in Display Ads: Transfer Collaborative Filtering to CTR by Weinan Zhang, Lingxi Chen, Jun Wang. ECIR 2016. Pleasing the advertising oracle: Probabilistic prediction from sampled, aggregated ground truth by Melinda Han Williams et al. ADKDD 2014. Focused matrix factorization for audience selection in display advertising by Kanagal B et al. ICDE 2013. Conversion Attribution Learning Multi-touch Conversion Attribution with Dual-attention Mechanisms for Online Advertising by Kan Ren, Yuchen Fang, Weinan Zhang, et al. CIKM 2018. Additional Multi-Touch Attribution for Online Advertising by Wendi Ji, et al. AAAI 2017. Multi-Touch Attribution in Online Advertising with Survival Theory by Ya Zhang, Yi Wei, and Jianbiao Ren. ICDM 2014. Multi-Touch Attribution Based Budget Allocation in Online Advertising by Sahin Cem Geyik, Abhishek Saxena, Ali Dasdan. ADKDD 2014. Causally Motivated Attribution for Online Advertising. by Brian Dalessandro et al. ADKDD 2012. Data-driven Multi-touch Attribution Models. by Xuhui Shao, Lexin Li. KDD 2011. Ad Exchanges, Mechanisms and Game Theory Truthfulness with Value-Maximizing Bidders: On the Limits of Approximation in Combinatorial Markets by Salman Fadaei and Martin Bichler. EJOR 2016. Repeated Auctions with Budgets in Ad Exchanges: Approximations and Design by Santiago R. Balseiro, Omar Besbesy, Gabriel Y. Weintraub. Management Science 2015. Ad Exchange: Intention Driven Auction Mechanisms for Mediating Between Publishers and Advertisers by Rina Azoulay, Esther David. WI/IAT 2015. Pricing Externalities in Real-Time Bidding Markets by Joseph Reisinger, Michael Driscoll. Machine Learning in Online Advertising. Competition between Demand-Side Intermediaries in Ad Exchanges by Lampros C. Stavrogiannis. PhD Thesis 2014. Auction Mechanisms for Demand-Side Intermediaries in Online Advertising Exchanges by Lampros C. Stavrogiannis, Enrico H. Gerding, Maria Polukarov. AMMAS 2014. Optimal Revenue-Sharing Double Auctions with Applications to Ad Exchanges by Renato Gomes, Vahab Mirrokni. WWW 2014. Competition and Yield Optimization in Ad Exchanges by Santiago R. Balseiro. PhD Thesis 2013. Selective Call Out and Real Time Bidding by Tanmoy Chakraborty. WINE 2010. Privacy Selling Off Privacy at Auction by Lukasz Olejnik, Tran Minh-Dung, Claude Castelluccia. NDSS 2014. Network Analysis of Third Party Tracking: User Exposure to Tracking Cookies through Search by Richard Gomer et al. WI 2013. Systems Finding Needle in a Million Metrics: Anomaly Detection in a Large-scale Computational Advertising Platform by Bowen Zhou, Shahriar Shariat. TargetAd 2016. Datasets and Benchmarking YOYI RTB datasets (with bidding information) by Kan Ren and Yifei Rong et al. CIKM 2016. iPinYou Global RTB Bidding Algorithm Competition Dataset by Hairen Liao et al. ADKDD 2014. Real-Time Bidding Benchmarking with iPinYou Dataset by Weinan Zhang et al. ArXiv 2014. Criteo Dataset for Product Recommendation / Counterfactual Learning by Damien Lefortier et al. What If workshop NIPS 2016. Criteo Conversion Logs Dataset by Criteo Labs. Criteo Terabyte Click Logs by Criteo Labs. Avazu Click Prediction by Avazu.]]></content>
      <categories>
        <category>演讲稿展示</category>
        <category>算法</category>
      </categories>
      <tags>
        <tag>入门教程</tag>
        <tag>算法</tag>
        <tag>技术分享</tag>
        <tag>RTB</tag>
        <tag>DSP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FastDFS安装]]></title>
    <url>%2F2018%2F%E8%BF%90%E7%BB%B4%2FFastDFS%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[安装安装 libfastcommonlibfastcommon是 FastDFS 中的公共 C 函数库，基础环境。下载编译安装git clone https://github.com/happyfish100/libfastcommon.gitcd libfastcommon./make.sh install 创建软链接（好像主要是因为FastDFS主程序设置的lib目录而非lib64目录导致，不过没尝试不清楚）ln -s /usr/lib64/libfastcommon.so /usr/local/lib/libfastcommon.soln -s /usr/lib64/libfdfsclient.so /usr/local/lib/libfdfsclient.soln -s /usr/lib64/libfdfsclient.so /usr/lib/libfdfsclient.so 安装 FastDFS下载编译安装 FastDFS:git clone https://github.com/happyfish100/fastdfs.gitcd fastdfs./make.sh install 配置 FastDFS]]></content>
      <categories>
        <category>技术博文</category>
        <category>系统运维</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>分布式存储</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用crontab运行定时任务]]></title>
    <url>%2F2018%2F%E8%BF%90%E7%BB%B4%2F%E7%94%A8crontab%E8%BF%90%E8%A1%8C%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[以一个Python项目的定时任务为例： 先写好一个run.sh脚本:#!/bin/bash/bin/echo "the script start `date`" &gt;&gt; /home/shikanon/log/log.txtsource venv/bin/activatepython getMinuteData.py 然后编写crontab文件，crontab文件结构如下：# Example of job definition:# .---------------- minute (0 - 59)# | .------------- hour (0 - 23)# | | .---------- day of month (1 - 31)# | | | .------- month (1 - 12) OR jan,feb,mar,apr ...# | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat# | | | | |# * * * * * user-name command to be executed 创建crontab文件:&gt; vim getData.cron&gt; 0 16 * * * /home/shikanon/download/getData/run.sh 表示每天16点运行一次/home/shikanon/download/getData/run.sh命令 创建任务crontab getData.cron查看用户所有任务crontab -l删除当前用户所有任务crontab -r编辑当前用户下的任务crontab -e，当结束编辑离开时，编辑后的文件将自动安装。 更多例子： (注意单纯echo，从屏幕上看不到任何输出，因为cron把任何输出都email到root的信箱了。) 每天早上6点执行一次&gt; 0 6 * * * echo "hello world" &gt;&gt; /tmp/test.txt 每两个小时执行一次&gt; 0 */2 * * * echo "hello world" &gt;&gt; /tmp/test.txt 23点到8点之间每两个小时执行一次&gt; 0 23-7/2 * * * echo "hello world" &gt;&gt; /tmp/test.txt 23点到8点之间每两个小时执行一次，同时8点执行一次&gt; 0 23-7/2，8 * * * echo "hello world" &gt;&gt; /tmp/test.txt 每个月的4号11点执行一次，同时每个周的周一到三11点执行一次&gt; 0 11 4 * 1-3 echo "hello world" &gt;&gt; /tmp/test.txt 每天的下午4点、5点、6点的5 min、15 min、25 min、35 min、45 min、55 min时执行一次&gt; 5，15，25，35，45，55 16，17，18 * * * echo "hello world" &gt;&gt; /tmp/test.txt]]></content>
      <categories>
        <category>技术博文</category>
        <category>系统运维</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pandas 高性能优化小技巧]]></title>
    <url>%2F2018%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2FPandas-%E9%AB%98%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%B0%8F%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[背景Pandas 对于Pythoner的搞数据分析的来说是常用的数据操作库，对于很多刚接触Pandas的人来说会发现它是一个很方便而且好用的库，它提供了各种数据变化、查询和操作，它的dataframe数据结构和R语言、Spark的dataframe的API基本一样，因此上手起来也非常简单。但是很多新手在使用过程中会发现pandas的dataframe的性能并不是很高，而且有时候占用大量内存，并且总喜欢将罪名归于Python身上(lll￢ω￢)，今天我这里给大家总结了在使用Pandas的一些技巧和代码优化方法。 1.使用Pandas on Ray Pandas on Ray 主要针对的是希望在不切换 API 的情况下提高性能和运行速度的 Pandas 用户。Pandas on Ray 实现了Pandas 的大部分API 功能，可已作为Pandas的一个子集，其主要是利用并行化进行加速。 Pandas on Ray 既可以以多线程模式运行，也可以以多进程模式运行。Ray 的默认模式是多进程，它可以从一台本地机器的多个核心扩展到一个机器集群上。在通信方面，Ray 使用共享内存，并且通过 Apache Arrow 实现零拷贝串行化，显著降低了进程之间的通信代价。 Ray 将根据可用内核的数量进行自动初始化,以一个1.8GB的全球健康数据为例 import ray.dataframe as pdimport pandas as old_pdprint("Pandas on Ray:")%time pandas_on_ray = pd.read_csv"midyear_population_age_country_code.csv")# Pandasprint("\nPandas:")%time pandas_native = old_pd.read_csv("midyear_population_age_country_code.csv") 输出结果:Pandas on Ray:CPU times: user 48.5 ms, sys: 19.1 ms, total: 67.6 msWall time: 68 msPandas:CPU times: user 49.3 s, sys: 4.09 s, total: 53.4 sWall time: 54.3 s Pandas on Ray主要是通过并线化来加速，就和Spark一样， 1.1使用iterrows或者apply代替直接对dataframe遍历 用过Pandas的都知道直接对dataframe进行遍历是十分低效的，当需要对dataframe进行遍历的时候我们可以使用迭代器iterrow代替。 import pandas as pdimport timedf = pd.read_csv('输出结果_总量_迁出.csv',encoding='gbk',engine='python')def loop_test(df): result = list() for i in range(len(df)): result.append(df.iloc[i]['迁出量']) return resultdef loop_iterrows_test(df): result = list() for index, row in df.iterrows(): result.append(row['迁出量']) return resultprint('loop directly...')%time result = loop_test(df)print('loop with iterrows...')%time result = loop_iterrows_test(df) 输出结果loop directly...Wall time: 29.2 sloop with iterrows...Wall time: 10.6 s 实验证明iterrow的效果在三倍以上。 1.2apply方法dataframe是一种列数据，apply对特定的轴计算做了优化,在针对特定轴（行/列）进行运算操作的时候，apply的效率甚至比iterrow更高. def loop_iterrows_test(df): result = list() for index, row in df.iterrows(): result.append(row['汽车百分比']+row['火车百分比']) return resultdef loop_apply_test(row): return row['汽车百分比']+row['火车百分比']print('func iterrows test...')%time df['iterrow'] = loop_iterrows_test(df)print('func apply test...')%time df['apply'] = df.apply(loop_apply_test,axis=1) 结果输出func iterrows test...Wall time: 12.3 sfunc apply test...Wall time: 3.8 s apply函数比iterrow提高了4倍 1.3直接使用内置函数进行计算Dataframe、Series具有大量的矢量函数，比如sum,mean等，基于内置函数的计算可以让性能更好，比如:%time df['add'] = df['汽车百分比']+df['火车百分比'] 输出结果Wall time: 546 ms 我们可以看到性能又往上提高了近6倍。 因此，我们在使用pandas进行计算的时候，如果可以使用内置的矢量方法计算最好选用内置方法，其次可以考虑apply方法，如果对于非轴向的循环可以考虑iterrow方法。 2.数据类型优化 Pandas的内存使用率一直被大家抱怨，特别对于初学者，当机器资源不足的时候，经常会发现相比其他的数据结构，Pandas存储的数据很容易就会爆掉。 在底层的设计中，pandas按照数据类型将列分组形成数据块（blocks）。pandas使用ObjectBlock类来表示包含字符串列的数据块，用FloatBlock类来表示包含浮点型列的数据块。对于包含数值型数据（比如整型和浮点型）的数据块，pandas会合并这些列，并把它们存储为一个Numpy数组（ndarray）。Numpy数组是在C数组的基础上创建的，其值在内存中是连续存储的。基于这种存储机制，对其切片的访问是相当快的。 df.info(memory_usage='deep')&lt;class 'pandas.core.frame.DataFrame'&gt;RangeIndex: 307870 entries, 0 to 307869Data columns (total 16 columns):起点城市 307870 non-null object起点城市代码 307870 non-null int64起点城市lng 291690 non-null float64起点城市lat 291690 non-null float64终点城市 307870 non-null object终点城市代码 307870 non-null object终点城市lng 304000 non-null object终点城市lat 304000 non-null object日期 307870 non-null object迁出量 307870 non-null int64汽车百分比 307870 non-null float64火车百分比 307870 non-null float64飞机百分比 307870 non-null float64iterrow 307870 non-null float64apply 307870 non-null float64add 307870 non-null float64dtypes: float64(8), int64(2), object(6)memory usage: 151.5 MB 2.1 子类型优化数值型列pandas中的许多数据类型具有多个子类型，比如，float型就有float16、float32和float64子类型,分别使用了2、4、8个字节。 我们可以用函数pd.to_numeric()来对数值型进行向下类型转换。用DataFrame.select_dtypes来只选择特定类型列，然后我们优化这种类型，并比较内存使用量。 df_int = df.select_dtypes(include=['float'])converted_int = df_int.apply(pd.to_numeric, downcast='float')print(df_int.dtypes.iloc[0],df_int.memory_usage(deep=True).sum())print(converted_int.iloc[0].dtypes,converted_int.memory_usage(deep=True).sum()) 输出结果float64 19703760float32 9851920 实验表明,float32比float64整好优化了一半内存 2.2 用category类型代替object类型object类型用来表示用到了Python字符串对象的值，有一部分原因是Numpy缺少对缺失字符串值的支持。因为Python是一种高层、解析型语言，它没有提供很好的对内存中数据如何存储的细粒度控制。 这一限制导致了字符串以一种碎片化方式进行存储，消耗更多的内存，并且访问速度低下。在object列中的每一个元素实际上都是存放内存中真实数据位置的指针。 category类型在底层使用整型数值来表示该列的值，而不是用原值。Pandas用一个字典来构建这些整型数据到原数据的映射关系。当一列只包含有限种值时，这种设计是很不错的。当我们把一列转换成category类型时，pandas会用一种最省空间的int子类型去表示这一列中所有的唯一值。 object数据类型 category数据类型 实验输入：df_object = df.select_dtypes(include=['object'])print(df_object.columns) 输出结果Index(['起点城市', '终点城市', '终点城市代码', '终点城市lng', '终点城市lat', '日期'], dtype='object') 输入down_cast_cols = df_object['起点城市'].astype('category')print('before...')print(df_object['起点城市'].memory_usage(deep=True))print('after...')print(down_cast_cols.memory_usage(deep=True)) 输出before...28885690after...659649 可以看出效果是非常明显的，压缩了近30倍的内存空间~ 这种基于类型的优化我们一般在数据载入的时候就可以进行自定义了，这样即可以大大的节省内存的空间。 df_origin = pd.read_csv('输出结果_总量_迁出.csv',encoding='gbk',engine='python')converted_df = pd.read_csv('输出结果_总量_迁出.csv',encoding='gbk',engine='python', dtype=&#123;'起点城市': 'category', '终点城市': 'category', '终点城市代码':'category', '终点城市代码': 'category', '汽车百分比': 'float32', '火车百分比':'float32', '飞机百分比': 'float32', &#125;, parse_dates=['日期'])print('No optimization... ')print(int(df_origin.memory_usage(deep=True).sum() / 1024))print('After optimization ....')print(int(converted_df.memory_usage(deep=True).sum() / 1024)) 输出结果No optimization... 147934After optimization ....35437 原始结果内存147M，优化后35M，内存优化了近四倍 3. 总结对于Pands的优化还有很多，这里主要介绍三种最常用的优化方法，一种是对于数据量极大的情况，可以使用Pandas on Ray 或者 Dask 优化，第二种是对于在运算的时候采用自定义的矢量迭代函数代替for循环可以取得显著的性能提升，第三种方法是通过对存储类型的设置或转换来优化pandas内存使用。 github地址]]></content>
      <categories>
        <category>技术博文</category>
        <category>编程语言</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>入门教程</tag>
        <tag>算法</tag>
        <tag>性能优化</tag>
        <tag>Pandas</tag>
        <tag>数据处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过jpg图片隐藏文件]]></title>
    <url>%2F2018%2F%E5%AE%89%E5%85%A8%2F%E9%80%9A%E8%BF%87jpg%E5%9B%BE%E7%89%87%E9%9A%90%E8%97%8F%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[比如我们现在有一个视频Video.mkv，我们想隐藏它，那么我们可以找一张背景图片谣言.jpg，把他们放在同一目录下： 将Video.mkv打包成压缩包Video.rar，为什么要打包呢？因为这是为后面解压服务得~ 在该目录下编写bat文件：copy /b 谣言.jpg+Video.rar 谣言2.jpg 双击运行压缩.bat，我们可以看到目录下生成了一张谣言2.jpg的图片，看看大小，整合等于压缩包文件和图片文件总和~ 最后，那如何还原原文件呢？？很简单，直接将文件后缀改为rar压缩包文件进行解压就可以了，因为rar解压有个专属的开始位置，解压程序会读到开始位置的标识符才执行解压程序，应该前面的jpg二进制会被忽略。 当然如果你希望获得更强大的加密可以自己编写加密解密策略。 附上Python代码：github地址加密#coding:utf-8import clickimport random@click.command()@click.option('--background', prompt=True, help='输入用于隐藏的背景图片文件.')@click.option('--encryptfile', prompt=True, help='输入需要加密的文件.')def encryptfile(background, encryptfile): seed = random.randint(1024, 2048) seeds = [] for i in range(seed): seeds.append(random.randint(1, 128)) confusion = bytes(seeds) with open(background, 'rb') as fr_bg: bg_body = fr_bg.read() with open(encryptfile, 'rb') as fr_enc: enc_body = fr_enc.read() confusion_bytes_index = random.randint(1, len(enc_body)//2) objectfile = "encry_%d_%d_%d_"%(len(bg_body), len(confusion), confusion_bytes_index) + background data = bg_body + confusion + enc_body[confusion_bytes_index:] + confusion + enc_body[:confusion_bytes_index] print(len(bg_body)+len(confusion)) print(len(enc_body[confusion_bytes_index:])) print(len(enc_body[:confusion_bytes_index])) print(len(bg_body)+2*len(confusion)+len(enc_body[confusion_bytes_index:])) print(len(data)) with open(objectfile, "wb") as fw_obf: fw_obf.write(data)if __name__ == "__main__": encryptfile() 解密：#coding:utf-8import click@click.command()@click.option('--inputfile', prompt=True, help='输入文件名及路径.')@click.option('--outputfile', prompt=True, help='输出文件名及路径.')def decryptFile(inputfile, outputfile): decryptfile = outputfile encryptfile = inputfile encrypt = encryptfile.split("_") bg_length, confuse_length, confusion_bytes_index = int(encrypt[1]), int(encrypt[2]), int(encrypt[3]) headerindex = bg_length + confuse_length with open(decryptfile, "wb") as fw: with open(encryptfile, "rb") as fr: data = fr.read() frist_data_num = len(data)-(headerindex + confusion_bytes_index + confuse_length) frist_data = data[-confusion_bytes_index:] second_data = data[headerindex:headerindex+frist_data_num] print(headerindex + confusion_bytes_index + confuse_length) print(len(frist_data),len(second_data)) fw.write(frist_data+second_data)if __name__ == "__main__": decryptFile()]]></content>
      <categories>
        <category>技术博文</category>
        <category>信息安全</category>
      </categories>
      <tags>
        <tag>信息安全</tag>
        <tag>加密&amp;解密</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gitlab CI/CD (上)]]></title>
    <url>%2F2018%2F%E8%BF%90%E7%BB%B4%2Fgitlab-CI-CD%2F</url>
    <content type="text"><![CDATA[githook本地Hook本地 Hook 只影响它们所在的仓库。以下是最常用的 6 个本地 Hook： pre-commit prepare-commit-msg commit-msg post-commit post-checkout pre-rebase前四个 Hook 介入到版本提交的生命周期，后两个允许执行一些额外的操作，分别为 git checkout 和 git rebase 的安全检查。所有与带 pre- 的 Hook 代表即将发生的某个阶段，带 post- 只用于通知。 pre-commitpre-commit 脚本在每次你运行 git commit 命令时，Git 向你询问提交信息或者生产提交对象时被执行。你可以用这个 Hook 来价差即将被提交的代码快照。比如说，你可以运行一些自动化测试，保证这个提交不会破坏现有的功能。 prepare-commit-msgprepare-commit-msg这个 Hook 在 pre-commit Hook 在文本编辑器中生效提交信息之后被调用。prepare-commit-msg 的参数可以是下列三个： 包含提交信息的文件名。你可以在原地更改提交信息。提交类型。可以是信息（-m 或 -F 选项），模板（-t选项），merge（如果是个合并提交）或squash（如果这个提交插入了其他提交）。相关提交的SHA1哈希字串。只有当-c，-C，或–amend选项出现时才需要。 post-commitpost-commit Hook 在 commit-msg Hook 之后立即被运行。它无法改变 git commit的结果，主要用于通知。这里我们详细来讲述一下这个 Hook ，因为我们之后要用到它。 这个脚本没有任何参数，而且退出状态不会影响提交。对于大多数的 post-commit 脚本来说，你只是想访问你刚刚创建的提交。你可以用 git rev-parse HEAD来获得最近一次提交的 SHA1 哈希字符串，或者你可以用 git log -l HEAD 来获得完整的信息。 post-checkoutpost-checkout Hook 和 post-commit Hook 很像，但它在你用 git checkout查看引用的时候被调用。 gitlab runner docker 运行docker run -d --name gitlab-runner \ -v /srv/gitlab-runner/config:/home/gitlab-runner \ -v /var/run/docker.sock:/var/run/docker.sock \ gitlab/gitlab-runner gitlab-runner注册输入:gitlab-ci-multi-runner register 这里主要是需要两个信息进行注册，一个是gitlab的url，和runner token。可以在gitlab CI/CD 的Runners settings中Specific Runners找到，如下所示： Please enter the gitlab-ci coordinator URL (e.g. https://gitlab.com )https://172.17.0.2 (因为我这里gitlab是放在dockder下面因此需要改成docker内网地址)Please enter the gitlab-ci token for this runnerkpSL7ViitQLYbSs3zS1xPlease enter the gitlab-ci description for this runnermy-runnerINFO[0034] fcf5c619 Registering runner... succeededPlease enter the executor: shell, docker, docker-ssh, ssh?shell gitlab-runner 运行检查runner的状态：gitlab-ci-multi-runner verify 重启所有runner：gitlab-ci-multi-runner run 重启单个runner：gitlab-ci-multi-runner run-single --url https://172.17.0.2 --token runnerToken --executor shell gitlab-runner运行成功界面 需要在gitlab-runner环境下按照运行所需要 git 修改注释并强制提交新记录仅修改注释git commit --amend git 强制提交远程分支git push --force &lt;远程地址&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt;]]></content>
      <categories>
        <category>技术博文</category>
        <category>系统运维</category>
      </categories>
      <tags>
        <tag>gitlab</tag>
        <tag>持续集成</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[公司内部区块链技术入门培训]]></title>
    <url>%2F2018%2F%E6%9E%B6%E6%9E%84%2F%E5%85%AC%E5%8F%B8%E5%86%85%E9%83%A8%E5%8C%BA%E5%9D%97%E9%93%BE%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8%E5%9F%B9%E8%AE%AD%2F</url>
    <content type="text"><![CDATA[演示稿（图文版） 区块链入门简介（文字版）区块链背景传统的数据库管理系统问题： （1）由单一机构管理和维护,在多方参与者协作的场景中,因无法完全信任数据库中的数据。 （2） 每方都需要单独构建一套承载自己业务数据的数据库,多方数据库间的数据差异会导致繁琐的人工对账和争议。 区块链是一种利用分布式数据存储、点对点传输、共识机制、加密算法等计算机技术构建的一种去中心化、 不可篡改、 可追溯、 多方共同维护的分布式数据库（区块链本质上看成一种数据库，任何需要保存的信息，都可以写入区块链，也可以从里面读取） 区块链最早起源于比特币的设计，是比特币的底层技术和基础架构。 1、去中心化：由大量节点共同组成的一个点对点网络，不存在中心化的硬件或管理机构。在网络中，每一个节点的义务和权利都是均等的。系统中所有节点都参与数据的记录和验证，将计算结果通过分布式传播发送给各个节点。在部分节点遭受损坏的情况下，整个系统的运作并不会收到影响，相当于每个参与的节点都是“自中心”。 2、基于共识建立信任。区块链理论最大的颠覆性在于新的信用形成机制。在传统的互联网模式中，陌生人之间是通过可信任的第三方机构（如银行，国家）来建立信用和进行交易。 而区块链技术从根本上改变了中心化的信用创建方式，它运用了一套基于共识的数学算法，在机器之间建立“信任”网络，从而通过技术背书而非中心化信用。通过这种机制，参与方不必知道交易的对象是谁，更不需要借助第三方机构来进行交易背书或者担保验证，而只需要信任共同的算法就可以建立互信，通过算法为参与者创造信用、产生信任和达成共识。 3、信息不可篡改。区块链是基于时间戳形成的不可篡改、不可伪造的数据库。区块（完整历史） 与链（完整验证）相加便形成了时间戳。时间戳存储在网络中所执行的所有交易历史，可为每一笔数据提供检索和查找功能，并可借助区块链结构追本溯源，逐笔验证。每个参与者在记账并生成区块时都加上时间戳，并广播到全网节点，让每个参与节点都能获得一份完整数据库的拷贝，一旦信息经过验证添加到区块链上，就会永久的存储起来。根据“少数服从多数”原则，从概率上讲，要篡改历史信息，必须同时控制整个系统中超过50%的节点。因此区块链技术认为其系统的数据可靠性很高，且参与系统中的节点越多和计算能力越强，该系统中的数据安全性越高。 基本概念区块链，顾名思义，是由区块(Block)和链(Chain)组成的。 区块（Block）：区块很像数据库的记录，每次写入数据，就是创建一个区块。 链（Chain）：每个区块都连着上一个区块，形成链条式的数据结构记录所有的信息。 区块链技术是一种解决信任问题、降低信任成本的信息技术方案。通过区块链技术，互联网上的各个用户成为一个节点并相互连接起来，所有在此区块链架构上发布的内容都会在加密后被每一个节点接收并备份，换而言之每一个节点都可以查看历史上产生的任何数据。各节点将加密数据不断打包到区块中，再将区块发布到网络中，并按照时间顺序进行连接，生成永久、不可逆向的数据链，这便形成了一个公开透明的受全部用户的监督的区块链。 区块链的运作流程运行区块链的基本流程： 新的交易操作（transaction）向全网进行广播； 通过共识算法（Consensus Algorithm）选择leader将交易操作写入一个区块(block)； 写入区块被其他节点认可和接受。 区块链特点区块链特点：（1）去中心化。（2）高可信。（3）不可篡改。（4）可追溯。（5）高可用。 共识算法Paxos算法阶段一：寻值阶段 （a）Proposer选择一个提案编号N，然后向半数以上的Acceptor发送编号为N的Prepare请求。 (b) 如果一个Acceptor收到一个编号为N的Prepare请求，且N大于该Acceptor已经响应过的所有Prepare请求的编号，那么它就会将它已经接受过的编号最大的提案（如果有的话）作为响应反馈给Proposer，同时该Acceptor承诺不再接受任何编号小于N的提案。 阶段二：提案阶段 (a) 如果Proposer收到半数以上Acceptor对其发出的编号为N的Prepare请求的响应，那么它就会发送一个针对[N,V]提案的Accept请求给半数以上的Acceptor。注意：V就是收到的响应中编号最大的提案的value，如果响应中不包含任何提案，那么V就由Proposer自己决定。 (b) 如果Acceptor收到一个针对编号为N的提案的Accept请求，只要该Acceptor没有对编号大于N的Prepare请求做出过响应，它就接受该提案。 Raft算法Raft算法是一种和Paxos算法一样的分布式一致性协议。（Raft的优势就是容易理解和实现，可以少出错误~~） Raft的工作模式是一个Leader和多个Follower模式，其安排了三种角色： (1)Leader: 处理所有客户端交互，日志复制等，一般一次只有一个Leader. (2)Follower: 类似选民，完全被动 (3)Candidate：候选人。 Raft算法分为两各阶段： 第一个阶段是选举领导人； 第二阶段是由领导人对其他节点对一致性的操作。 选举阶段： （1）初始状态时所有server都处于Follower状态，并且随机睡眠一段时间，最先醒来的server A进入Candidate状态 （2）Candidate状态的server A有权利发起投票，向其它所有server发出请求，请求其它server给它投票成为Leader。 （3）当其它server收到请求后，将自己仅有的一票投给server A，同时继续保持Follower状态并重置选举计时器。 （4）当server A收到大多数（超过一半以上）server的投票后，就进入Leader状态，成为系统中仅有的Leader。 传统共识算法缺陷传统分布式数据库主要使用 Paxos 和 Raft 算法解决分布式一致性问题,虽然它可以解决报文可能发生丢失和延时等问题，但面对拜占庭问题的时候，决策就可能混乱，即其假定系统中每个节点都是忠诚、不作恶的。 但这对于处于公有链上的，有着大量不可信任节点的分布式数据库来说是一种灾难，会遇到各类问题，比如拜占庭问题、女巫攻击问题等。 区块链共识算法公有链的区块链共识算法主要包括：工作量证明机制(Proof of Work, POW)权益证明机制(Proof of Stake, POS)。股份授权证明机制(Delegated Proof of Stake, DPOS) PoW工作量证明机制（PoW），其机制是通过工作量的大小来决定Leader，即工作量证明，被leader打包的区块可以获得整个网络的认可。工作量主要指算力，即计算设备每秒能进行哈希运算的次数。一台设备的算力在全网算力中所占的比重即由这台设备创建新区块(挖矿)的概率。PoW 机制可有效应对女巫攻击,其依靠分布式节点间的算力竞争来保证全网区块链数据的一致性和安全性。 PoW 机制将经济激励与共识过程相融合,促使更多节点参与挖矿并保持诚信,从而主动增强了网络的可靠性与安全性。 流程： 1、每笔新交易被广播到区块链网络的所有节点。 2、为了构建新的区块,每个节点收集自前一区块生成以来接收到的所有交易,并根据这些交易计算出区块头部的 Merkle 根。将区块头部的随机数 Nonce 从 0 开始递增加 1,直至区块头的两次SHA256 哈希值小于或等于难度目标的设定值为止。 3、全网节点同时参与计算,若某节点先找到了正确的随机数,则该节点将获得新区块的记账权及奖励,并将该区块向全网广播。 4、其它节点接收到新区块后,验证区块中的交易和随机数 Nonce 的有效性,如果正确,就将该区块加入本地的区块链,并基于该块开始构建下一区块。 分叉问题分叉问题：若多个区块同时被创建就会引起分叉问题。 解决方案： （1）比特币采用确定主链，忽视分支的方法。当发生分叉时,最长的链即花费了最多算力的链被认为是主链,其它则被认为是分支,分支中的所有交易会被忽略。比特币将分支结点上的区块称为孤块,并会将其作为废块而丢弃。一般地，比特币假定在6个区块生成以后可以确定交易。 （2）以太坊采用GHOST协议处理。GHOST 协议认为分支上的有效区块对确认主链上的交易也有贡献,因而没有丢弃该区块,而是将该区块作为叔块并给予相当主块 87.5%的奖励,给予叔块的直接子块相当主块 12.5%的奖励,矿工每引用一个叔块给予相当主块 3%的奖励。 为了适应硬件技术的快速发展及计算能力的不断提升,比特币每 2016 块就会调整一次难度目标,以控制区块的平均生成时间（10 分钟） 始终保持不变。 PoS股权证明和工作量证明一样，是一种用于公有链的共识算法，其根据矿工在区块链中拥有的股权（数字货币量） 来决定其挖矿的难度。 Casper共识算法Casper共识是以太坊基于 PoS 机制提出。Casper 以智能合约的方式实现，根据抵押的以太币数量和时间,成比例的分配区块的记账权和奖励。与 PoS 机制不同,Casper 还引入了惩罚措施,一旦发现某个矿工作弊,其抵押的所有以太币将全被罚没,参与共识和出块的权利也会被取消。 基于Casper 共识的以太坊一个区块的挖矿时间为4秒，而比特币则需要10分钟。 DPoS股份授权证明机制（DPOS）采用“股份投票”的方式决定谁来生成区块。它的原理是让每一个持有“股份”的人进行投票，由此产生N个超级节点或者矿池，而这N个超级节点彼此的权利是完全相等的。从某种角度来看，DPOS有点像是议会制度或人民代表大会制度。如果代表不能履行他们的职责（当轮到他们时，没能生成区块），他们会被除名，网络会选出新的超级节点来取代他们。 EOS使用DPOS共识机制 PBFT实用拜占庭容错机制（PBFT）是一种状态机副本复制算法，状态机在分布式系统的不同节点进行副本复制。每个状态机的副本都保存了服务的状态，同时也实现了服务的操作。在保证活性和安全性的前提下提供了(n-1)/3的容错性。 PBFT算法流程： 1.客户端向主节点发送请求调用服务操作 2.主节点通过广播将请求发送给其他副本 3.所有副本都执行请求并将结果发回客户端 4.客户端需要等待f+1个不同副本节点发回相同的结果，作为整个操作的最终结果。 共识算法小结（1）公有链的共识算法，均需要“代价”作为支撑，比如工作量、股权。 （2）对于私有链来说，其和传统的分布式数据一样，采用paxos算法和Raft 算法即可。 （3）“因地制宜”最重要，根据不同的场景采用不同的共识算法解决问题。 智能合约智能合约是用程序语言编写的商业合约,在预定条件满足时,能够自动强制的执行合同条款,实现“代码即法律” 的目标。 （1）依照商业逻辑编写完智能合约代码后,需要将其发布到区块链网络节点上。（2）调用涉及到修改操作,需要先在全网达成共识,之后修改操作会被记录在区块链，修改结果会被存在状态数据库。调用查询操作，则无需共识,也不需被记录在区块链上。（3）智能合约支持合约内部事件的注册与通知机制，外部应用与智能合约间的关系非常类似于传统数据库应用与存储过程间的关系,存储过程运行于数据库管理系统之中,访问关系数据库数据,而智能合约运行于区块链系统之中,访问区块和状态数据。 智能合约是运行在区块链上的一段计算机程序,其扩展了区块链的功能,丰富了区块链的上层应用。依照商业逻辑编写完智能合约代码后,需要将其发布到区块链网络节点上。在以太坊中,部署后的合约存放在区块链上,每次被调用时才被以太坊虚拟机（EVM）加载运行；在 Hyperledger Fabric 中,部署后的合约被打包成 Docker 镜像,每个节点基于该镜像启动一个新的 Docker 容器并执行合约中的初始化方法，然后等待被调用。外部应用通过调用智能合约来实现各种交易,如果调用涉及到修改操作,需要先在全网达成共识,之后修改操作会被记录在区块链，修改结果会被存在状态数据库（例如,转账交易的转账金额会被记录到区块链,账户余额的增减会被应用到状态数据库）。如果调用仅包含查询操作，则无需共识,也不需被记录在区块链上。智能合约还支持合约内部事件的注册与通知机制,从而可主动向外部应用通知合约内部发生的关键事件。智能合约目前只能访问链内数据,无法主动监听并响应 可扩展性区块链想要真正做到更深度化的应用和普及，关键就是要解决交易的吞吐量和交易的速度问题。区块链（公有链）的吞吐量和交易速度一直是区块链发展和应用的关键技术瓶颈。交易数量增加导致比特币区块已经接近1MB容量的92%，如果你经常浏览区块链相关的信息，你一定知道比特币交易开始变得拥堵，在社区中对于是扩容还是侧链的讨论喋喋不休。你肯定也知道就连以太坊也因《CryptoKitties》这款养猫游戏没能逃掉网络拥堵的命运。 现有的主流的可扩展性解决方案可分为三种侧链技术(SideChains)、分片技术(Sharing)和有向无环图（DAG）。 解决方案侧链（Side Chains）是通过在外部搭建一个新的交易通道嫁接到主链，从而解决扩容问题。侧链的一个典型就是比特币的闪电网络（Lighting Network）：A和B两人可以把比特币放到一个多重签名钱包中锁定（链下），然后进行交易签名更改双方各自能取回的比特币数量。交易参与方可以随时关闭交易通道，最后一笔经过签名且包含最新余额动态的交易最终将会被广播并写入比特币区块链。 分片其实是一种传统数据库的技术，它将大型数据库分成更小、更快、更容易管理的部分。分片技术可以理解为在将主链在内部进行切分。现在用了分片技术的主要有以太坊的sharing和EOS的Region。 以太坊分片机制介绍以太坊依据账户地址将全网划分为多个相对独立的分片， 每个分片内维护一条独立子链， 用户可自行选择在哪个分片执行自己的交易， 每个节点根据自身的计算和存储能力选择加入一到多个分片， 并处理和存储这些分片上的交易。 全网节点分工配合以覆盖到所有分片， 如果需要访问本节点没有的交易数据， 则利用轻客户端技术从其它分片节点读取。 全网节点可并行的处理和存储不同的交易数据， 使得全网交易处理能力不再受限于单一节点， 单一节点也不需处理、 存储全部数据。 DAG有向无环图（Directed Acyclic Graph，DAG）是一种数据结构，不同于传统区块链的底层数据结构Blockchain设计，其通过数据单元之间的引用来完成交易的确认。 流程： （1）客户端自主异步地提交一个数据单元，客户端采用点对点互相校验 （2）通过数据单元之间的引用来完成交易的确认，后面发生的单元去引用前面的单元。 （3）数据单元间通过引用关系链接起来，从而形成具有半序关系的DAG （4）通过特定的方法选择“主链” ， “主链”确立了，才把“双花”检测出来剔除，在确定“主链”以前它是一个并行验证的操作，而且是并行往数据结构上放。（“主链”的选择采用共识算法进行确定） 目前采用DAG作为存储结构的代表项目有dagcoin、Byteball、Iota。 展望区块链虽有去中心化的特性，但很多线上业务的纠纷无法离开中心来解决。因此区块链的真正价值在于促进各行各业的中心化机构之间达成共识，构建联盟，形成多个中心组成的商业生态圈，这样的生态系统突出了中心的职能，大大简化了中心化机构运营成本。]]></content>
      <categories>
        <category>演讲稿展示</category>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>入门教程</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[生活小技能：科学地股票选股策略]]></title>
    <url>%2F2018%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2F%E7%94%9F%E6%B4%BB%E5%B0%8F%E6%8A%80%E8%83%BD%EF%BC%9A%E8%82%A1%E7%A5%A8%E9%80%89%E8%82%A1%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[多种选股策略介绍1.1 彼得林奇PEG价值选股策略策略思路: 1.选择PEG &lt; 0.5, 即稳定成长且价值被低估的股票 其中PEG = PE / growth_rate2.使用ES风险平价配权3.根据组合的日内波动小于3%的条件, 与货币基金组合配资4.最大持仓5只股票和1只货币基金, 优先买入市值小的, 15天调仓一次5.剔除了周期性和项目类行业(该部分对改善回撤有明显的效果) 1.2 詹姆斯.奥肖内西价值投资法策略选股 A. 股票的市值大于市场的中位数B. 股票的股本大于市场的中位数C. 股票的市现率大于0，从小到大排列，取前400只股票D. 股票的市销率大于0，从小到大排列，取前400只股票E. 股票的股息率从大到小排列，取前400只股票F. 取上述5个条件满足下的前30只股票 交易方式：按月调仓 止损方式A. 当个股价格低于成本价的7%时，卖出该股票B. 当5日内大盘下跌13%时，卖出所有股票 1.3 阿梅特·欧卡莫斯集中投资法则A 三年平均营业收入成长率大于市场平均值的60%B.三年平均税后利润成长率大于市场平均值的60%C 三年平均自由现金流量成长率大于市场平均值的60%D ROE 大于市场平均值的60%E 管理层持股比例增加或者高于市场平均值的60%（缺少数据）F 市净率小于4.0 倍G 市盈率小于30 倍H 满足上述条件下股票池中前30只股票 交易方式：按月调仓 止损方式:A. 当个股价格低于成本价的7%时，卖出该股票B. 当5日内大盘下跌13%时，卖出所有股票 1.4 本杰明格雷厄姆企业主投资法策略选股: A．股票的市盈率大于0，且选取市盈率最低的400只股票B．股票的市净率大于0且小于2.5，且选取市净率最低的400只股票C．企业的流动资产至少是流动负债的1.2 倍D．企业的总借款不超过净流动资产的1.5 倍E．企业净利润大于0F．最近一期现金股利大于0G．净利润增长率从大到小排序，选取前400只股票H. 满足于上述7个条件下的前30只股票 交易方式：按月调仓 止损方式:A. 当个股价格低于成本价的7%时，卖出该股票B. 当5日内大盘下跌13%时，卖出所有股票 1.5 史蒂夫·路佛价值选股法则策略选股: A 市净率大于0且低于全市场平均值，股票按市净率从小到大排列B.市盈率大于0且低于全市场平均值，股票按市盈率从小到大排列C 流动资产至少是总市值的30%D 股价现金流量比大于0且低于全市场平均值，股票按股价现金流量从小到大排列E 长期借款占总资本比率低于50%F 流动比率高于全市场平均值,股票按流动比率从大到小排列G 满足上述条件下股票池中前30只股票 交易方式：按月调仓 止损方式:A. 当个股价格低于成本价的7%时，卖出该股票B. 当5日内大盘下跌13%时，卖出所有股票 1.6戴维•波伦价值型系统评价投资法策略选股: 1) 总市值 ＞ 市场平均值；2) 产权比率（负债/股东权益） ＜ 市场平均值；3) 每股企业自由现金流量 ＞ 市场平均值；4) 股价/每股自由现金流量 ＜ 市场平均值；5)（ROE）均大于市场平均值；6) 净利润同比增长率均大于市场平均值；7) 投入资本回报率 ＞ 市场平均值；8) 投入资本回报率 ＞ 市场基准利率。(3.5%)9) 选取符合以上条件的前30只股票 交易方式：按月调仓 止损方式:A. 当个股价格低于成本价的7%时，卖出该股票B. 当5日内大盘下跌13%时，卖出所有股票 1.7 三一投资管理公司价值选股策略具体策略 一、每月作为调仓周期，选取符合以下条件的股票进入投资组合：选取本益比最低的前400公司股价账面价值比最低的前400公司股利收益率最高的前400公司 为了控制每期选出的股票数，我们增加如下条件：若选出股票超过30 个，选取前30个进入组合。 二、止损方式当个股价格低于成本价的8%时，卖出该股票当5日内大盘下跌13%时，卖出所有股票 1.8 查尔斯.布兰德价值投资策略策略选股 A. 股票负债净值比小于80%B. 股票的市盈率不高于市场平均值1.5 倍C. 股票的股价/近四季现金流量（市现率）不高于市场平均值的1.5 倍D. 股票的市净率不高于市场平均值的1.5 倍E. 股票的市净率小于2.0 倍F. 满足于上述条件下的前30只股票 交易方式：按月调仓 止损方式A. 当个股价格低于成本价的7%时，卖出该股票B. 当5日内大盘下跌13%时，卖出所有股票 1.9 迈克尔•普莱斯低估价值选股策略策略选股: A 股价与每股净值比小于2，且选取市净率最低的400只股票B 董监事持股比例大于市场平均值(缺失该数据)C 负债比例低于市场平均值D. 满足于上述条件下的前30只股票 交易方式：按月调仓 止损方式:A. 当个股价格低于成本价的7%时，卖出该股票B. 当5日内大盘下跌13%时，卖出所有股票 爬虫爬虫数据： （1）采集沪股通及深股通持股纪录，存入数据库中，每天更新http://sc.hkexnews.hk/TuniS/www.hkexnews.hk/sdw/search/mutualmarket_c.aspx?t=sh （2）同花顺里面的龙虎榜名单http://data.10jqka.com.cn/market/longhu/#refCountId=data_55f13c7e_426 （3）同花顺里面的公司财报信息。http://stockpage.10jqka.com.cn/000807/finance/#finance?qq-pf-to=pcqq.c2c （4）采集公司的融资融券及其历史信息http://stockpage.10jqka.com.cn/000807/#lhb?qq-pf-to=pcqq.c2c #coding:utf-8import scrapy, json,iofrom scrapy.selector import Selectorfrom scrapy.http import Request, FormRequestfrom StockRecord.items import StockrecordItemimport datetime, re, requestsimport collectionsfrom urllib.parse import urlencode, quote_plusclass Scrapy(scrapy.Spider): name = 'stockrecord' allow_domain = ['http://sc.hkexnews.hk/'] start_urls =['http://sc.hkexnews.hk/TuniS/www.hkexnews.hk/sdw/search/mutualmarket_c.aspx?t=sh'] def parse(self,response): with open('index.html','wb')as f: f.write(response.body) url = 'http://sc.hkexnews.hk/TuniS/www.hkexnews.hk/sdw/search/mutualmarket_c.aspx?t=sh' EVENTVALIDATION = response.xpath("//*[@id='__EVENTVALIDATION']/@value").extract() VIEWSTATE = response.xpath("//*[@id='__VIEWSTATE']/@value").extract() VIEWSTATEGENERATOR = response.xpath("//*[@id='__VIEWSTATEGENERATOR']/@value").extract() today = response.xpath("//*[@id='today']/@value").extract() sortBy = response.xpath("//*[@id='sortBy']/@value").extract() alertMsg = response.xpath("//*[@id='alertMsg']/@value").extract() formdata =&#123;&#125; for i in range(1): # formdata['__VIEWSTATE'] =re.findall(r'&lt;input type="hidden" name="__VIEWSTATE" id="__VIEWSTATE" value="(.*?)" /&gt;',sourepage.text)[0] # formdata['__EVENTVALIDATION'] = re.findall(r'&lt;input type="hidden" name="__EVENTVALIDATION" id="__EVENTVALIDATION" value="(.*?)" /&gt;',sourepage.text)[0] # formdata['__VIEWSTATEGENERATOR'] = 'EC4ACD6F' formdata['__VIEWSTATE'] =VIEWSTATE[0] formdata['__EVENTVALIDATION'] = EVENTVALIDATION[0] formdata['__VIEWSTATEGENERATOR'] = VIEWSTATEGENERATOR[0] formdata['today'] = today[0] formdata['sortBy']= '' formdata['alertMsg']= '' start_time = datetime.date(2017, 3, 17) + datetime.timedelta(i) formdata['ddlShareholdingDay'] = str(start_time.day) formdata['ddlShareholdingMonth'] = str(start_time.month) formdata['ddlShareholdingYear'] = str(start_time.year) formdata['btnSearch.x'] = '32' formdata['btnSearch.y'] = '11' # print (formdata) data = urlencode(formdata,quote_via=quote_plus) print (data) # formdata = &#123;'ddlShareholdingDay':'17','ddlShareholdingMonth':'03','ddlShareholdingYear':'2017'&#125; return Request(url,self.parse_result, method="POST",headers=&#123;'User-Agent':'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.108 Safari/537.36'&#125;,body=json.dumps(data)) # yield FormRequest.from_response(response,method='POST',formdata=formdata, callback=self.parse_result) # print ('result',result) # return result def parse_result(self, response): items = [] # print('页面',response.text) with open('test.html','wb')as f: f.write(response.body) sel = Selector(response=response).css('#pnlResult &gt; table') table_date = Selector(response=response).css('#pnlResult &gt; div:nth-child(1)::text').extract()[0].strip().split(':')[-1] table = sel.css('td::text').extract() all_data = list(map(lambda x: x.strip(), table)) every_line_data = [all_data[i:i + 4] for i in range(0, len(all_data), 4)] items=[] for every_line in every_line_data: item = StockrecordItem() item['date']= table_date item['code'] = every_line[0] item['name'] = every_line[1] item['shareholding'] = every_line[2] item['percentage'] = every_line[3] items.append(item) # print('结果:&#123;&#125;'.format(items)) print (items) # return items abupy策略代码# coding: utf-8# In[1]:import abupyfrom abupy import EMarketDataFetchModefrom abupy import AbuMetricsBasefrom abupy import EDataCacheTypefrom abupy import EMarketTargetTypefrom abupy import AbuDoubleMaBuy, AbuDoubleMaSellfrom abupy import AbuPositionBasefrom abupy import abu# In[2]:# **AbuFactorBuyBreak**(N日趋势突破策略)趋势突破定义为当天收盘价格超过N天内的最高价或最低价，超过最高价格作为买入信号买入股票持有，超过最低价格作为卖出信号。# # **AbuFactorAtrNStop**(止盈止损策略)真实波幅atr作为最大止盈和最大止损的常数值,当stop_loss_n 乘以 当日atr &gt; 买入价格 － 当日收盘价格：止损卖出;当stop_win_n 乘以 当日atr &lt; 当日收盘价格 －买入价格：止盈卖出# # **AbuFactorPreAtrNStop**(风险控制止损策略)使用真实波幅atr作为常数值: 当今日价格下跌幅度 &gt; 当日atr 乘以 pre_atr_n（下跌止损倍数）卖出股票# # **AbuFactorCloseAtrNStop**(利润保护止盈策略) atr移动止盈策略，当买入股票有一定收益后，如果股价下跌幅度超过close_atr_n乘以当日atr：则保护止盈卖出# In[2]:from abupy import AbuFactorBuyBreak, AbuFactorAtrNStop, AbuFactorPreAtrNStop, AbuFactorCloseAtrNStop# In[3]:# 初始化资金20万read_cash = 200000# 买入因子使用60日向上和42日突破因子buy_factors = [&#123;'xd': 60, 'class': AbuFactorBuyBreak&#125;, &#123;'xd': 42, 'class': AbuFactorBuyBreak&#125;]# 趋势跟踪策略止盈要大于止损设置值，这里1.0，3.0# 卖出因子并行生效sell_factors = [ &#123;'stop_loss_n': 1.0, 'stop_win_n': 3.0, 'class': AbuFactorAtrNStop&#125;, &#123;'class': AbuFactorPreAtrNStop, 'pre_atr_n': 1.5&#125;, &#123;'class': AbuFactorCloseAtrNStop, 'close_atr_n': 1.5&#125;]# In[4]:# 回测生成买入时刻特征abupy.env.g_enable_ml_feature = True# 回测开始时将symbols切割分为训练集数据和测试集两份，使用训练集进行回测#abupy.env.g_enable_train_test_split = True# In[5]:# 很多交易细节还是使用的默认设置中的美股交易模式，因此需要将环境设置为A股abupy.env.g_market_target = EMarketTargetType.E_MARKET_TARGET_CN# In[6]:# 择时股票池choice_symbols = ['002230', '000725', '300059', '601766', '600085', '600036', '600809', '000002', '002594', '002739', '601388', '601919', '600307', '000725', '601880', '000100','601168']# **针对A股涨停和跌停的特殊设置打开**# In[7]:from abupy import slippage# 开启针对非集合竞价阶段的涨停，滑点买入价格以高概率在接近涨停的价格买入slippage.sbb.g_enable_limit_up = True# 将集合竞价阶段的涨停买入成功概率设置为0，如果设置为0.2即20%概率成功买入slippage.sbb.g_pre_limit_up_rate = 0# 开启针对非集合竞价阶段的跌停，滑点卖出价格以高概率在接近跌停的价格卖出slippage.ssb.g_enable_limit_down = True# 将集合竞价阶段的跌停卖出成功概率设置为0, 如果设置为0.2即20%概率成功卖出slippage.ssb.g_pre_limit_down_rate = 0# **自定义手续费**# In[8]:def buy_commission_ch(trade_cnt, price): """ 计算交易费用：每股0.001块，，最低消费1块；交易佣金：最高收费为3‰，最低收费5元；印花税：1‰ :param trade_cnt: 交易的股数 :param price: 每股的价格 :return: 计算结果手续费 """ # 每股手续费0.01 transfer_fees = trade_cnt * 0.001 commission = price*trade_cnt*0.0003 if transfer_fees &lt; 1: transfer_fees = 1 if commission &lt; 5: # 最低消费2.99 commission = 5 return transfer_fees+commissiondef sell_commission_ch(trade_cnt, price): """ 计算交易费用：每股0.001块，，最低消费1块；交易佣金：最高收费为3‰，最低收费5元；印花税：1‰ :param trade_cnt: 交易的股数 :param price: 每股的价格 :return: 计算结果手续费 """ # 每股手续费0.01 transfer_fees = trade_cnt * 0.001 commission = price*trade_cnt*0.0003 stamp_duty = price*trade_cnt*0.001#算一半，因为只有卖出才收 if transfer_fees &lt; 1: transfer_fees = 1 if commission &lt; 5: commission = 5 return transfer_fees+commission+stamp_duty# In[9]:# 卖出字典key='sell_commission_func', 指向同一个手续费方法，当然也可以定义不同的方法commission_dict = &#123;'buy_commission_func': buy_commission_ch, 'sell_commission_func': sell_commission_ch&#125;# In[13]:# 使用run_loop_back运行策略abu_result_tuple, kl_pd_manger = abu.run_loop_back(read_cash, buy_factors, sell_factors, n_folds=8, commission_dict=commission_dict, choice_symbols=choice_symbols)# In[14]:AbuMetricsBase.show_general(*abu_result_tuple, only_show_returns=True)# **仓位管理**# # 应用kelly公式来做仓位控制# In[15]:metrics = AbuMetricsBase(*abu_result_tuple)# In[16]:metrics.fit_metrics()# In[17]:metrics.win_rate# In[10]:class AbuKellyPosition(AbuPositionBase): """示例kelly仓位管理类""" def fit_position(self, factor_object): """ fit_position计算的结果是买入多少个单位（股，手，顿，合约） 需要factor_object策略因子对象通过历史回测统计胜率，期望收益，期望亏损， 并设置构造当前factor_object对象，通过kelly公司计算仓位 :param factor_object: ABuFactorBuyBases子类实例对象 :return:买入多少个单位（股，手，顿，合约） """ # 败率 loss_rate = 1 - self.win_rate # kelly计算出仓位比例 kelly_pos = self.win_rate - loss_rate / (self.gains_mean / self.losses_mean) # 最大仓位限制，依然受上层最大仓位控制限制，eg：如果kelly计算出全仓，依然会减少到75%，如修改需要修改最大仓位值 kelly_pos = self.pos_max if kelly_pos &gt; self.pos_max else kelly_pos # 结果是买入多少个单位（股，手，顿，合约） return self.read_cash * kelly_pos / self.bp * self.deposit_rate def _init_self(self, **kwargs): """kelly仓位控制管理类初始化设置""" # 默认kelly仓位胜率0.445 self.win_rate = kwargs.pop('win_rate', 0.445) # 默认平均获利期望0.1338 self.gains_mean = kwargs.pop('gains_mean', 0.1338) # 默认平均亏损期望0.06959 self.losses_mean = kwargs.pop('losses_mean', 0.06959)# In[20]:# 买入因子使用60日向上和42日突破因子buy_factors_sec = [&#123;'xd': 60, 'class': AbuFactorBuyBreak&#125;, &#123;'xd': 42, 'class': AbuFactorBuyBreak, 'position': &#123;'class': AbuKellyPosition, 'win_rate': metrics.win_rate, 'gains_mean': metrics.gains_mean, 'losses_mean': -metrics.losses_mean&#125;,&#125;]# In[21]:# 使用run_loop_back运行策略abu_result_tuple, kl_pd_manger = abu.run_loop_back(read_cash, buy_factors_sec, sell_factors, n_folds=8, commission_dict=commission_dict, choice_symbols=choice_symbols)# In[22]:AbuMetricsBase.show_general(*abu_result_tuple, only_show_returns=True)# In[23]:metrics = AbuMetricsBase(*abu_result_tuple)metrics.plot_max_draw_down()# ## 当天行为动作# In[24]:action_result_pd = abu_result_tuple.action_pdaction_result_pd[action_result_pd['Date']==20180124]# In[25]:result_orders_pd = abu_result_tuple.orders_pdresult_orders_pd[result_orders_pd['buy_date']==20180124]# **买入动作重写**# # 构建一个保守买入算法，以开盘价和最高价的平均值作为买入,而不是两者均值# In[26]:from abupy import AbuSlippageBuyBase, slippageimport numpy as npclass AbuSlippageBuyMean2(AbuSlippageBuyBase): """示例日内滑点均价买入类""" @slippage.sbb.slippage_limit_up def fit_price(self): """ 取当天交易日的最高最低均价做为决策价格 :return: 最终决策的当前交易买入价格 """ g_open_down_rate = 0.02 # TODO 基类提取作为装饰器函数，子类根据需要选择是否装饰，并且添加上根据order的call，put明确细节逻辑 if self.kl_pd_buy.pre_close == 0 or (self.kl_pd_buy.open / self.kl_pd_buy.pre_close) &lt; (1 - g_open_down_rate): # 开盘就下跌一定比例阀值，放弃单子 return np.inf # 买入价格为当天均价，即最高，最低的平均，也可使用高开低收平均等方式计算 self.buy_price = np.mean([self.kl_pd_buy['open'], self.kl_pd_buy['high']]) # 返回最终的决策价格 return self.buy_price# In[27]:# 买入因子使用60日向上和42日突破因子buy_factors_sec = [&#123;'xd': 60, 'class': AbuFactorBuyBreak,'slippage': AbuSlippageBuyMean2&#125;, &#123;'xd': 42, 'class': AbuFactorBuyBreak, 'slippage': AbuSlippageBuyMean2, 'position': &#123;'class': AbuKellyPosition, 'win_rate': metrics.win_rate, 'gains_mean': metrics.gains_mean, 'losses_mean': -metrics.losses_mean&#125;,&#125;]# In[43]:# 使用run_loop_back运行策略abu_result_tuple, kl_pd_manger = abu.run_loop_back(read_cash, buy_factors_sec, sell_factors, n_folds=8, commission_dict=commission_dict, choice_symbols=choice_symbols)# In[44]:AbuMetricsBase.show_general(*abu_result_tuple, only_show_returns=True)# In[41]:action_result_pd = abu_result_tuple.action_pdaction_result_pd[action_result_pd['Date']==20180124]# **双均线策略**# In[45]:# 买入双均线策略AbuDoubleMaBuy寻找金叉买入信号：ma快线＝5，ma慢线＝20buy_factors = [&#123;'fast': 5, 'slow': 20, 'class': AbuDoubleMaBuy&#125;]# 卖出双均线策略AbuDoubleMaSell寻找死叉卖出信号：ma快线＝5，ma慢线＝20，并行继续使用止盈止损基础策略sell_factors = [&#123;'fast': 5, 'slow': 20, 'class': AbuDoubleMaSell&#125;, &#123;'stop_loss_n': 1.0, 'stop_win_n': 3.0, 'class': AbuFactorAtrNStop&#125;, &#123;'class': AbuFactorPreAtrNStop, 'pre_atr_n': 1.5&#125;, &#123;'class': AbuFactorCloseAtrNStop, 'close_atr_n': 1.5&#125;]# In[46]:abu_result_tuple, kl_pd_manger = abu.run_loop_back(read_cash, buy_factors, sell_factors, n_folds=8, commission_dict=commission_dict, choice_symbols=choice_symbols)# In[47]:AbuMetricsBase.show_general(*abu_result_tuple, only_show_returns=True)# In[23]:action_result_pd = abu_result_tuple.action_pdaction_result_pd[action_result_pd['Date']==20180124]# In[49]:metrics = AbuMetricsBase(*abu_result_tuple)metrics.plot_max_draw_down()# In[12]:buy_factors = [&#123;'fast': 5, 'slow': 20, 'class': AbuDoubleMaBuy&#125;,&#123;'xd': 60, 'class': AbuFactorBuyBreak&#125;, &#123;'xd': 42, 'class': AbuFactorBuyBreak, 'position': &#123;'class': AbuKellyPosition&#125;,&#125;]sell_factors = [&#123;'stop_loss_n': 1.0, 'stop_win_n': 3.0,'class': AbuFactorAtrNStop&#125;, &#123;'class': AbuFactorPreAtrNStop, 'pre_atr_n': 1.5&#125;, &#123;'class': AbuFactorCloseAtrNStop, 'close_atr_n': 1.5&#125;]# In[13]:abu_result_tuple, kl_pd_manger = abu.run_loop_back(read_cash, buy_factors, sell_factors, n_folds=8, commission_dict=commission_dict, choice_symbols=choice_symbols)# In[14]:AbuMetricsBase.show_general(*abu_result_tuple, only_show_returns=True)# In[15]:metrics = AbuMetricsBase(*abu_result_tuple)metrics.plot_max_draw_down()# In[16]:buy_factors = [&#123;'fast': 5, 'slow': 20, 'class': AbuDoubleMaBuy&#125;,&#123;'xd': 60, 'class': AbuFactorBuyBreak&#125;, &#123;'xd': 42, 'class': AbuFactorBuyBreak, 'position': &#123;'class': AbuKellyPosition&#125;,&#125;]sell_factors = [&#123;'class': AbuDoubleMaSell&#125;, &#123;'stop_loss_n': 1.0, 'stop_win_n': 3.0,'class': AbuFactorAtrNStop&#125;, &#123;'class': AbuFactorPreAtrNStop, 'pre_atr_n': 1.5&#125;, &#123;'class': AbuFactorCloseAtrNStop, 'close_atr_n': 1.5&#125;]# In[17]:abu_result_tuple, kl_pd_manger = abu.run_loop_back(read_cash, buy_factors, sell_factors, n_folds=8, commission_dict=commission_dict, choice_symbols=choice_symbols)# In[18]:AbuMetricsBase.show_general(*abu_result_tuple, only_show_returns=True)# In[19]:metrics = AbuMetricsBase(*abu_result_tuple)metrics.plot_max_draw_down()# In[20]:action_result_pd = abu_result_tuple.action_pdaction_result_pd[action_result_pd['Date']==20180124]# In[28]:result_orders_pd = abu_result_tuple.orders_pd# In[44]:result_orders_pd[result_orders_pd['symbol']=='600797']# In[43]:result_orders_pd['symbol'].unique()# In[11]:from abupy import AbuBenchmark, AbuCapital, AbuKLManager# In[ ]:benchmark = AbuBenchmark()capital = AbuCapital(1000000, benchmark)kl_pd_manger = AbuKLManager(benchmark, capital)]]></content>
      <categories>
        <category>生活技能</category>
        <category>股票</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>选股策略</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[专利]一种基于深度孪生网络的人流检测方法]]></title>
    <url>%2F2018%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2F%E4%B8%93%E5%88%A9-%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%AA%E7%94%9F%E7%BD%91%E7%BB%9C%E7%9A%84%E4%BA%BA%E6%B5%81%E6%A3%80%E6%B5%8B%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[全文]]></content>
      <categories>
        <category>技术博文</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>专利</tag>
        <tag>深度学习</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7 下的防火墙 firewall 命令汇总(方便查询)]]></title>
    <url>%2F2018%2F%E8%BF%90%E7%BB%B4%2Fcentos7-%E4%B8%8B%E7%9A%84%E9%98%B2%E7%81%AB%E5%A2%99-firewall-%E5%91%BD%E4%BB%A4%E6%B1%87%E6%80%BB-%E6%96%B9%E4%BE%BF%E6%9F%A5%E8%AF%A2%2F</url>
    <content type="text"><![CDATA[1、firewalld的基本使用启动：systemctl start firewalld 关闭：systemctl stop firewalld 查看状态：systemctl status firewalld 开机禁用 ：systemctl disable firewalld 开机启用 ：systemctl enable firewalld 2.systemctl是CentOS7的服务管理工具中主要的工具，它融合之前service和chkconfig的功能于一体。启动一个服务：systemctl start firewalld.service 关闭一个服务：systemctl stop firewalld.service 重启一个服务：systemctl restart firewalld.service 显示一个服务的状态：systemctl status firewalld.service 在开机时启用一个服务：systemctl enable firewalld.service 在开机时禁用一个服务：systemctl disable firewalld.service 查看服务是否开机启动：systemctl is-enabled firewalld.service 查看已启动的服务列表：systemctl list-unit-files|grep enabled 查看启动失败的服务列表：systemctl --failed 3.配置firewalld-cmd查看版本：firewall-cmd --version 查看帮助：firewall-cmd --help 显示状态：firewall-cmd --state 查看所有打开的端口：firewall-cmd --zone=public --list-ports 更新防火墙规则：firewall-cmd --reload 查看区域信息:firewall-cmd --get-active-zones 查看指定接口所属区域：firewall-cmd --get-zone-of-interface=eth0 拒绝所有包：firewall-cmd --panic-on 取消拒绝状态：firewall-cmd --panic-off 查看是否拒绝：firewall-cmd --query-panic 常用命令添加端口firewall-cmd --zone=public --add-port=80/tcp --permanent （–permanent永久生效，没有此参数重启后失效） 重新载入firewall-cmd --reload 查看端口firewall-cmd --zone=public --query-port=80/tcp 删除端口firewall-cmd --zone=public --remove-port=80/tcp --permanent 查看所有打开的端口firewall-cmd --zone=public --list-ports]]></content>
      <categories>
        <category>技术博文</category>
        <category>系统运维</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>Linux</tag>
        <tag>快捷键</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[https加密协议流量劫持尝试]]></title>
    <url>%2F2017%2F%E5%AE%89%E5%85%A8%2Fhttps%E5%8A%A0%E5%AF%86%E5%8D%8F%E8%AE%AE%E6%B5%81%E9%87%8F%E5%8A%AB%E6%8C%81%2F</url>
    <content type="text"><![CDATA[由越来越多的网页信息改为HTTPS 加密协议，传统的运营商基于DPI的数据获取和广告营销方式已经不可行，需要一种新的方式采集可用数据。 这里以汽车之家为例… （1）通过手机版的数据获取部分DPI信息。 相对网页版，手机版的加密信息相对少些，因此可以以手机版本作为切入，获取用户部分信息。 实验结果： 我们可以看出手机版具有部分数据依然是HTTP格式，比如用户中心还有一些汽车api等，但是大部分的页面已经改为HTTPS格式了。 (2)让浏览器加入特定的根证书实现网络劫持。 导入受信人根证书到浏览器中，劫持客户端向服务器发送的请求，利用受信任证书进行解密。 实验结果： 结论：我们利用SSLSplit导入证书后，可以看出汽车之家的连接已经全部变成明文可解密的连接。 实现方法：可以类似12306的网站，要求用户下载安装根证书，风险是会提示网站证书出错。 （3）利用sslstrip进行HTTPS 向下降级攻击。 将SSL strip将HTTPS请求改为HTTP请求，从而进行中间人攻击。 实现方法：这类方法的实现难度较大，需要作为中间人进行转发，未进行相关实验。]]></content>
      <categories>
        <category>技术博文</category>
        <category>信息安全</category>
      </categories>
      <tags>
        <tag>ssl解密</tag>
        <tag>流量劫持</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习思维导图]]></title>
    <url>%2F2017%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[翻译至dformoso]]></content>
      <categories>
        <category>技术博文</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>算法</tag>
        <tag>思维导图</tag>
        <tag>框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于知识图谱和人工智能驱动的企业深度智能运营和运维平台]]></title>
    <url>%2F2017%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2F%E5%9F%BA%E4%BA%8E%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%92%8C%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E9%A9%B1%E5%8A%A8%E7%9A%84%E4%BC%81%E4%B8%9A%E6%B7%B1%E5%BA%A6%E6%99%BA%E8%83%BD%E8%BF%90%E8%90%A5%E5%92%8C%E8%BF%90%E7%BB%B4%E5%B9%B3%E5%8F%B0%2F</url>
    <content type="text"><![CDATA[项目概述本项目利用知识图谱、深度学习技术，为企业及个人构建企业知识库，从而实现集知识管理、知识发现、知识服务等功能于一身的企业深度智能运营和运维平台，为企业提供知识化、数字化和智能化的管理服务，致力于帮助传统中小企业解决构建自身专业知识库的构建和管理问题，通过开箱即用、人机智能交互的方式提高企业的运营、运维的效率。促进我国对人工智能，知识库领域的核心技术能力，极大推进了人工智能“三步走”战略。 项目必要性、可行性概述知识社会的发展以及学习、生活信息获取环境变化，已逐渐改变了人们的信息获取途径、方式、要求以及知识的管理与应用，如从企业对信息知识的需求变化来看，已呈现出向个性化、学科化、多元化、智能化等方向发展的趋势，并随着以数据密集型为科学研究特征的第四研究范式时代的到来，使得信息知识的需求向数据化、智能化方向的发展特征逐渐明显。对以面向企业提供知识存储、组织与服务的平台来说如何适应社会的发展与企业的知识需求，对其数据的信息知识进行科学的管理，最终实现向企业用户提供专业的个性化、智能化知识，已引起了业界的广泛讨论。 计算机技术与深度学习等技术的发展，推动着社会向自动化、网络化、数字化、智能化方向发展。数据的关联整合、实施跨库检索和元数据集中索引检索等多种更深层次的资源整合技术的出现，也让包括企业数据在内的资源整合、资源检索与知识发现走向了深入，向着语义化、智能化等方向发展。 Google等一站式知识检索、发现、服务系统的出现也为企业知识管理数据化、智能化提出了挑战，如何应用人工智能技术，借鉴Google等服务商，为企业提供集成了知识整合、发现与服务的一站式服务成为了近年来的研究与实践热点。 自2009年Serials Solution公司的Summon知识发现系统问世以来，几年间，包括Primo，Worldcat Local与Encore等在内的越来越多的知识发现系统被开发，并广泛的应用到了图书馆的资源检索、信息组织与知识服务中。 知识图谱(Knowledge Graph)是近年来文本分析和知识组织领域的研究热点，是一种以“语义网络”为基础的新型海量知识管理和服务模式，可支持综合性的知识检索、知识问答、决策支持等智能应用。知识发现服务是近年来知识服务的一个发展趋势，Primo等知识发现系统的开发与应用让知识发现服务走进了图书馆，但目前知识发现服务系统主要是借鉴谷歌等知识服务互联网企业，提供一站式资源检索和获取服务，对个性化知识服务的开发与建设还不完善。基于以上两点，本项目以知识管理，知识发现为视角，对企业用户提供个性化知识服务的开发平台进行了设计与研究。 项目实施的前期准备本项目的实施主要包括了四个部分内容： 第一部分为搭建智能数据采集系统，实现多源数据的采集工作。智能数据采集系统主要将互联网数据通过特点规则采集下来，数据采集系统实现快速低成本开发特定主题网络爬虫，使得爬虫开发技术变成web窗口化界面操作，实现半自动化操作。现阶段已经基本完成了智能数据采集系统的搭建工作，智能数据采集系统已经上线提供试运营，并取得了良好的反馈效果。 第二部分构建基于多源数据的企业知识库。知识图谱自动构建系统主要对特定的文本数据进行处理，使用深度学习技术从而实现命名实体和关系的抽取，并将实体和关系存入图数据库中。 第三部分基于知识库构建知识问答系统。 利用深度学习结合知识库构建智能问答系统，主要包括两个主要部分：(1)利用深度学习技术将自然语言转化为SQL查询语句；(2)利用深度学习训练模型，对查询的异质图数据根据相似度进行排序。 第四阶部分构建智能运营系统与运维管理系统。(1)智能运维管理系统主要针对平台运行日志检测，错误排查，预测维护等功能。可适用应用领域包括交通，电信等。(2)智能运营主要针对产品内容设计、用户行为分析、用户粘度控制、用户销售等。可适用应用领域包括媒体，金融，医疗等。 经过多年行业积累和沉淀，申报单位在人才、资源、成果基础、资金投入等多方面做了大量的前期准备。申报单位聘请了在人工智能与知识图谱方面具有相当丰富的行业经验和较高的行业声望的领军人物—新加坡高级数字科学中心(ADSC)的研究员作为项目技术负责人，带领在人工智能相关专业领域具有一定成就的专业技术人员共同完成。现阶段已经基本完成了智能爬虫平台和大数据分析平台的搭建工作，并且完成基础知识库的构建，同时团队具有大量相关经验人才，在国际顶级期刊和会议发表过50多篇知识图谱及深度学习领域相关论文，在项目实施和推进方面具有强大的执行力。 项目立项依据研究意义，国内外发展现状和趋势随着知识经济的到来，作为其核心价值的知识凸显出了重要的战略地位。如何有效管理知识，使其发挥最大作用，以提高组织的核心竞争力，成为组织重点研究的问题。 从有效参与国内外激烈市场竞争的要求来看，我国广大中小制造企业的技术水平和创新能力与发达国家的跨国公司还是有相当大的距离。例如产业层次比较低，并且企业整体技术创新能力较弱。创新能力与企业利用现有资源和知识的能力密切相关。中小企业一般没有能力开发或购买成熟的、大型的知识管理系统，这使得中小企业与本领域内的优势企业在创新能力方面的差距进一步拉大，形成恶性循环。如果使中小型企业方便、快速地管理知识，已经成为急需解决的问题。为此，本项目提出了一个面向企业，以知识图谱和人工智能为驱动的企业深度智能运营和运维平台。平台集成了知识采集系统，即高效数据爬虫、知识管理系统、基于知识图谱的智能问答系统等，为企业整理、共享、评估内部知识资产提供了稳定高效的平台。 企业拥有大量的数据，主要可分为两大部分，一是以人为核心的数据。例如，对于网站中用户的浏览记录，个人信息等。二是以机器为核心的数据，例如系统运行日志等；这些数据通常包括丰富语义(semantics) 且是关系型数据(relational data)。在对复杂的关系型数据的管理上，知识图谱具备明显的优点。首先，在关联查询的效率上会比传统的存储方式有显著的提高。当涉及2、3度的关联查询，基于知识图谱的查询效率会高出几千倍甚至几百万倍。其次，基于图的存储在设计上会非常灵活，一般只需局部的改动即可。比如有了一个新的数据源，只需要在已有的图谱上插入就可以。与此相反，传统的存储方式灵活性比较差，它所有的Schema都是提前定义好的，如果后续要改变，代价是非常高的。最后，把实体和关系存储在图数据结构是一种符合整个故事逻辑的最好方式，并且可以通过关系进行知识推理。 所以，为了构建企业知识库，从而实现集知识管理、知识发现、知识服务等功能于一身的企业深度智能运营和运维平台，本项目采用知识图谱技术对企业知识数据进行存储、管理。知识图谱的概念由谷歌2012年正式提出，旨在实现更智能的搜索引擎，并且于2013年以后开始在学术界和业界普及，并在智能问答、情报分析、数据管理等应用中发挥作用。知识图谱是一种知识数据的管理方式，通过语义检索技术获取并有机整合多源数据，用于提高搜索引擎的质量。知识图谱本质上是一种语义网络，使用语义网络可以很方便的将自然语言的句子用图来表达和存储，用于机器翻译，问答系统和自然语言理解。知识图谱中的每个节点表达的是现实世界中存在的“实体”，每条边为实体与实体之间的“关系”。也就是说，知识图谱就是把所有不同种类的信息连接在一起而得到的一个关系网络。知识图谱提供了从“关系”的角度去分析问题的能力，也强调了数据驱动应用的概念。通过知识图谱，用户可以快速有效地获取相关知识以及知识之间的逻辑关系，并将不易理解的抽象信息以用户能够理解的可视化方式展示出来，并且能够返回更全面、更丰富的信息。 构建知识图谱的主要目的是获取大量的、让计算机可读的知识。在互联网飞速发展的今天，知识大量存在于非结构化的文本数据、大量半结构化的表格和网页以及生产系统的结构化数据中。基于统计学的方法将从文本中识别实体间关系的问题转化为分类问题。基于统计学的方法在实体关系识别时需要加入实体关系上下文信息确定实体间的关系，常用的方法有监督学习、非监督学习等。 Jain等人在Kambhatla的基础上加入了基本词组块信息和worldNet，使用SVM作为分类器，在实体关系识别的准确率达到了55.5%，实验表明实体类别信息的特征有助于提高关系抽取性能；Zelenko等人使用浅层句法分析树上最小公共子树来表达关系实例，计算两棵子树之间的核函数，通过训练例如SVM模型的分类器来对实例进行分。但基于核函数的方法的问题是召回率普遍较低，这是由于相似度计算过程匹配约束比较严格，因此在后续研究对基于核函数改进中，大部分是围绕改进召回率。但随着时间的推移，语料的增多，深度学习在图像和语言领域获得成功，信息抽取逐渐转向了基于神经网络模型的研究，相关的语料被提出作为测试标准，如SemEval-2010 tast 8。 基于神经网络方法的研究有，Hashimoto等人利用Word Embedding方法从标注语料中学习特定的名称对的上下文特征，然后将该特征加入到神经网络分类器中，在SemEval-2010 task 8上取得F1值82.8%的效果。基于神经网络模型显著的特点是不需要加入太多的特征，一般可用的特征有词向量、位置等。 当企业拥有海量的以用户为核心的数据，以及以机器为核心的日志数据，这种数据作为一种新的生产要素，正在带动业务和管理模式向“数据驱动型”转变，把数据“用活”，深度挖掘数据价值，是目前企业面临的重要挑战和机遇。目前对数据的应用可分为两大类，一是运营数据。即对以人为核心的数据拓展开的业务。例如，用户画像、行为分析、信用分析等；二是运维数据。即以机器为核心的日志数据拓展开的业务。例如，系统检测、检控、基础设施管理等；在传统的自动运营和自动运维中，对于不同的领域使用固定的模式、规则提供运营。在本项目中，当知识图谱来管理数据时，能通过实体与关系进行计算，从而智能推理。因此，对于不同的领域数据，可以通过知识图谱实现智能推理，并且自动制定运营、运维规则。 应用前景智能运维系统智能运维管理系统主要使用深度学习技术，针对平台运行日志检测，错误排查，预测维护等功能。如，结合知识图谱和当地地铁运行日志做故障诊断和排查等。可适用的应用领域包括交通，电信等。 (1)基于知识图谱的自动预警系统 系统运维面临越来越多的难点，包括服务器节点类型复杂、运维问题类型众多、问题发生不可预测，如何在大规模运维场景下，将重复度高的工作，基于监控数据智能决策触发，实现无人参与的自动操作的运维能力，是现代化运维手段的关键。 传统的自动化运维主要通过基于规则的模板进行触发，但是现在的服务器节点类型复杂、运维问题类型众多，具有许多基于人工的规则无法解决的问题，因此可以利用知识图谱构建一个全面的运维知识库，利用机器学习技术实现自动化运维。通过知识图谱技术对服务器硬件、操作系统、作业调度系统、计算应用的各种状态信息，如 CPU 使用率、作业负载、存储使用率等进行分析处理，形成业务运行数据，与运维事件特征知识库比对，可实现运维问题自动识别，对于特定的事件情况提前进行预警处理。 (2)基于知识图谱的员工培训助手 随着知识型经济在市场中大放异彩，知识管理所带来的的企业竞争软实力不容小觑，在企业的管理过程中，往往能产生大量的信息和文档，比如员工的工作经验、新员工的培训文档，项目管理过程中产生的调研报告、实施方案等，有效地利用知识将有利于企业发展。目前，传统的员工培训注重于知识传授，对于员工对知识的吸收、应用的关注较少，此外，目前许多知识管理模式对数据的存储比较零散，存在信息浪费，通过构建员工技能知识图谱，可以快速地帮助员工建立起对知识架构地认识，提高学习效率，改变学习曲线，提高知识应用比例，缩短知识学习到知识应用的距离，在知识经济时代构筑自身核心竞争力，同时可以通过利用知识图谱解决在实际工作中所遇到地问题。比如新员工入职地时候对公司的架构和人事关系不了解，可以通过企业知识图谱快速构建对企业架构的认识，提供培训的效率。 (3)基于知识图谱的机械维修运维平台 在机械维修领域中最为关键的信息就是机械的性能、机械工作流程信息以及机械故障信息。了解各类机械的性能和工作流程，能够为维修过程中提供科学而全面的理论指导，提高机械维修效率，同时，通过已有的故障信息，可以判别故障性质，查找故障根本原因，从而提出有效的维护方案。在机械维修的过程中，机械维修工作者为了能够对机械的性能、工作流程等信息有较为全面的了解，需要多年的学习和工作经验积累。这种方式需要耗费大量的时间、人力和财力。而科学合理地整合获得的知识能更好地为将来知识工作服务，可以通过知识图谱构建机械维修运维平台。通过提供可视化的图谱数据抽取机制、面向事件 Pattern 的技术文献意图理解及支持机械结构图的图谱数据查询，构建机械维修领域的知识图谱将简化机械维修工作者的工作并协助机械维修工作者进行新知识的挖掘。 智能运营系统智能运营系统：智能运营运用大数据分析技术和图深度学习技术，针对产品内容设计、用户行为分析、用户粘度控制、用户销售等。如结合知识图谱和用户在互联网电视的点播行为做媒体推荐系统。可适用的应用领域包括媒体、金融、医疗等。 (1)股票投研情报分析 通过知识图谱相关技术从招股书、年报、公司公告、券商研究报告、新闻等半结构化表格和非结构化文本数据中批量自动抽取公司的股东、子公司、供应商、客户、合作伙伴、竞争对手等信息，构建出公司的知识图谱。在某个宏观经济事件或者企业相关事件发生的时候，券商分析师、交易员、基金公司基金经理等投资研究人员可以通过此图谱做更深层次的分析和更好的投资决策，比如在美国限制向中兴通讯出口的消息发布之后，如果有中兴通讯的客户供应商、合作伙伴以及竞争对手的关系图谱，就能在中兴通讯停牌的情况下快速地筛选出受影响的国际国内上市公司从而挖掘投资机会或者进行投资组合风险控制。 (2)电信反欺诈分析 反欺诈是对包含交易诈骗，网络诈骗，电话诈骗，盗卡盗号等欺诈行为进行识别的一项服务。传统的方法是特定的人工规则构建欺诈规则，但是如何将大量的全面的知识整合到一起，进行计算和预测欺诈行为需要一种高效的具有推理能力的网络处理方法。基于海量数据的反欺诈的难点在于如何把结构化、非结构话数据结整合在一起，并构建欺诈引擎，从而有效地识别出欺诈案件(身份造假，团体欺诈，代办包装等)，同时，不少欺诈案件会涉及到复杂的关系网络，知识图谱基于图的表示方式和存储方式可以有效地解决这类问题。 要识别潜在的欺诈风险，首先，反欺诈的核心是人，需要融合不同数据源的信息构成知识图谱，比如判断借款人的欺诈风险，知识图谱不仅整合了借款人的基本信息，同时也整合借款人的消费记录、行为记录、网上浏览记录等信息，这些多源的，非结构化的数据需要利用机器学习、自然语言处理技术进行结构化处理。其次，根据领域专家建立的业务规则和知识图谱进行不一致性检验，比如借款人张 xx 和借款人吴 x 填写信息为同事，但是两个人填写的公司名却不一样 , 以及同一个电话号码属于两个借款人，这些不一致性很可能有欺诈行为。同时，通过对数据进行异常分析和知识推理，找出异常结构，最后，根据异常结构进一步分析，评估出欺诈风险。 (3)基于知识图谱的智能医疗 疾病的治疗知识大部分来自医生的临床经验、已形成的关于疾病治疗的有效方法等，特别是慢病，这种医疗经验及知识在具体的医疗诊治中的差异性给慢病知识的规范、标准化带来了困难，目前尚没有规范化体系的慢病病理、发病规律、医疗控制等方面的资源。慢病知识图谱的构建需要整合多方资源，如关于慢病的医学研究文献、慢病保健常识以及临床诊疗案例库数据等。这些数据分布在互联网、科学文献数据库、专科诊疗数据集、纸质书籍等多个地方，并且这些资源类型多样，具有不同的侧重点和不同的质量。构建关于慢病的知识图谱，需要考虑该体系的全面性、高质量，因此需要对众多的资源进行过滤、抽取，使之结构化、系统化。同时，为了实现慢病知识的有效组织及扩展性，需要对慢病知识中涉及的医学专业术语进行规范化，以保证慢病相关的资料数据都能够被有效地收集和处理。 因此，为了实现慢病治疗相关知识的体系化，需要对慢病知识资源进行收集、归类与整理，过滤不相关的内容，构建关于慢病诊疗的知识图谱，从而实现慢病的智能医疗。慢病知识图谱是智能慢病辅助诊断系统的基础，可以利用知识图谱和自然语言处理技术将不同来源、不同结构的慢病知识，例如临床路径、诊疗规范等按照一定的标准(如病情阶段等)和结构结合成一个可供利用的有机知识体系。通过使用核心的慢病知识库和不断地收集患者的临床诊疗数据、日常监测数据以及专科体检数据和各种输入的患者症状数据等，配合慢病知识库的语义匹配与推理技术辅助确认患者的慢病类型、治疗手段与计划、慢病保健常识与注意事项等。 项目研究内容研究目标和内容随着科学技术的发展，人类社会进入了一个新的时代——知识经济时代，知识的产生、分配、使用和传播成为经济增长的主要动力，企业的竞争、产业的竞争、综合国力的竞争，集中表现为科技发展水平、管理水平和技术转变为生产能力的竞争。 不论你是企业的新兵还是老将，都可能遇到：新加入某项目组，查找不到相关资料，也没有前辈特地给你传授经验，导致迟迟上不了手；项目开发中，想向企业里某些方面的专家请教，却不知该找谁；自己写过或见过的一份有价值的报告，在需要时却找不着了；一位离职同事带走了他手头所有的客户关系，企业因此蒙受巨大损失,这些都是知识管理进驻企业之前常遇到的困境。 以上种种问题，究其原因，在于知识的管理，没有一个可靠的知识管理体系来支撑。2000年左右，知识管理在中国落地，进入应用阶段，在软件公司、咨询公司等实践企业的推动下，越来越多的企业开始关注知识管理，并投入人力、财力将其付诸实践。但企业实践知识管理还处于起步阶段，远不成熟。特别是中小型企业，由于规模的限制，其知识管理思路和知识管理体系都只能在限制的资源中发挥，这就需要一个通用性，开放性的产品，用于提升企业在知识管理领域的能力。 因此，该项目为企业制定了一整套基于知识图谱和人工智能驱动的知识管理系统，并且在知识管理系统的基础之上，利用申报单位现有的大数据技术，增加了知识发现和知识服务等方案。 (1) 知识管理 企业有很多数据，主要分为两大类：一、以人为核心的数据。例如，网站中用户的浏览记录，个人信息等，定位数据中人的轨迹路径等数据。二、以机器为核心的数据。例如，系统的调用日志信息，地铁管理系统的运行日志等。这些数据通常包括丰富语言(semantics)且是关系型数据(relational data)。为了管理这些数据，我们引入了企业知识图谱。通过将企业数据构建成知识图谱，实现了企业的知识管理。同时，在企业自身的知识之上，通过申报单位的高效数据爬虫，获取与企业知识高度相关联的多源数据，用以扩展企业知识图谱的内容和范围。 (2) 知识发现 在企业知识图谱的基础上，提供基于自然语言的人机交互接口，即通过自然语言问题进行知识图谱查询和问答，实现了人机智能交互获取知识。同时，通过深度图学习(deep graph learning)技术，结合企业知识图谱和当前系统日志做推理诊断如：结合知识图谱和用户的行为习惯做推荐系统，或者结合知识图谱和当地地铁运行日志做故障诊断和排查。 (3)知识服务 智能运营主要针对以人为核心的数据进行产品内容设计。包括用户行为分析，用户粘度控制，用户销售等。例如，对于网站中用户的浏览记录，个人信息等，定位数据中人的轨迹路径等数据，通过数据分析人的社会属性，生活习惯和消费行为等信息而抽像出的一个标签化的用户画像。或者，在银行信用体系中，通过将借款人相关的所有的数据源打通，并构建包含多数据源的知识图谱，如，消费记录、行为记录、网上浏览记录等。从而对借款人进行分析和预测等。智能运营可适用于应用领域包括媒体(用户画像)，金融(投资，保险，风控)，医疗(就诊，医疗咨询)。 智能运维主要针对以机器为核心的数据进行的日志检测，错误排查，预测维护等。在工业过程，尤其是流程工业，在同一过程中的不同变量间往往存在相互关联的关系。比如在地铁系统中，主处理单元MPU、司机室智能显示单元IDU、牵引控制单元PCU等等多个模块。从直观上看，这种多变量间的关系变化是错综复杂的。而知识图谱这种语义网络可以很方便的将实体和关系，即变量和变量之间的关系用图来表达和存储，转化为计算机可读的知识。从而利用深度图学习技术，研发出的错误排查系统，和预测维度系统。智能能运维可适用于应用领域包括交通(高铁，地铁)，电信(基础设施管理)，流程工业(错误检测，监控、预测)等。 项目实施的成果将助力企业高效率、智能化的管理知识数据。例如，当查找不到资料，有问题想请教专家时，可以使用人工智能交互系统，进行查询问答。在总多复杂的文件中查找某份有价值的报告时，可以使用人工智能交互系统，进行查询。在系统运行过程中，出现错误时，可以通过知识图谱查询哪个变量出错导致的问题等。 拟解决的关键技术问题知识管理多源数据的知识抽取和关联 通常而言，知识抽取是指从数字资源中识别、发现和提取出概念、类型、事实以及相关关系、结束规则，以及进行问题求解的步骤、规则的过程。依据数字资源类型的不同，知识抽取的概念有广义和狭义之分。广义的知识抽取泛指从各种类型的数据和信息资源中获取各种知识的过程，例如从数字信号中、从多种媒体资源(如图像、数据、视频、音频)中抽取出知识，从数据集中发现重要模式的过程等。 狭义的知识抽取是指从非结构化的自由文本中获取相关知识内容的过程。与广义知识抽取针对各种类型数据的情况不同，狭义的知识抽取基本上属于文本挖掘的范畴，其处理的对象是自由文本，目标是分析文本内容，通过识别文本中的知识片段(Knowledge Fragments)，促进对文本内容的理解。 目前，市面上大部分的知识抽取方法尚处在狭义的知识抽取上，即仅仅对文本数据进行分析、挖掘。然而目前对于企业来说，数据的类型不仅仅是文本文档类型的结构化数据，其中还包含了大量的非结构化、半结构化数据等，例如图片，视频等。所以，如果知识抽取不能从狭义的知识抽取推广到广义的知识抽取，在实际应用中对企业的效益有限。 知识查询与发现(1)基于知识表示的知识推理方法 为了使计算机具有智能，仅仅使计算机拥有知识是不够的，还必须使它具有思维能力、推理能力。即能够运用已知的知识推理问题，求解问题。所以知识推理也是人工智能研究的重点。 目前的知识的表示方法有很多，如：谓词逻辑、产生式规则、语义网络和框架等等，这些知识表示各有各的特点，如生产式的自然性，语义网络的层次性，框架的通用性，模糊逻辑对模糊知识的适用性等，它们都在智能系统中发挥了重要的作用。但它们也各有其局限性，如产生式规则用于表达表层知识，而表达深层知识则十分困难。框架的固定式使许多表达结果与原型不符等等。知识表示的能力直接影响了推理的有效性和知识获取的能力。因此，目前智能问答系统构造中面临了一些较迫切需要解决的问题。一是知识库中知识的容量和质量问题。这包括不同数据结构的知识获取，需要设计出有效而且使用绝大部分数据结构的知识表示；二是现有的问答系统很少有自学推理能力。例如，在基于知识图谱的问题系统中，在问答时知识时，现在的做法通常是简单的从问题里解析出话题实体(topic entity)和对应的关系(relations)，然后在知识图谱上做检索，即从话题实体沿着对应的关系走到目标实体，然后返回，缺乏对知识图谱进行推理的功能。 所以如果知识图谱存在不确定关系(即从问题中解析得到的某个关系链在知识图谱上不存在)，这种检索有很大大机会不能得到有效的答案； 同时，现在的做法通常认为知识图谱上的关系(relations)是离散的，已经定义好的谓词(predicates)；但实际企业知识图谱中，很可能实体之间的关系是一堆自然语言文本(比如上下文)，而不是谓词，所以现在的做法(即通过话题实体－谓词１－谓词２－目标实体进行检索)也不适用。 (2)面向自然语言的图查询技术 现在基于知识图谱的问答系统主要有两大类方法：基于深度学习的端到端的训练和基于规则的知识库的匹配。但是这两种方法都存在着缺陷，基于规则的知识库的匹配面对自然语言处理的时候缺乏泛化性，对于出现规则中没能匹配的特征无能为力。基于深度学习的端到端的答案生成虽然解决了规则匹配的泛化性问题，但由于自然语言的开放性，通常无法很好的给出准确的回答，同时对训练样本数量要求很高，无法利用现有的知识库。 知识服务大规模数据处理能力 在互联网时代信息呈现爆炸性的增长。在科学领域、工程领域以及商业计算领域每天产生大量的数据。据不完全统计报告，2016年全球信息量已达到了25ZB(相当于2.5万亿GB)，储存单位从小到大依次是B,KB,NB,GB,TB,PB,EB,ZB,YB，IDC报告显示，预计到2020年全球数据总量将超过40ZB，这一数据量是2011年的22倍。如此海量数据给计算机数据的存储和计算带来了严峻的挑战，实际对计算能力的需求远超自身IT架构的计算能力，传统的方式是不断地加大硬件投入来适应大数据的增长。但是由于传统并行编程模型的复杂性，这无疑限制了系统的可扩展性，同时也降低了系统的易维护性。面对此种情况，这就迫切的需要一种全新的并行计算框架。 主要创新点在项目中分为了三个部分，知识管理，知识发现和知识服务；在知识管理层中，企业的数据不仅仅为文本类型的结构化数据，其中还包括了大量的非结构化数据、半结构化数据，例如文本、图片、视频等。为了从这些多源的数据中抽取知识，使用结构化实体结合半结构化、非结构化文本或多媒体的弹性表征方式，以应对企业的多源异构数据；利用集成学习 (ensemble learning)框架来有效结合多种实体抽取工具，以获取最好的实体抽取效果。同时，采用了利用混合匹配(hybrid matching)的框架，即结合模式匹配和实例匹配，来实现有效的实体关联和数据关联，从而将多源的知识进行知识融合，建立企业知识图谱，实现知识管理。在知识发现层中，为了能够实现对图数据库快速查询、检索，利用深度图学习(deep graph learning)技术和自然语言处理技术，将自然语言问题翻译成SQL查询语句，即答案可以直接通过图数据库查询得到。同时，为了使得检索过程中，计算机能够有智能推理的能力，采用了基于翻译模型(Trans系列)的方法将自然语言问题翻译成图推理查询语句，即答案需要通过图数据的逻辑推理得到。在知识服务层中，为了解决数据的存储和计算问题，创建了一种基于CPU和GPU的分布式混合架构。 基于多源数据的知识抽取方法知识抽取主要包括实体抽取和关系抽取。知识抽取是知识构建中最重要得一环。本项目采用了集成学习( ensemble learning)的框架，因此在知识抽取过程中，针对多源的数据应用了不同的实体抽取工具。其中，对于文本数据，主要采用双层的 LSTM-RNN 模型进行知识抽取；对于图像和视频数据，主要采用了Fast RCNN模型对图像进行语义分割(Image Sematic Segmentation)，从而实现实体的抽取。 (1) 基于双层的 LSTM-RNN 模型。第一层 LSTM 输入的是词向量、位置特征和词性来识别实体的类型。训练得到的 LSTM 中隐藏层的分布式表达和实体的分类标签信息作为第二层 RNN 模型的输入，第二层的输入实体之间的依存路径，第二层训练对关系的分类，通过神经网络同时优化 LSTM 和 RNN 的模型参数。 (2)基于Fast RCNN模型的图像语义分割。Faster RCNN 是在Region CNN算法之上改进而成。主要包括四个步骤候选区域生成，特征提取，分类，位置精修。重要步骤如下：通过多个尺度的窗口选择性搜索，并搜寻共享纹理、颜色或强度的相邻像素，创造了这些边界框，或者区域提案(region proposal)关于这个被称为选择性搜索(Selective Search)的方法，选择性搜索通过不同尺寸的窗口查看图像，并且对于不同尺寸，其尝试通过纹理、颜色或强度将相邻像素归类，以识别物体。在创建一组区域提案(region proposal)后，Fast R-CNN 只需将图像传递给一个训练好的卷积神经网络以确定其是否为有效区域，然后再通过SVM查看框图像目标，最后 通过线性回归模型运行边框，一旦目标完成分类，输出边框的更紧密的坐标。 Fast R-CNN 将卷积神经网络(CNN)，分类器和边界框回归器组合为一个简单的网络。Fast R-CNN 在单一模型中联合训练卷积神经网络、分类器和边界框回归器。之前有不同的模型来提取图像特征(CNN)，分类(SVM)和紧缩边界框(回归器)，而 Fast R-CNN 使用单一网络计算上述三个模型。 多源数据融合多源数据融合对知识库的构建是非常重要，与传统数据融合(data fusion)任务的主要不同是，知识融合可能使用多个知识抽取工具为每个数据项从每个数据源中抽取相应的值，而数据融合未考虑多个抽取工具。多源数据融合可以丰富知识库，使得知识库可以表示的维度更多。 知识融合包括了本体的融合和实例的融合。在知识融合技术中，本体匹配扮演着非常重要的角色，提供了概念或者实体之间的对应关系。本体匹配算法，一般可以分为模式匹配(schema matching)和实例匹配(instance matching)。本项目采用了混合匹配(hybrid matching)的框架，即模式匹配和实例匹配相结合的方法进行知识融合，对于文本类数据主要采用模式匹配，对于图片视频等其他类型数据主要采用实例匹配。 模式匹配主要寻找本体中属性和概念之间的对应关系。本项目采用自动的语义匹配方法，该方法首先利用像WordNet之类的词典以及本体的结构等信息进行模式匹配，然后将结果根据加权平均的方法整合起来，再利用一些模式(patterns)进行一致性检查，去除那些导致不一致的对应关系。该过程可循环的，直到不再找到新的对应关系为止。同时先实现过程中也考虑多种匹配算法的结合，利用基于术语的一些相似度计算算法，例如 n-gram 和编辑距离，这里算法计算的结果根据加权求和进行合并，还考虑了概念的层次关系和一些背景知识，最后通过用户定义的权重进行合并。 实例匹配是评估异构知识源之间实例对的相似度，用来判断这些实例是否指向给定领域的相同实体。首先使用向量空间模型表示实例的描述性信息，再基于规则采用倒排索引(inverted indexes)获取最初的匹配候选，在使用用户定义的属性值对候选进行过滤，最后计算出的匹配候选相似度用来作为整合的向量距离，由此抽取出匹配结果。 基于知识表示的知识推理方法知识库推理可以分为基于符号的推理和基于统计的推理。基于符号的推理一般是基于经典逻辑(一阶谓词逻辑或者命题逻辑)或者经典逻辑的变异(比如说缺省逻辑)。基于符号的推理可以从一个已有的知识图谱，利用规则，推理出新的实体间关系，还可以对知识图谱进行逻辑的冲突检测。基于统计的方法一般指关系机器学习方法，通过统计规律从知识图谱中学习到新的实体间关系。 本项目采用基于翻译模型(Trans系列)的知识表示学习来解决知识推理问题。表示学习旨在将研究对象的语义信息表示为稠密低维实值向量，知识表示学习主要是面向知识图谱中的实体和关系进行表示学习。使用建模方法将实体和向量表示在低维稠密向量空间中，然后进行计算和推理。翻译模型包括了TransE、TransR、TransH等。其实质是基于同一损失度量关系向量空间的头实体加上关系等于关系向量空间中的尾实体(hr+r=tr)。 TransE:$$h_r = h$$$$t_r = t$$ TransH:$$h_r = h - (w_r)^{T.h.w_r}$$$$t_r = t - (w_r)^{T.t.w_r}$$ TransR:$$h_r = M_r.h$$$$t_r = M_r.t$$ 本项目主要采用TransR模型做知识表示学习，构建推理系统。TransR在准确性和性能上都达到一个比较好的平衡，TransR模型如下图所示。对于每个元组(h，r，t)，首先将实体空间中的实体通过Mr向关系r投影得到hr和tr，然后使hr+r=tr。特定的关系投影(彩色的圆圈表示)能够使得头/尾实体在这个关系下真实的靠近彼此，使得不具有此关系(彩色的三角形表示)的实体彼此远离。 基于深度学习的SQL语句生成技术现在做问答系统主要有两大类方法：基于深度学习的端到端的训练和基于规则的知识库的匹配。但是这两种方法都存在着缺陷，基于规则的知识库的匹配面对自然语言处理的时候缺乏泛化性，对于出现规则中没能匹配的特征无能为力。基于深度学习的端到端的答案生成虽然解决了规则匹配的泛化性问题，但由于自然语言的开放性，通常无法很好的给出准确的回答，同时对训练样本数量要求很高，无法利用现有的知识库。因此，我们提出一种利用深度学习和知识库相结合的方法，利用深度学习技术将自然语言问题翻译成SQL查询语句对现有的知识库进行搜索。 利用LSTM-attention模型对输入的自然语言进行端到端的训练，输出分为两个部分：关于所需要查询的表名、列名和操作符号的选择。 大规模分布式混合架构传统的大数据技术多基于CPU上运行，如Hadoop、Spark等。但对于深度学习模型来说，由于其参数非常庞大，对并行计算要求非常高，传统的基于CPU架构下的分布式框架无法满足需求。为了可以同时使用CPU和GPU，本项目创建了一种基于CPU和GPU的分布式混合架构。 为了可以同时处理两种异构的底层框架，我们设计了一个抽象层来屏蔽底层资源，实现对底层物理资源的屏蔽，尤其是对GPU资源的抽象和调度。在屏蔽和抽象底层接口技术上，容器技术具有天然的优势，特别是Docker和Kubernetes的发展，其在GPU调度上十分完善，因此，本项目采用基于的Kubernetes容器集群作为中间调度层。 集群内置了Docker镜像仓库服务，多副本的API Server和Etcd集群，保证了整个集群所有组件的高可用性，后端使用Kubernetes编排系统，通过API Server实现授权认证和Quota配额功能。基于Web服务器可以实现集成内部权限管理系统的业务逻辑，系统提供了类似AWS的AKSK签名认证机制，用户注册登录后可以自行创建Access key和Secret key，请求时在客户端进行AKSK的签名后发送，这样用户不需要把账号密码或密钥加到请求中，即使密钥泄露也可以由用户来禁用，请求时即使签名被嗅探也只能重放当前的请求内容，同时，系统参考OpenStack项目的体系架构，实现了多租户和Quota功能，通过认证和授权的请求需要经过Quota配额检查，在高可用数据库中持久化相应的数据，这样平台管理员就可以动态修改每个租户的Quota，而且用户可以随时查看自身的审计信息。 采用的方法、技术路线以及工艺流程系统总体架构本项目的整体架构主要包括四层：数据采集层、知识管理层、知识发现层、知识服务层。数据采集层主要由一个分布式智能采集系统构成，其主要功能为对互联网数据进行定向采集，利用外部数据补充企业知识数据，是底层的异构数据的主要来源之一。知识管理层主要负责对知识进行抽取、识别、存储、管理和维护工作，知识管理层主要包括了知识自动构建系统和知识管理系统，是提供知识服务的保障。知识发现层主要是将知识进行表征学习，使得知识可以做推理，从而提供自动问答和查询服务，知识发现层主要包括了知识表征系统和知识推理系统两个系统。知识服务层是整个系统的价值的直接展现方式，是对外提供服务的渠道，知识服务包括了两个模块：基于知识图谱的智能运营服务系统和基于知识图谱的智能运维服务系统。 大规模分布式混合架构传统的大数据技术多基于CPU上运行，如Hadoop、Spark等。但对于深度学习模型来说，由于其参数非常庞大，对并行计算要求非常高，传统的基于CPU架构下的分布式框架无法满足需求。为了可以同时使用CPU和GPU，本项目创建了一种基于CPU和GPU的分布式混合架构。为了可以同时处理两种异构的底层框架，我们设计了一个抽象层来屏蔽底层资源，实现对底层物理资源的屏蔽，尤其是对GPU资源的抽象和调度。在屏蔽和抽象底层接口技术上，容器技术具有天然的优势，特别是Docker和Kubernetes的发展，其在GPU调度上十分完善，因此，本项目采用基于的Kubernetes容器集群作为中间调度层。 集群内置了Docker镜像仓库服务，多副本的API Server和Etcd集群，保证了整个集群所有组件的高可用性，后端使用Kubernetes编排系统，通过API Server实现授权认证和Quota配额功能。基于Web服务器可以实现集成内部权限管理系统的业务逻辑，系统提供了类似AWS的AKSK签名认证机制，用户注册登录后可以自行创建Access key和Secret key，请求时在客户端进行AKSK的签名后发送，这样用户不需要把账号密码或密钥加到请求中，即使密钥泄露也可以由用户来禁用，请求时即使签名被嗅探也只能重放当前的请求内容，同时，系统参考OpenStack项目的体系架构，实现了多租户和Quota功能，通过认证和授权的请求需要经过Quota配额检查，在高可用数据库中持久化相应的数据，这样平台管理员就可以动态修改每个租户的Quota，而且用户可以随时查看自身的审计信息。 数据采集层数据采集层主要包括两部分：(1)从企业提供的结构化和非结构化的数据流中收集知识数据，如通过企业的机器日志采集CPU、内存和程序运行等状态，通过员工打卡考勤登记表搜集员工的考勤信息；(2)利用分布式爬虫从互联网数据中采集外部数据，构建外部数据知识库，对企业知识库进行补充。下面重点对分布式智能采集平台的架构进行说明。 分布式智能采集系统主要分为五个部分：第一部分通过前端将CSS或XPATH规则转化为爬虫代码存入爬虫数据库CrawlerDB中；第二部分为通过CrawlerDB下达抓取命令，生产抓取列表fetchlist；第三部分Fetchlist通过组合url请求和IP地址、login登录信息得到网络请求；第四部分Fetchlist通过网络请求获取目标网页内容，并提交给parser模块进行页面解析；第五部分将解析结果被存储数据库中，同时向CrawlerDB反馈爬取结果状态，更新爬取信息。 知识管理层知识管理层主要负责抽取、识别、存储、管理和维护工作，知识管理系统包括了知识库自动构建和知识管理两部分组成。 知识图谱构建主要分为两大部分，第一个部分是知识获取，主要阐述如何从非结构化、半结构化、以及结构化数据中获取知识。第二部是数据融合，主要阐述如何将不同数据源获取的知识进行融合构建数据之间的关联。知识获取主要包括了实体识别和关系抽取、消除歧义、知识增强、知识纠错。 实体识别需要通过自然语言技术识别文章中的实体，实体识别通常有两种方法，一种是用户本身有一个知识库则可以使用实体链接将文章中可能的候选实体链接到用户的知识库上。另一种是当用户没有知识库则需要使用命名实体识别技术识别文章中的实体。若文章中存在实体的别名或者简称还需要构建实体间的同义词表，这样可以使不同实体具有相同的描述。歧义性和多样性是自然语言的固有属性，也是实体链接的根本难点。如何挖掘更多、更加有效的消歧证据，设计更高性能的消歧算法依然是实体链接系统的核心研究问题。本项目提出构一种基于图的模型，其中图节点为所有实体指称和所有候选实体；图的边分为两类，一类是实体指称和其对应的候选实体之间的边，权重为实体指称和候选实体之间的局部文本相似度，采用词袋模型和余弦距离计算得出。另一类是候选实体之间的边，权重为候选实体之间的语义相关度，采用谷歌距离计算。算法首先采集不同实体的初始置信度，然后通过图中的边对置信度进行传播和增强。 当获得实体后，则需要关注实体间的关系，即实体关系识别，有些实体关系识别的方法会利用句法结构来帮助确定两个实体间的关系，因此在有些算法中会利用依存分析或者语义解析。如果用户不仅仅想获取实体间的关系，还想获取一个事件的详细内容，那么则需要确定事件的触发词并获取事件相应描述的句子，同时识别事件描述句子中实体对应事件的角色。 当知识从各个数据源下获取时需要提供统一的术语将各个数据源获取的知识融合成一个庞大的知识库。提供统一术语的结构或者数据被称为本体，本体不仅提供了统一的术语字典，还构建了各个术语间的关系以及限制。本体可以让用户非常方便和灵活的根据自己的业务建立或者修改数据模型。通过数据映射技术建立本体中术语和不同数据源抽取知识中词汇的映射关系，进而将不同数据源的数据融合在一起。同时不同源的实体可能会指向现实世界的同一个客体，这时需要使用实体匹配将不同数据源相同客体的数据进行融合。不同本体间也会存在某些术语描述同一类数据，那么对这些本体间则需要本体融合技术把不同的本体融合。最后融合而成的知识库需要一个存储、管理的解决方案。知识存储和管理的解决方案会根据用户查询场景的不同采用不同的存储架构如 NoSQL 或者关系数据库。同时大规模的知识库也符合大数据的特征，因此需要传统的大数据平台如 Spark 或者 Hadoop 提供高性能计算能力，支持快速运算。 知识发现层知识发现层主要是将知识进行表征学习，从而实现知识的推理和计算。知识计算主要是根据图谱提供的信息得到更多隐含的知识，如通过本体或者规则推理技术可以获取数据中存在的隐含知识；而链接预测则可预测实体间隐含的关系；同时使用社会计算的不同算法在知识网络上计算获取知识图谱上存在的社区，提供知识间关联的路径；通过不一致检测技术发现数据中的噪声和缺陷。通过知识计算知识图谱可以产生大量的智能应用如可以提供精确的用户画像为精准营销系统提供潜在的客户；提供领域知识给专家系统提供决策数据，给律师、医生、公司 CEO 等提供辅助决策的意见；提供更智能的检索方式，使用户可以通过自然语言进行搜索；同时也可以做问答系统。 (1)知识推理系统 知识计算的核心是知识推理技术。知识库推理可以粗略地分为基于符号的推理和基于统计的推理。在人工智能的研究中，基于符号的推理一般是基于经典逻辑(一阶谓词逻辑或者命题逻辑)或者经典逻辑的变异(比如说缺省逻辑)。基于符号的推理可以从一个已有的知识图谱，利用规则，推理出新的实体间关系，还可以对知识图谱进行逻辑的冲突检测。基于统计的方法一般指关系机器学习方法，通过统计规律从知识图谱中学习到新的实体间关系。 知识图谱中基于统计的推理方法一般指利用机器学习方法技术做知识推理，如类型推理(type inference)方法、模式归纳(schema induction)方法、基于实体关系学习方法。知识图谱上的类型推理目的是学习知识图谱中的实例和概念之间的属于关系，例如SDType利用三元组主语或谓语所连接属性的统计分布以预测实例的类型。该方法可以用在任意单数据源的知识图谱，但是无法做到跨数据集的类型推理。模式归纳方法学习概念之间的关系，主要有基于 ILP 的方法和基于 ARM 的方法。ILP 结合了机器学习和逻辑编程技术，使得人们可以从实例和背景知识中获得逻辑结论。实体关系学习的目的是学习知识图谱中实例和实例之间的关系，例如翻译(translation)模型就是将实体与关系统一映射至低维向量空间中，且认为关系向量中承载了头实体翻译至尾实体的潜在特征。因此，通过发掘、对比向量空间中存在类似潜在特征的实体向量对，可以得到知识图谱中潜在的三元组关系。基于实体关系学习的方法可以很好的和深度学习技术相结合，因此本次项目的知识推理采用了基于实体关系学习的方法。 (2)面向自然语言查询的知识搜索 在知识发现层提供了一种面向自然语言查询得知识搜索功能。采用了基于知识图谱的知识搜索和基于搜索引擎的知识搜索。基于自然语言的知识检索主要包括两方面，一个是将自然语言转化为查询语句，一个是基于深度图学习的搜索。 本项目提出一种基于基于语义关系抽取的自动生成算法,实现从无结构化自然查询语句到结构化查询语句之间的映射。针对非事实性的问题,本项目提供了基于无结构化的社区问答数据的知识搜索服务，从基于问题跟问题相似度匹配和问题跟答案相似度匹配两个方向解决问题。在问题跟问题相似度匹配模型中,我们提出改进的WMD算法,该算法根据社区问答数据的特性对原始的WMD算法进行改进,算法的结果比传统的BM25算法以及原始的WMD算法在性能上都有了较大提高。在问题与答案相似度匹配模型中,通过深度学习在NLP领域的应用来比较两个句子或者段落的语义相似度,考虑问题和答案在数据集上的共现特征,提高了模型在处理答案简短、关键词与问题语义不匹配等情况下性能低下的问题。 传统的知识搜索是基于结构化查询的形式进行，这种检索模式存在检索语法复杂、数据结构复杂等问题，而且无法做知识推理。而且企业的知识图谱和传统的知识图谱搜索不同，传统的知识图谱是基于离散性关系的搜索，其谓语动词是定义好的，如头实体-谓词-尾实体。因此本项目采用一种利用深度学习在异质图上做语义推理的方法，利用LSTM根据两点之间的路径结构训练其邻近性表示，从而实现邻近性的嵌入表示。 知识服务层知识服务层是整个系统的价值的直接展现方式，是对外提供服务的渠道，是整个系统的应用层，知识服务包括了两个方面应用：智能运营服务系统和智能运维服务系统。 (1)基于智能运营系统 自动化运营体系功能架构分为三层，由下至上依次为数据层、 能力层和应用层。 上层调用下层的能力和应用，下层为上层提供支撑服务。 数据层。 数据层主要依托企业知识库，汇聚客户标签、产品信息、触点信息、场景模型、运营指标等基础数据，形成标准化的数据库，供能力层调用。在汇总海量客户数据的基础上，准确描述客户特征，从自然属性、社会属性、电信属性、互联网属性等维度对全量客户进行画像，实现对客户的“ 超细分”。 能力层。 能力层主要依托业务逻辑，调用下层的标准数据库，形成可供应用层调用的标准化能力，主要包括事件(时机)识别能力、数据标签能力、场景模型能力、动态内容发布能力、触点管理能力和评估监控能力。其中，关键事件(时机)识别能力是开展自动化运营的前提和基础。 应用层。 应用层调用下层的标准化能力，实现闭环的自动化流程，包括需求分析、策略适配、时机识别、触点匹配、效果评估五个环节。 (2)智能运维系统 智能运维系统架构层次主要包括了三部分： 系统监测自动化。系统监测是运维自动化的基础，自动化抓取服务器硬件、操作系统、作业调度系统、计算应用的各种状态信息，如 CPU 使用率、作业负载、存储使用率等，全面掌握集群状态，并将数据和事件存储于知识库，为自动化运维提供原始数据与事件关系。 数据分析自动化。监测数据一般为运行信息，无法直接用于业务运维，必须对其进行分析处理，形成业务运行数据，方可实现运维问题自动识别。 问题处理自动化。经分析的业务数据出现异常时，说明业务存在运行问题，需运维人员处理，其中大部分是重复出现的简单问题，占用了运维人员大量时间。将运维人员处理问题的方法总结形成标准化工作流程，或将复杂操作封装为可视化操作，业务异常发生时，自动触发问题处理流程，保证业务连续性。 项目效益分析项目产品市场分析，并明确说明本项目产品市场定位产品： 构建知识图谱和人工智能驱动的企业深度智能运营和运维平台 背景：企业有很多数据，包括各种类型日志：文本日志(比如电信文档，法律卷宗)，用户日志(比如媒体浏览，地理轨迹)，机器日志(比如生产线传感器，高铁／地铁运行日志)等。数据宝贵。如何对这些企业数据进行管理，进而做知识发现和知识服务，在人工智能时代尤为重要。 申报单位希望能够构建一个智能平台，可以帮助企业： 一、知识管理； 1)将企业的数据构建成企业专属的知识图谱，实现企业知识管理。比如可以用来帮助培训员工，降低员工训练成本；2)人机智能交互界面系统。通过该系统界面，使得企业能够使用自然语言问题查询知识库中知识，提高工作效率。 二、知识发现； 1)通过高效数据爬虫，获取多源关联数据，用以扩展企业知识图谱的内容和范围； 2)通过多源数据关联融合，用以帮助企业做知识发现，最大化企业数据的效能，实现企业知识发现。比如可以用来提供自动问答和技术支持，降低人工成本； 三、知识服务； 利用扩展过的企业知识图谱所带来的丰富语义和关联信息，来实现知识服务，帮助提高企业效能。即利用企业知识图谱来帮助企业原有的业务，比如推荐等。同时平台可以支持多种商业模式： １)知识服务模式(针对中小型企业)：申报单位已经在某些应用行业有深耕，并已构建该行业的大型知识图谱和有着一套相关的企业应用解决方案。 这样对于一个有业务需求的企业，可以将该企业的数据和平台对接，让该企业在平台上进行企业应用。 ２)技术服务模式(针对大中型企业)：对于一个有业务需求的企业，但其所属行业不在申报单位已有的业务范围之内，申报单位可以提供一整套企业知识图谱的端到端方案，帮助他们构建起自己的企业知识图谱并提供技术支持。]]></content>
      <categories>
        <category>演讲稿展示</category>
        <category>知识图谱</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>知识图谱</tag>
        <tag>人工智能</tag>
        <tag>智能运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于实时流式计算技术的高吞吐量网络数据分析云平台]]></title>
    <url>%2F2017%2F%E6%9E%B6%E6%9E%84%2F%E5%9F%BA%E4%BA%8E%E5%AE%9E%E6%97%B6%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E7%9A%84%E9%AB%98%E5%90%9E%E5%90%90%E9%87%8F%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%BA%91%E5%B9%B3%E5%8F%B0%2F</url>
    <content type="text"><![CDATA[总体方案基于实时流式计算技术的高吞吐量网络数据分析云平台是利用自有研发的分布式流处理框架，把数据采集、数据挖掘、数据可视化于一身的大数据云计算平台，平台架构创新性的改造了Heron和Strom的分布式流式计算框架以适应高吞吐量网络大规模数据的处理，以Mesos为资源管理框架，同时结合docker将计算节点、管理节点容器化处理，保证对资源的控制和隔离。平台利用分布式流式处理技术为企业提供适用与大规模网络数据采集、挖掘和可视化云服务。此平台在6台32核CPU，130G内存的服务器下处理的数据吞吐量能达到100w/s。平台预期可以实现千万的成果创收，帮助政企客户及中小企业创建便捷易用的一站式大数据实时处理分析平台。 主要研究内容基于实时流式计算技术的高吞吐量网络数据分析云平台是一个集合了数据采集、数据分析和数据可视化的大数据服务BDPS平台，平台以Mesos为资源管理框架支持资源调度，以Heron、Storm作为实时流计算框架，整合数据采集、数据可视化系统，使用Docker作为容器实现资源隔离和限制。 项目主要由三大平台组成，包括了数据采集平台、大数据分析平台、数据可视化平台三大部分，具有完整的数据挖掘和处理流程，其工艺流程如下图所示。 技术路线数据采集平台数据采集平台主要将互联网数据通过特定规则采集下来，数据采集平台实现快速低成本开发特定主题网络爬虫，使得爬虫开发技术变成web窗口化界面操作，降低学习门槛，平滑学习曲线，同时将更多设置放在底层处理，实现半自动化设计，使得界面简单清晰。包含主要功能： 1）可视化制定爬取规则 平台具有WebUI操作界面，可以通过操作页面设定规则，如特定标签抓取，循环抓取和页面跳转规则等。 2）固定爬取更新间隔 爬虫系统具有特定时间对内容进行更新爬取设置，同时爬虫系统可以在多次更新中通过学习算法学习到特定网页更新时间，从而减少人工介入。 3）模拟js代码运行，自动模拟登陆 爬虫框架包含js运行环境，可以直接解析js源码，并进行模拟登陆操作。 4）识别通用性验证码 具有对通用型验证码如字母数字混合型验证码进行识别功能，实现自动登陆功能。 5）高性能，分布式爬取及存储 具有高并发爬取功能，可以实现分布式爬取和存储任务。 6）IP代理服务 设置IP代理池和UA池，爬虫系统可以自动切换IP及UA，防止网站封杀。 数据采集平台模块设计主要分为五个部分：第一部分通过前端将UI规则转换为爬虫代码存入爬虫数据库CrawlerDB中；第二部分为通过CrawlerDB下达抓取命令，生产抓取列表fetchlist；第三部分Fetchlist通过组合url请求和IP地址、login登陆信息得到网络请求；第四部分Fetchlist通过网络请求获取目标网页内容，并提交给parser模块进行页面解析；第五部分将解析结果被存储数据库中，同时向CrawlerDB反馈爬取结果状态，更新爬取信息。设计图如下图所示。 大数据分析平台大数据分析平台是一个集数据处理、特征工程、机器学习算法、文本算法于一身的分布式流式处理平台，平台提供从数据预处理到模型评估的一站式平台服务，基于WEB工作界面，通过拖、拉、拽等方式即可完成复杂数据挖掘流程，支持自定义算法和组件，灵活开放的个性化设置，提供丰富的分布式算法，提高模型精度。 平台除了具有数据分析功能，其一个最大的特点是可以做实时计算的流处理平台。平台整合了Storm、Heron等实时计算分布式流处理技术，以Mesos为资源管理框架管理管理流式处理实体，从而实现吞吐量达到100w/s的实时数据分析。在系统架构设计上主要采用了反压机制来确保拓扑在组件缓慢的情况下可以自适应，同时采用了docker容器技术作为拓扑节点的隔离和资源的限制，从而保证永远不能超过初始分配的资源限制。 数据可视化平台数据可视化平台采用ECharts框架和D3框架相结合的方式。提供可视化场景模板，包括运营动态直播、数据综合展示、设备监控预警等多种场景模板，稍加修改就能够直接服务于您的可视化需求，数据可视化平台采用拖拽式界面布局，通过拖拽即可实现灵活的可视化布局，以WebGL技术作为支撑，能够绘制海量数据下的地理轨迹、飞线、热力、区块、3D地图/地球，支持多层叠加，支持关系型数据库、非关系型数据库、Restful API、CSV、静态JSON等多种数据来源，且能够实现动态轮询，将多个数据源汇聚于一个可视化界面中。 创新点1、通过改动开源框架Heron和Storm构建实时清洗系统的底层框架，实现了基于进程的实时计算模型，大大降低了大规模网络数据对内存的占有量，提升了实时处理平台的稳定性。 2、解决了大规模网络数据的实时性处理数据时的吞吐量问题，平台能以高吞吐量地进行数据清洗、模型训练及实时反馈，为实时而且精准的营销提供一个良好的基础。 3、通过整合数据采集、数据清洗、数据分析、数据可视化，构建一站式大数据服务平台(Big Data Platform as a Service , BDPS)。 产品对比市面上现存主要大数据挖掘平台的产品主要有国云数据的“魔镜”、阿里巴巴的“数加”、永洪商智的永洪大数据计算平台等。将市场上主要的三个产品和本产品进行对比。 通过对比可知：现有各平台的大数据工具较为单一，主要集中在云计算、数据挖掘和数据可视化等领域，但是各企业的产品较为分散，各企业没有一套完整的从数据采集到数据清洗、到数据挖掘和数据可视化的大数据解决方案。]]></content>
      <categories>
        <category>演讲稿展示</category>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>流式计算</tag>
        <tag>大数据</tag>
        <tag>Storm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Docker容器云技术的大数据智能挖掘处理一站式服务平台]]></title>
    <url>%2F2017%2F%E6%9E%B6%E6%9E%84%2F%E5%9F%BA%E4%BA%8EDocker%E5%AE%B9%E5%99%A8%E4%BA%91%E6%8A%80%E6%9C%AF%E7%9A%84%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%99%BA%E8%83%BD%E6%8C%96%E6%8E%98%E5%A4%84%E7%90%86%E4%B8%80%E7%AB%99%E5%BC%8F%E6%9C%8D%E5%8A%A1%E5%B9%B3%E5%8F%B0%2F</url>
    <content type="text"><![CDATA[背景简介随着各行业信息化速度的加快，不同类型的数据皆呈现出爆发性的增长并质变成大数据。随着海量、细致的新数据源的不断呈现，大数据在运营、策划、营销等方面的应用，得到不同层面的技术指标，产生系列的报表并反馈在生产和运营中，大数据价值的挖掘应用成为智慧企业发展的所迫切需要迈出的重要一步。 随着海量、细致的新数据源的呈现，基于海量数据的存储技术、挖掘技术、计算技术、剖析技术等各种技术的飞速进步，使企业可以深化发掘大数据的发展潜力，应用以往无法应用的商业信息，从而发现大量的商机。自2012年发展至今，大数据已经渗透到了每个行业和业务领域，逐渐成为重要的生产因素。但是，传统的信息化系统和工具逐渐无法承载如此庞大的数据存储和运算，分析效率逐步地下，以至于无法胜任数据挖掘分析的需求。在这种情况下，决策者们往往向大数据靠拢，对原有信息系统进行改造，去拥抱真正意义上的大数据资产。 面对如此庞大而复杂的数据，还需要专门设计的软硬件工具进行处理，数据分析类产品应运而生。数据分析类产品侧重于数据的分析和挖掘以及为企业用户提供比较完整的解决方案。目前国内外市场的大数据服务商纷纷推出了面向云计算、数据挖掘和数据可视化等领域的的大数据服务应用技术及平台，但由于受到研发投入不足、研发人才稀缺等因素的制约，主要是仅面向其中一个细分领域应用的功能性产品，存在应用操作复杂、对操作人员的技术素质的要求高、多功能产品整合利用成本高等不足，制约了中小企业对大数据技术的应用。 因此，站在对大数据全局认识的角度、深入中小企业的大数据应用需求研究一套从大数据数据采集到数据清洗、到数据挖掘和数据处理可视化的一站式大数据应用解决方案对推动大数据及相关行业的发展具有非常重要意义。 技术研发情况本项目是站在对大数据全局认识的角度、深入中小企业低成本大数据应用需求，研究的一套基于Docker容器云技术的大数据智能挖掘处理一站式服务平台，是一个面向中小企业通用型的集成智能数据采集、数据分析挖掘、数据可视化的一站式大数据服务平台，使得用户无需关心集群的搭建和运维，WEB页面的工作环境实现了拖拽式、点击式等类似于桌面操作方式，从最初始的网站数据采集到对采集回来的数据进行数据清洗和数据分析，最后以可视化图表的形式呈现分析结果，为中小企业提供安全、便捷、高效的一站式数据挖掘处理服务，基于轻量级虚拟化技术——docker技术实现了一站式云计算与大数据智能挖掘处理的完美结合。 所采用的关键技术（1） 基于Docker和Mesos结合的分布式计算架构本项目整合了Mesos和Docker的优势，实现Mesos和Docker的无缝对接，将各应用通过Docker进行容器化管理，让应用在更轻量化的情况下分配资源、隔离进程和网络，完成从开发到部署的快速搭建，同时将Docker作为分布式环境下的进程管理，对通过Mesos各应用进行管理，既解决了分布式的痛点，又为用户提供基于集群环境的高速计算能力，极大地提高了发布效率。 （2） 基于机器学习的防封杀智能数据爬取技术该平台首先，模拟浏览器头文件请求，模拟浏览器头文件请求可以伪装成浏览器对服务器进行访问，模拟的头请求包括了手机PC端等数十种浏览器；其次，构建ip代理池，可以通过切换ip防止服务器对ip访问的限制，通过蒙特卡罗算法随机切换ip代理，伪装成多个用户进行访问，并利用机器学习学习网站封杀规律使得代理池可以最大效率的利用代理ip，从而防止某些网站对单个用户的访问限制；最后，通过Phantomjs对javascript代码进行模拟运行，从而实现对网站的交互式操作，模范真人上网行为，防止网站对爬虫的封杀。采用基于机器学习的多种反封杀组合实现对数据的智能爬取，提高抓取数据的质量、可靠性和完整性。 （3） 基于MD5树的URL去重算法的数据清洗技术对URL进行去重是实现高性能数据挖掘服务的一项十分关键的技术之一。该平台将 MD5 加密算法以及树相结合设计出一种基于 MD5 的URL去重树对URL进行去重处理，避免了数据的重复。主要方法如下：1）由于在网络爬虫抓取过程中需要频繁的解析URL，导致对DNS服务器的压力过大，本项目引入并且优化了 DNS 本地缓存模块，将域名使用哈希函数到哈希表，利用线性指针将域名到ip的映射指向至冲突域，以此解决当数据量较大时发生碰撞的情形。2）再利用了MD5加密的低碰撞率，将MD5和树相结合构成去重树，由于树的结构与操作系统文件目录的结构一样，去重树也可以用另一种方法即基于磁盘符号的查找方式，将密文生成的数组转为相应的路径，如果路径存在则代表linkurl中已有相应的url，如果不存在说明此url为新的url。 （4） 基于二分策略分组的负载均衡改进算法的数据分析技术对于服务类型的应用，分布式系统用负载均衡器和服务发现来保证高可靠性的服务。本项目基于Spark对APFP_Growth 算法进行改进，研究基于二分策略分组的负载均衡改进，改进现有的并行PFP_Growth 算法在 FList 分组的步骤中没有考虑分组中负载均衡的问题，改进的 APFP_Growth 算法具有很好的可扩展性，并且比 PFP_Growth 算法具有更好的负载均衡效果。 （5） 基于改进的并行协同过滤算法的数据处理技术本项目基于Spark通过将构建共现矩阵、矩阵相乘简化为获取邻居用户改进基于共现矩阵的并行算法，改进的并行协同过滤算法比原来基于共现矩阵的并行算法更适合于分布式并行计算，具有更好的运行效率和更高的推荐精度。改进后的并行算法主要通过三个步骤实现：生成评分矩阵、获取邻居用户、形成推荐。获取邻居用户主要是通过相似度计算方法来找出目标用户的 K 个邻居用户，即用 K 最小堆的算法来找出 K 个相似度最大值。 技术研发方案该平台以Apache Mesos为资源管理框架支持资源调度，以Spark、Storm、Hive作为计算框架，使用Docker作为容器包装Mesos、Spark、Storm、Hive实现资源隔离。 本项目以Docker容器为单元为每个应用构建一个容器（如图1所示），借助Docker实现用户定制的分布式系统。 Docker主要包括了Docker Client、Docker Daemon、Docker Registry、Graph、Driver、libcontainer以及Docker container七个模块，其中Docker Client是Docker架构中用户用来和Docker Daemon建立通信的客户端;Docker Daemon是Docker架构中一个常驻在后台的系统进程，其负责接受并处理Docker Client发送的请求;Docker Registry是一个存储容器镜像的仓库;Graph负责对Docker已下载容器镜像的保管者，以及已下载容器镜像之间关系的记录者;Driver是Docker架构中的驱动模块，通过Driver驱动，Docker可以实现对Docker容器执行环境的定制，为了将Docker容器的管理从Docker Daemon内部业务逻辑中区分开来，设计了Driver层驱动来接管所有这部分请求；libcontainer是Docker架构直接访问内核中与容器相关的API，libcontainer扩展了LXC特性并使用高层的 API，LXC 作为一种共享 Kernel 的操作系统级别的虚拟化解决方案，通过在执行时不重复加载内核，且虚拟容器(Container)与宿主机(Host)之间共享内核来加快启动速度和减少内存消耗；Docker container（Docker容器）是Docker架构中服务交付的最终体现形式。 Mesos用于实现了双层调度机制，使它可以管理多种类型的应用程序：第一级调度是Master的守护进程，管理Mesos集群中所有节点上运行的Slave守护进程。集群由物理服务器或虚拟服务器组成，用于运行应用程序的任务，比如Hadoop和MPI作业；第二级调度由被称作Framework的“组件”组成，包括调度器（Scheduler）和执行器（Executor）进程，其中每个节点上都会运行执行器。 Mesos由四个组件组成，分别是Mesos-master，mesos-slave，framework和executor。Mesos-master是整个系统的核心，负责管理接入mesos的各个framework和slave，并将slave上的资源按照某种策略分配给framework。Mesos-slave负责接收并执行来自mesos-master的命令、管理节点上的mesos-task，并为各个task分配资源。mesos-slave将自己的资源量发送给mesos-master，由mesos-master中的Allocator模块决定将资源分配给哪个framework。Framework是指外部的计算框架，本项目中采用的计算框架包括了Spark、Storm、Hive等，可通过注册的方式接入mesos，以便mesos进行统一管理和资源分配，整个mesos系统采用了双层调度框架：第一层，由mesos将资源分配给框架；第二层，框架自己的调度器将资源分配给自己内部的任务。Executor主要用于启动框架内部的task。由于不同的框架，启动task的接口或者方式不同，当一个新的框架要接入mesos时，需要编写一个executor，告诉mesos如何启动该框架中的task。 该平台的架构主要围绕这数据采集、数据分析挖掘、数据处理这几个关键点进行构建，分别实现在云平台上实行数据计算、挖掘、服务等相关功能，数据采集挖掘能力是该架构的核心能力，可以实现在云计算平台上实现对不同格式的数据进行并行挖掘，使数据的分析处理能够运行更加稳定，方便整个架构的高效运行。 A. 大数据采集大数据的采集是整个流程的基础。随着互联网技术和应用的发展以及各种终端设备的普及，使得数据生产者范围越来越大，数据的产量也越来越多，数据之间的关联也越来越复杂，因此对数据采集速度和精度的要求越来越高。 该模块的核心是智能爬虫抓取模块的实现，主要将互联网数据通过WebUI操作界面对数据采集规则进行个性化设定实现对大数据的个性化采集，该平台采用机器学习方法的主动爬虫技术实现智能数据高并发爬取提高数据的采集精度，整个过程无需太多的人工介入，降低学习门槛，平滑学习曲线，同时将更多设置放在底层处理，实现半自动化设计，使得界面简单清晰，提高数据的采集效率。 B. 大数据挖掘处理大数据挖掘是整个流程的核心，数据挖掘则是将大量的、不完全的、有噪声的、模糊的、随机的实际应用数据经过加工处理，筛选优化后，提取隐藏其中的有价值的信息。由于数据复杂多样、数据挖掘和处理需要高速、高效，基于Docker容器云技术的数据挖掘架构是能够利用Docker容器云技术的轻量级虚拟化海量存储和并行计算能力解决了大数据的海量、高可靠性和高效性要求。 该模块主要提供数据预处理到模型评估的一站式平台服务，基于WEB工作界面，通过拖、拉、拽等方式即可完成复杂数据挖掘流程，支持自定义算法和组件，灵活开放的个性化设置，提供丰富的分布式算法，提高模型精度，其核心内容主要包括：数据挖掘流程配置服务、DMS数据挖掘服务、数据挖掘模型管理等。 C. 大数据分析展示大数据分析展示是整个流程的目标。在完成数据的采集和处理后，需要对数据进行分析，因为在进行数据分析后才能体现所有大数据的重要价值。数据分析的对象是对上一步数据的处理与集成后的统一格式数据，根据所需数据的应用需求和价值体现方向对这些数据进一步处理和分析，并将分析的结果向用户进行交互展示。 该平台主要采用ECharts框架和D3框架相结合的方式，为中小企业提供运营动态直播、数据综合展示、设备监控预警等多种可视化场景模板；通过拖拽即可实现灵活的可视化布局；以WebGL技术作为支撑，能够绘制海量数据下的地理轨迹、飞线、热力、区块、3D地图/地球，支持多层叠加，支持关系型数据库、非关系型数据库、Restful API、CSV、静态JSON等多种数据来源，且能够实现动态轮询，将多个数据源汇聚于一个可视化界面中，并同时实现在线分享应用功能。 关键技术 A. 该平台整合了Mesos和Docker的优势，实现Mesos和Docker的无缝对接，利用Mesos实现对分布式集群做细粒度资源分配，结合Docker规避了Mesos无中心化缺陷，将各应用通过Docker进行容器化管理，让应用在更轻量化的情况下分配资源、隔离进程和网络，完成从开发到部署的快速搭建，既解决了分布式的痛点，又为用户提供基于集群环境的高速计算能力，极大地提高了发布效率 B. 该平台将数据采集模块的解析、设计和点击功能全部通过网页的Web端实现，从而可以使得平台具有跨平台特性和自定义数据服务功能，满足中小企业低成本享受一站式大数据服务需求。 C. 采用基于机器学习的多种反封杀组合实现对数据的智能爬取，结合基于 MD5 的URL去重树对URL进行去重处理对数据进行清洗，提高挖掘数据的质量、可靠性和完整性。 D. 该平台基于Spark对并行协同过滤算法和APFP_Growth 算法进行改进，改进的并行协同过滤算法比原来基于共现矩阵的并行算法具有更高的运行效率和更高的推荐精度，基于二分策略分组的负载均衡改进的APFP_Growth算法，规避了现有的并行 PFP_Growth 算法在 FList 分组的步骤中没有考虑分组中负载均衡的问题，达到更好的负载均衡效果。]]></content>
      <categories>
        <category>演讲稿展示</category>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>Dokcer</tag>
        <tag>容器技术</tag>
        <tag>数据挖掘</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CAP简易理解]]></title>
    <url>%2F2017%2F%E6%9E%B6%E6%9E%84%2FCAP%E7%AE%80%E6%98%93%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[引言一个分布式系统里面，节点组成的网络本来应该是连通的。然而可能因为一些故障，使得有些节点之间不连通了，整个网络就分成了几块区域。数据就散布在了这些不连通的区域中。这就叫分区。当你一个数据项只在一个节点中保存，那么分区出现后，和这个节点不连通的部分就访问不到这个数据了。这时分区就是无法容忍的。提高分区容忍性的办法就是一个数据项复制到多个节点上，那么出现分区之后，这一数据项就可能分布到各个区里。容忍性就提高了。然而，要把数据复制到多个节点，就会带来一致性的问题，就是多个节点上面的数据可能是不一致的。要保证一致，每次写操作就都要等待全部节点写成功，而这等待又会带来可用性的问题。总的来说就是，数据存在的节点越多，分区容忍性越高，但要复制更新的数据就越多，一致性就越难保证。为了保证一致性，更新所有节点数据所需要的时间就越长，可用性就会降低。 分布式系统中的CAP理论： P：Partition tolerance，要有高容错性就必须要采用多节点，数据和节点越冗余，容错性越好。 A：Availability，这里的可用性指得是系统对操作的响应速度，对具体的操作响应越快，其可用性越高。 C：Consistency，要保证各节点数据的一致，在跨节点通信中，那必不可少需要对数据做校验和检查，如果通信节点越多（高容错），每个节点操作都做校验（强一致），那么响应速度就越慢（低可用）。 分布式系统CAP推论 performance -&gt; sharding最开始为什么需要分布式的系统，分布式系统提出最早就是为了解决用一堆廉价机器代替一台很NB机器的解决方案，也就是单机性能问题。 sharding -&gt; failed tolerance对于分布式系统，由于各组件是通过网络通信，是非常不可靠的，这时候就要考虑容错性，需要尽量需要建立一个具有容错性的系统。 tolerance -&gt; replication需要一个具有容错性的系统，最好的办法就是多准备几份数据，通过多副本的方式解决分布式系统容易出错的问题。 replication -&gt; inconsistency但是多副本就必然需要面临数据一致性的问题，在主数据被更新的时候有可能导致其他的副本没有同步过来，从而导致数据不一致。 consistency -&gt; low performance为了解决数据一致性问题，我们需要通过lock或者进行多个节点进行通信确认的方式来确保数据的一致性，但是这样就必然会降低整个系统的性能，特别是出现失联节点。]]></content>
      <categories>
        <category>技术博文</category>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>CAP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[电信wifi大数据能力平台]]></title>
    <url>%2F2017%2F%E6%9E%B6%E6%9E%84%2F%E7%94%B5%E4%BF%A1wifi%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%83%BD%E5%8A%9B%E5%B9%B3%E5%8F%B0%2F</url>
    <content type="text"><![CDATA[演示稿]]></content>
      <categories>
        <category>演讲稿展示</category>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>WIFI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django小知识]]></title>
    <url>%2F2017%2F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%2FDjango%E5%B0%8F%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[Django知识小问答 Django知识小问答关于makemigrations问：我用python manage.py makemigrations怎么没能将我的model文件生成数据？ 答：可以給我看下model的文件目录吗？ 问：目录是这样的(venv) G:\git\bigbooom\bigboomm\citizen&gt;tree /f卷 study 的文件夹 PATH 列表卷序列号为 0000000F B64E:66E1G:. models.py models.pyc __init__.py __init__.pyc 答：嗯嗯，我知道，我想你应该是少了一个migrations的文件夹吧，所以他不知道你需要生成migrations，你试试在citizen文件夹下面建一个migrations，记得要在里面加一个init.py哦，不然也是不可以的 问：啊，可以了~~ Good Job(venv) G:\git\bigbooom\bigboomm&gt;python manage.py makemigrationsMigrations for 'citizen': citizen\migrations\0001_initial.py: - Create model Citizen 答：其实，一般Django中建app建议用manage.py startapp ```这个命令，这样可以帮你建立一个完整的app目录哦~~## cryptography 错误报`RuntimeError: cryptography is required for sha256_password or caching_sha2_password`错： File “C:\Users\shikanon\Desktop\新建文件夹\venv\lib\site-packages\pymysql\connections.py”, line 325, in init self.connect() File “C:\Users\shikanon\Desktop\新建文件夹\venv\lib\site-packages\pymysql\connections.py”, line 599, in connect self._request_authentication() File “C:\Users\shikanon\Desktop\新建文件夹\venv\lib\site-packages\pymysql\connections.py”, line 882, in _request_authentication auth_packet = _auth.caching_sha2_password_auth(self, auth_packet) File “C:\Users\shikanon\Desktop\新建文件夹\venv\lib\site-packages\pymysql_auth.py”, line 264, in caching_sha2_password_auth data = sha2_rsa_encrypt(conn.password, conn.salt, conn.server_public_key) File “C:\Users\shikanon\Desktop\新建文件夹\venv\lib\site-packages\pymysql_auth.py”, line 142, in sha2_rsa_encrypt raise RuntimeError(“cryptography is required for sha256_password or caching_sha2_password”)RuntimeError: cryptography is required for sha256_password or caching_sha2_password只要安装`cryptography`包就可以了：```pip install cryptography windows 二进制包下载https://www.lfd.uci.edu/~gohlke/pythonlibs/]]></content>
      <categories>
        <category>技术博文</category>
        <category>编程语言</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Web开发</tag>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo使用文档]]></title>
    <url>%2F2017%2F%E8%BF%90%E7%BB%B4%2FHexo%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[快速开始安装 Hexo 完成后，请执行下列命令，Hexo 将会在指定文件夹中新建所需要的文件。 $ hexo init $ cd $ npm install 新建完成后，指定文件夹的目录如下： .├── _config.yml├── package.json├── scaffolds├── source| ├── _drafts| └── _posts└── themes 指令init$ hexo init [folder] 新建一个网站。如果没有设置 folder ，Hexo 默认在目前的文件夹建立网站。 new$ hexo new [layout] &lt;title&gt; 新建一篇文章。如果没有设置 layout 的话，默认使用 _config.yml 中的 default_layout 参数代替。如果标题包含空格的话，请使用引号括起来。 generate$ hexo generate 生成静态文件。 选项 描述 -d, --deploy 文件生成后立即部署网站 -w, --watch 监视文件变动 该命令可以简写为$ hexo g publish$ hexo publish [layout] &lt;filename&gt; 发表草稿。 server$ hexo server 启动服务器。默认情况下，访问网址为： http://localhost:4000/。 选项 描述 -p, --port 重设端口 -s, --static 只使用静态文件 -l, --log 启动日记记录，使用覆盖记录格式 deploy$ hexo deploy 部署网站。 参数 描述 -g, --generate 部署之前预先生成静态文件 该命令可以简写为：$ hexo d render$ hexo render &lt;file1&gt; [file2] ... 渲染文件。 参数 描述 -o, --output 设置输出路径 migrate$ hexo migrate &lt;type&gt; 从其他博客系统 迁移内容。 clean$ hexo clean 清除缓存文件 (db.json) 和已生成的静态文件 (public)。 在某些情况（尤其是更换主题后），如果发现您对站点的更改无论如何也不生效，您可能需要运行该命令。 list$ hexo list &lt;type&gt; 列出网站资料。 version$ hexo version 显示 Hexo 版本。 选项安全模式$ hexo --safe 在安全模式下，不会载入插件和脚本。当您在安装新插件遭遇问题时，可以尝试以安全模式重新执行。 调试模式$ hexo --debug 在终端中显示调试信息并记录到 debug.log。当您碰到问题时，可以尝试用调试模式重新执行一次，并 提交调试信息到 GitHub。 简洁模式$ hexo --silent 隐藏终端信息。 自定义配置文件的路径$ hexo --config custom.yml 自定义配置文件的路径，执行后将不再使用 _config.yml。 显示草稿$ hexo --draft 显示 source/_drafts 文件夹中的草稿文章。 自定义 CWD$ hexo --cwd /path/to/cwd 自定义当前工作目录（Current working directory）的路径。 写作你可以执行下列命令来创建一篇新文章。 $ hexo new [layout] &lt;title&gt; 您可以在命令中指定文章的布局（layout），默认为 post，可以通过修改 _config.yml 中的 default_layout 参数来指定默认布局。 布局（Layout）Hexo 有三种默认布局：post、page 和 draft，它们分别对应不同的路径，而您自定义的其他布局和 post 相同，都将储存到 source/_posts 文件夹。 布局 路径 post source/_posts page source draft source/_drafts 如果你不想你的文章被处理，你可以将 Front-Matter 中的layout: 设为 false 。 文件名称Hexo 默认以标题做为文件名称，但您可编辑 new_post_name 参数来改变默认的文件名称，举例来说，设为 :year-:month-:day-:title.md 可让您更方便的通过日期来管理文章。 变量 描述 :title 标题（小写，空格将会被替换为短杠） :year 建立的年份，比如， 2015 :month 建立的月份（有前导零），比如， 04 :i_month 建立的月份（无前导零），比如， 4 :day 建立的日期（有前导零），比如， 07 :i_day 建立的日期（无前导零），比如， 7 草稿刚刚提到了 Hexo 的一种特殊布局：draft，这种布局在建立时会被保存到 source/_drafts 文件夹，您可通过 publish 命令将草稿移动到 source/_posts 文件夹，该命令的使用方式与 new 十分类似，您也可在命令中指定 layout 来指定布局。 $ hexo publish [layout] &lt;title&gt; 草稿默认不会显示在页面中，您可在执行时加上 --draft 参数，或是把 render_drafts 参数设为 true 来预览草稿。 模版（Scaffold）在新建文章时，Hexo 会根据 scaffolds 文件夹内相对应的文件来建立文件，例如： $ hexo new photo "My Gallery" 在执行这行指令时，Hexo 会尝试在 scaffolds 文件夹中寻找 photo.md，并根据其内容建立文章，以下是您可以在模版中使用的变量： 变量 描述 layout 布局 title 标题 date 文件建立日期]]></content>
      <categories>
        <category>技术博文</category>
        <category>命令工具</category>
      </categories>
      <tags>
        <tag>入门教程</tag>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习从小白到入门 —— 基于keras的深度学习基本概念讲解]]></title>
    <url>%2F2017%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2FLearnOfDeepLearning%2F</url>
    <content type="text"><![CDATA[深度学习 Author: shikanonCreateTime: 2017/2/13 目录 1.softmax 2.损失函数 3.激活函数 4.sigmoid 5.ReLu 6.学习速率 7.Dropout 一、基础篇神经网络中的每个神经元 对其所有的输入进行加权求和，并添加一个被称为偏置（bias） 的常数，然后通过一些非线性激活函数来反馈结果。 数据集我们采用深度学习界的Hello-Word———— MNIST手写数字数据集，学习从第一个softmax开始。 1. softmaxsoftmax主要用来做多分类问题，是logistic回归模型在多分类问题上的推广，softmax 公式： 当k=2时，转换为逻辑回归形式。 softmax一般作为神经网络最后一层，作为输出层进行多分类，Softmax的输出的每个值都是&gt;=0，并且其总和为1，所以可以认为其为概率分布。 softmax 示意图 softmax 输出层示意图 %pylab inline Populating the interactive namespace from numpy and matplotlib from IPython.display import SVGfrom keras.datasets import mnistfrom keras.models import Sequentialfrom keras.layers import Dense, Dropout, Activation, Reshapefrom keras.optimizers import SGD, Adamfrom keras.utils.visualize_util import model_to_dotfrom keras.utils import np_utilsimport matplotlib.pyplot as pltimport tensorflow as tfimport pandas as pd Using TensorFlow backend. #设置随机数种子,保证实验可重复import numpy as npnp.random.seed(0)#设置线程THREADS_NUM = 20tf.ConfigProto(intra_op_parallelism_threads=THREADS_NUM)(X_train, Y_train),(X_test, Y_test) = mnist.load_data()print('原数据结构：')print(X_train.shape, Y_train.shape)print(X_test.shape, Y_test.shape)#数据变换#分为10个类别nb_classes = 10x_train_1 = X_train.reshape(60000, 784)#x_train_1 /= 255#x_train_1 = x_train_1.astype('float32')y_train_1 = np_utils.to_categorical(Y_train, nb_classes)print('变换后的数据结构：')print(x_train_1.shape, y_train_1.shape)x_test_1 = X_test.reshape(10000, 784)y_test_1 = np_utils.to_categorical(Y_test, nb_classes)print(x_test_1.shape, y_test_1.shape) 原数据结构： ((60000, 28, 28), (60000,)) ((10000, 28, 28), (10000,)) 变换后的数据结构： ((60000, 784), (60000, 10)) ((10000, 784), (10000, 10)) # 构建一个softmax模型# neural network with 1 layer of 10 softmax neurons## · · · · · · · · · · (input data, flattened pixels) X [batch, 784] # 784 = 28 * 28# \x/x\x/x\x/x\x/x\x/ -- fully connected layer (softmax) W [784, 10] b[10]# · · · · · · · · Y [batch, 10]# The model is:## Y = softmax( X * W + b)# X: matrix for 100 grayscale images of 28x28 pixels, flattened (there are 100 images in a mini-batch)# W: weight matrix with 784 lines and 10 columns# b: bias vector with 10 dimensions# +: add with broadcasting: adds the vector to each line of the matrix (numpy)# softmax(matrix) applies softmax on each line# softmax(line) applies an exp to each value then divides by the norm of the resulting line# Y: output matrix with 100 lines and 10 columnsmodel = Sequential()model.add(Dense(nb_classes, input_shape=(784,)))#全连接，输入784维度, 输出10维度，需要和输入输出对应model.add(Activation('softmax'))sgd = SGD(lr=0.005)#binary_crossentropy，就是交叉熵函数model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])#model 概要model.summary() ____________________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ==================================================================================================== dense_1 (Dense) (None, 10) 7850 dense_input_1[0][0] ____________________________________________________________________________________________________ activation_1 (Activation) (None, 10) 0 dense_1[0][0] ==================================================================================================== Total params: 7,850 Trainable params: 7,850 Non-trainable params: 0 ____________________________________________________________________________________________________ SVG(model_to_dot(model).create(prog='dot', format='svg')) from keras.callbacks import Callback, TensorBoardimport tensorflow as tf#构建一个记录的loss的回调函数class LossHistory(Callback): def on_train_begin(self, logs=&#123;&#125;): self.losses = [] def on_batch_end(self, batch, logs=&#123;&#125;): self.losses.append(logs.get('loss'))# 构建一个自定义的TensorBoard类，专门用来记录batch中的数据变化class BatchTensorBoard(TensorBoard): def __init__(self,log_dir='./logs', histogram_freq=0, write_graph=True, write_images=False): super(BatchTensorBoard, self).__init__() self.log_dir = log_dir self.histogram_freq = histogram_freq self.merged = None self.write_graph = write_graph self.write_images = write_images self.batch = 0 self.batch_queue = set() def on_epoch_end(self, epoch, logs=None): pass def on_batch_end(self,batch,logs=None): logs = logs or &#123;&#125; self.batch = self.batch + 1 for name, value in logs.items(): if name in ['batch', 'size']: continue summary = tf.Summary() summary_value = summary.value.add() summary_value.simple_value = float(value) summary_value.tag = "batch_" + name if (name,self.batch) in self.batch_queue: continue self.writer.add_summary(summary, self.batch) self.batch_queue.add((name,self.batch)) self.writer.flush() tensorboard = TensorBoard(log_dir='/home/tensorflow/log/softmax/epoch')my_tensorboard = BatchTensorBoard(log_dir='/home/tensorflow/log/softmax/batch')model.fit(x_train_1, y_train_1, nb_epoch=20, verbose=0, batch_size=100, callbacks=[tensorboard, my_tensorboard]) &lt;keras.callbacks.History at 0xa86d650&gt; 损失函数损失函数（loss function），是指一种将一个事件（在一个样本空间中的一个元素）映射到一个表达与其事件相关的经济成本或机会成本的实数上的一种函数，在统计学中损失函数是一种衡量损失和错误（这种损失与“错误地”估计有关，如费用或者设备的损失）程度的函数。 交叉熵（cross-entropy）就是神经网络中常用的损失函数。 交叉熵性质： （1）非负性。 （2）当真实输出a与期望输出y接近的时候，代价函数接近于0.(比如y=0，a～0；y=1，a~1时，代价函数都接近0)。 一个比较简单的理解就是使得 预测值Yi和真实值Y’ 对接近，即两者的乘积越大，coss-entropy越小。 交叉熵和准确度变化图像可以看 TensorBoard 。 梯度下降如果对于所有的权重和所有的偏置计算交叉熵的偏导数，就得到一个对于给定图像、标签和当前权重和偏置的「梯度」，如图所示： 我们希望损失函数最小，也就是需要到达交叉熵最小的凹点的低部。在上图中，交叉熵被表示为一个具有两个权重的函数。 而学习速率，即在梯度下降中的步伐大小。 #模型的测试误差指标print(model.metrics_names)# 对测试数据进行测试model.evaluate(x_test_1, y_test_1, verbose=1, batch_size=100) [&apos;loss&apos;, &apos;acc&apos;] 9800/10000 [============================&gt;.] - ETA: 0s [0.87580669939517974, 0.94387999653816224] 上面，我们探索了softmax对多分类的支持和理解，知道softmax可以作为一个输出成层进行多分类任务。 但是，这种分类任务解决的都是线性因素形成的问题，对于非线性的，特别是异或问题，如何解决呢？ 这时，一种包含多层隐含层的深度神经网络的概念被提出。 3. 激活函数激活函数（activation function）可以使得模型加入非线性因素的。 解决非线性问题有两个办法：线性变换、引入非线性函数。 （1）线性变换(linear transformation) 原本一个线性不可分的模型如：X^2 + Y^2 = 1 其图形如下图所示： fig = plt.figure(0)degree = np.random.rand(50)*np.pi*2x_1 = np.cos(degree)*np.random.rand(50)y_1 = np.sin(degree)*np.random.rand(50)x_2 = np.cos(degree)*(1+np.random.rand(50))y_2 = np.sin(degree)*(1+np.random.rand(50))# x_3 和 y_3 就是切分线t = np.linspace(0,np.pi*2,50)x_3 = np.cos(t)y_3 = np.sin(t)scatter(x_1,y_1,c='red',s=50,alpha=0.4,marker='o')scatter(x_2,y_2,c='black',s=50,alpha=0.4,marker='o')plot(x_3,y_3) [&lt;matplotlib.lines.Line2D at 0x86c7510&gt;] 将坐标轴进行高维变换，横坐标变成X^2，纵坐标变成 Y^2，这是表达式变为了 X + Y = 1，这样，原来的非线性问题，就变成了一个线性可分的问题，变成了一个简单的一元一次方程了。 详细可以参见下图： fig2 = plt.figure(1)#令新的横坐标变成x^2,纵坐标变成 Y^2x_4 = x_1**2y_4 = y_1**2x_5 = x_2**2y_5 = y_2**2# 这样就可以构建一个一元线性方程进行拟合x_6 = np.linspace(-1,2,50)y_6 = 1 - x_6scatter(x_4,y_4,c='red',s=50,alpha=0.4,marker='o')scatter(x_5,y_5,c='black',s=50,alpha=0.4,marker='o')plot(x_6,y_6) [&lt;matplotlib.lines.Line2D at 0x984bf10&gt;] （2）引入非线性函数 异或是一种基于二进制的位运算，用符号XOR 表示(Python中的异或操作符为 ^ )，其运算法则是对运算符两侧数的每一个二进制位，同值取0，异值取1。 下面是一个典型的异或表： table = &#123;'x':[1,0,1,0],'y':[1,0,0,1]&#125;df = pd.DataFrame(table)df['z'] = df['x']^df['y']df x y z 0 1 1 0 1 0 0 0 2 1 0 1 3 0 1 1 x = 1, y = 1, 则 z = 0 x = 0, y = 0, 则 z = 0 x = 1, y = 0, 则 z = 1 x = 0, y = 1, 则 z = 1 … 其图形如下： fig3 = plt.figure(2)groups = df.groupby('z')for name, group in groups: scatter(group['x'],group['y'],label=name,s=50,marker='o') 那么如果可以构建一个函数拟合这样的图形呢？即如何构建一个f()，使得：f(x,y)=z呢？ 为了解决问题，我们来构建一个两层的神经网络，该神经网络有两个激活函数，F(x,y)和 H(x,y), 具体如下图所示： F(x,y)为一个阈值为1的阈值函数： 即：当AX+BY&gt;1时候,F(x,y) = 1;否则为0；if AX+BY &gt; 1: F = 1else: F = 0 H(x,y）为一个阈值为0的阈值函数：if AX+BY &gt; 0: H = 1else: H = 0 图中线的数字表示权重值， - 对于(1,1)的点，第二层从左到右隐藏层的值分别为(1,1,1),最后输出为(1,1,1)*(1,-2,1)=0；- 对于(0,0)的点，第二层从左到右隐藏层的值分别为(0,0,0),最后输出为(0,0,0)*(1,-2,1)=0；- 对于(1,0)的点，第二层从左到右隐藏层的值分别为(1,0,0),最后输出为(1,0,0)*(1,-2,1)= 1；- 对于(0,1)的点，第二层从左到右隐藏层的值分别为(0,0,1),最后输出为(0,0,1)*(1,-2,1)= 1； first_hidder_layer_table = &#123;'x':[1,0,1,0],'y':[1,0,0,0],'z':[1,0,0,1],'output':[0,0,1,1]&#125;first_hidder_layer_data = pd.DataFrame(first_hidder_layer_table)first_hidder_layer_data output x y z 0 0 1 1 1 1 0 0 0 0 2 1 1 0 0 3 1 0 0 1 这样我们就构建出了一个可以计算拟合的函数了。 我们观察一下第一个隐含层，其总共有三个维度，三个权重值，从输入层到第一层，实际上，就是从将一个二维的数组变成一个三维数组，从而实现线性切分。 图形化解释： from mpl_toolkits.mplot3d import Axes3Dfig4 = plt.figure(3)ax = fig4.add_subplot(111, projection='3d')groups = first_hidder_layer_data.groupby('output')for name, group in groups: ax.scatter(group['x'],group['y'],group['z'],label=name,c=np.random.choice(['black','blue']),s=50,marker='o')ax.set_xlabel('X Label')ax.set_ylabel('Y Label')ax.set_zlabel('Z Label') &lt;matplotlib.text.Text at 0xb7b0d90&gt; 经过变换后的数据是线性可分的（n维，比如本例中可以用平面将两个不同颜色的点切分） 更多的操作可以参考tensorflow提供的一个神经网络的网页小程序，通过自己调整程序参数可以更深刻理解神经网络、激活函数的作用。 演示网址： http://playground.tensorflow.org/ 可以自己建立一个小型神经网络帮助理解。 4. sigmoidsigmoid是一个用来做二分类的”S”形逻辑回归曲线 sigmoid公式： sigmoid图像： 其抑制两头,对中间细微变化敏感，因此sigmoid函数作为最简单常用的神经网络激活层被使用。 优点： （1）输出范围(0,1)，数据在传递的过程中不容易发散 （2）单向递增 （3）易求导 sigmod有个缺点，sigmoid函数反向传播时，很容易就会出现梯度消失,在接近饱和区的时候，导数趋向0，会变得非常缓慢。因此，在优化器选择时选用Adam优化器。 Adam 也是基于梯度下降的方法，但是每次迭代参数的学习步长都有一个确定的范围，不会因为很大的梯度导致很大的学习步长，参数的值比较稳定。有利于降低模型收敛到局部最优的风险，而SGD容易收敛到局部最优，如果下面代码中的optimizer改成SGD的化，在一次epoch后就acc值不会改变了，陷入局部最优 # 构建一个五层sigmod全连接神经网络# neural network with 5 layers## · · · · · · · · · · (input data, flattened pixels) X [batch, 784] # 784 = 28*28# \x/x\x/x\x/x\x/x\x/ -- fully connected layer (sigmoid) W1 [784, 200] B1[200]# · · · · · · · · · Y1 [batch, 200]# \x/x\x/x\x/x\x/ -- fully connected layer (sigmoid) W2 [200, 100] B2[100]# · · · · · · · Y2 [batch, 100]# \x/x\x/x\x/ -- fully connected layer (sigmoid) W3 [100, 60] B3[60]# · · · · · Y3 [batch, 60]# \x/x\x/ -- fully connected layer (sigmoid) W4 [60, 30] B4[30]# · · · Y4 [batch, 30]# \x/ -- fully connected layer (softmax) W5 [30, 10] B5[10]# · Y5 [batch, 10]model = Sequential()model.add(Dense(200, input_shape=(784,)))#全连接，输入784维度, 输出10维度，需要和输入输出对应model.add(Activation('sigmoid'))model.add(Dense(100))# 除了首层需要设置输入维度，其他层只需要输入输出维度就可以了，输入维度自动继承上层。model.add(Activation('sigmoid'))model.add(Dense(60))model.add(Activation('sigmoid'))model.add(Dense(30)) #model.add(Activation('sigmoid'))和model.add(Dense(30))可以合并写出model.add(Activation('sigmoid'))#model.add(Dense(30,activation='softmax'))model.add(Dense(10))model.add(Activation('softmax'))sgd = Adam(lr=0.003)model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])#model 概要model.summary() ____________________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ==================================================================================================== dense_23 (Dense) (None, 200) 157000 dense_input_7[0][0] ____________________________________________________________________________________________________ activation_23 (Activation) (None, 200) 0 dense_23[0][0] ____________________________________________________________________________________________________ dense_24 (Dense) (None, 100) 20100 activation_23[0][0] ____________________________________________________________________________________________________ activation_24 (Activation) (None, 100) 0 dense_24[0][0] ____________________________________________________________________________________________________ dense_25 (Dense) (None, 60) 6060 activation_24[0][0] ____________________________________________________________________________________________________ activation_25 (Activation) (None, 60) 0 dense_25[0][0] ____________________________________________________________________________________________________ dense_26 (Dense) (None, 30) 1830 activation_25[0][0] ____________________________________________________________________________________________________ activation_26 (Activation) (None, 30) 0 dense_26[0][0] ____________________________________________________________________________________________________ dense_27 (Dense) (None, 10) 310 activation_26[0][0] ____________________________________________________________________________________________________ activation_27 (Activation) (None, 10) 0 dense_27[0][0] ==================================================================================================== Total params: 185,300 Trainable params: 185,300 Non-trainable params: 0 ____________________________________________________________________________________________________ SVG(model_to_dot(model).create(prog='dot', format='svg')) tensorboard2 = TensorBoard(log_dir='/home/tensorflow/log/five_layer_sigmoid/epoch', histogram_freq=0)my_tensorboard2 = BatchTensorBoard(log_dir='/home/tensorflow/log/five_layer_sigmoid/batch')model.fit(x_train_1, y_train_1, nb_epoch=20, verbose=0, batch_size=100, callbacks=[my_tensorboard2, tensorboard2]) &lt;keras.callbacks.History at 0xf868a90&gt; #模型的测试误差指标print(model.metrics_names)# 对测试数据进行测试model.evaluate(x_test_1, y_test_1, verbose=1, batch_size=100) [&apos;loss&apos;, &apos;acc&apos;] 9800/10000 [============================&gt;.] - ETA: 0s [0.036339853547979147, 0.98736999988555907] 根据上面，我们可以看出，深度越深，效果越好。 但是，对于深层网络，sigmoid函数反向传播时，很容易就会出现梯度消失的情况从而无法完成深层网络的训练。在sigmoid接近饱和区时，变换非常缓慢，导数趋于0，减缓收敛速度。 5. ReLuReLu来自于对人脑神经细胞工作时的稀疏性的研究，在 Lennie,P.(2003)提出人脑神经元有95%－99%是闲置的，而更少工作的神经元意味着更小的计算复杂度，更不容易过拟合 修正线性单元(Rectified linear unit,ReLU)公式： $$ReLU\left(x\right)=\left\lbrace\begin{align}x, \quad x \gt 0 \cr0, \quad x \le 0\end{align}\right .$$ 其图像： ReLU具有线性、非饱和性，而其非饱和性使得网络可以自行引入稀疏性。 ReLU的使用解决了sigmoid梯度下降慢，深层网络的信息丢失的问题。 ReLU在训练时是非常脆弱的，并且可能会“死”。例如，经过ReLU神经元的一个大梯度可能导致权重更新后该神经元接收到任何数据点都不会再激活。如果发生这种情况，之后通过该单位点的梯度将永远是零。也就是说，ReLU可能会在训练过程中不可逆地死亡，并且破坏数据流形。如果学习率太高，大部分网络将会“死亡”（即，在整个训练过程中神经元都没有激活）。而设置一个适当的学习率，可以在一定程度上避免这一问题。 6. 学习速率上面说梯度下降的时候，说过学习速率其实就是梯度下降的步伐。因此，为了到达山谷，需要控制步伐的大小，即学习速率。 学习速率大小的调节一般取决于 loss 的变化幅度。 # neural network with 5 layers## · · · · · · · · · · (input data, flattened pixels) X [batch, 784] # 784 = 28*28# \x/x\x/x\x/x\x/x\x/ -- fully connected layer (relu) W1 [784, 200] B1[200]# · · · · · · · · · Y1 [batch, 200]# \x/x\x/x\x/x\x/ -- fully connected layer (relu) W2 [200, 100] B2[100]# · · · · · · · Y2 [batch, 100]# \x/x\x/x\x/ -- fully connected layer (relu) W3 [100, 60] B3[60]# · · · · · Y3 [batch, 60]# \x/x\x/ -- fully connected layer (relu) W4 [60, 30] B4[30]# · · · Y4 [batch, 30]# \x/ -- fully connected layer (softmax) W5 [30, 10] B5[10]# · Y5 [batch, 10]model = Sequential()model.add(Dense(200, input_shape=(784,)))#全连接，输入784维度, 输出10维度，需要和输入输出对应model.add(Activation('relu'))# 将激活函数sigmoid改为ReLUmodel.add(Dense(100))model.add(Activation('relu'))model.add(Dense(60))model.add(Activation('relu'))model.add(Dense(30)) model.add(Activation('relu'))model.add(Dense(10))model.add(Activation('softmax'))sgd = Adam(lr=0.001)model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])#model 概要model.summary() ____________________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ==================================================================================================== dense_16 (Dense) (None, 200) 157000 dense_input_4[0][0] ____________________________________________________________________________________________________ activation_16 (Activation) (None, 200) 0 dense_16[0][0] ____________________________________________________________________________________________________ dense_17 (Dense) (None, 100) 20100 activation_16[0][0] ____________________________________________________________________________________________________ activation_17 (Activation) (None, 100) 0 dense_17[0][0] ____________________________________________________________________________________________________ dense_18 (Dense) (None, 60) 6060 activation_17[0][0] ____________________________________________________________________________________________________ activation_18 (Activation) (None, 60) 0 dense_18[0][0] ____________________________________________________________________________________________________ dense_19 (Dense) (None, 30) 1830 activation_18[0][0] ____________________________________________________________________________________________________ activation_19 (Activation) (None, 30) 0 dense_19[0][0] ____________________________________________________________________________________________________ dense_20 (Dense) (None, 10) 310 activation_19[0][0] ____________________________________________________________________________________________________ activation_20 (Activation) (None, 10) 0 dense_20[0][0] ==================================================================================================== Total params: 185,300 Trainable params: 185,300 Non-trainable params: 0 ____________________________________________________________________________________________________ SVG(model_to_dot(model).create(prog='dot', format='svg')) tensorboard3 = TensorBoard(log_dir='/home/tensorflow/log/five_layer_relu/epoch', histogram_freq=0)my_tensorboard3 = BatchTensorBoard(log_dir='/home/tensorflow/log/five_layer_relu/batch')model.fit(x_train_1, y_train_1, nb_epoch=30, verbose=0, batch_size=100, callbacks=[my_tensorboard3, tensorboard3]) &lt;keras.callbacks.History at 0xe3c6d50&gt; #模型的测试误差指标print(model.metrics_names)# 对测试数据进行测试model.evaluate(x_test_1, y_test_1, verbose=1, batch_size=100) [&apos;loss&apos;, &apos;acc&apos;] 9600/10000 [===========================&gt;..] - ETA: 0s [0.017244604945910281, 0.99598000288009647] 7.Dropout 运行目录下的mnist_2.1_five_layers_relu_lrdecay.py 随着迭代次数的增加，我们可以发现测试数据的loss值和训练数据的loss存在着巨大的差距， 随着迭代次数增加，train loss 越来越好，但test loss 的结果确越来越差，test loss 和 train loss 差距越来越大，模型开始过拟合。 Dropout是指对于神经网络单元按照一定的概率将其暂时从网络中丢弃,从而解决过拟合问题。 可以对比mnist_2.1_five_layers_relu_lrdecay.py 和 加了dropout的/mnist_2.2_five_layers_relu_lrdecay_dropout.py的结果 # neural network with 5 layers## · · · · · · · · · · (input data, flattened pixels) X [batch, 784] # 784 = 28*28# \x/x\x/x\x/x\x/x\x/ ✞ -- fully connected layer (relu+dropout) W1 [784, 200] B1[200]# · · · · · · · · · Y1 [batch, 200]# \x/x\x/x\x/x\x/ ✞ -- fully connected layer (relu+dropout) W2 [200, 100] B2[100]# · · · · · · · Y2 [batch, 100]# \x/x\x/x\x/ ✞ -- fully connected layer (relu+dropout) W3 [100, 60] B3[60]# · · · · · Y3 [batch, 60]# \x/x\x/ ✞ -- fully connected layer (relu+dropout) W4 [60, 30] B4[30]# · · · Y4 [batch, 30]# \x/ -- fully connected layer (softmax) W5 [30, 10] B5[10]# · Y5 [batch, 10]model = Sequential()model.add(Dense(200, input_shape=(784,)))#全连接，输入784维度, 输出10维度，需要和输入输出对应model.add(Activation('relu'))# 将激活函数sigmoid改为ReLUmodel.add(Dense(100))model.add(Activation('relu'))model.add(Dropout(0.25))# 添加一个dropout层, 随机移除25%的单元model.add(Dense(60))model.add(Activation('relu'))model.add(Dropout(0.25))model.add(Dense(30)) model.add(Activation('relu'))model.add(Dropout(0.25))model.add(Dense(10))model.add(Activation('softmax'))sgd = Adam(lr=0.001)model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])#model 概要model.summary() ____________________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ==================================================================================================== dense_171 (Dense) (None, 200) 157000 dense_input_35[0][0] ____________________________________________________________________________________________________ activation_171 (Activation) (None, 200) 0 dense_171[0][0] ____________________________________________________________________________________________________ dense_172 (Dense) (None, 100) 20100 activation_171[0][0] ____________________________________________________________________________________________________ activation_172 (Activation) (None, 100) 0 dense_172[0][0] ____________________________________________________________________________________________________ dropout_100 (Dropout) (None, 100) 0 activation_172[0][0] ____________________________________________________________________________________________________ dense_173 (Dense) (None, 60) 6060 dropout_100[0][0] ____________________________________________________________________________________________________ activation_173 (Activation) (None, 60) 0 dense_173[0][0] ____________________________________________________________________________________________________ dropout_101 (Dropout) (None, 60) 0 activation_173[0][0] ____________________________________________________________________________________________________ dense_174 (Dense) (None, 30) 1830 dropout_101[0][0] ____________________________________________________________________________________________________ activation_174 (Activation) (None, 30) 0 dense_174[0][0] ____________________________________________________________________________________________________ dropout_102 (Dropout) (None, 30) 0 activation_174[0][0] ____________________________________________________________________________________________________ dense_175 (Dense) (None, 10) 310 dropout_102[0][0] ____________________________________________________________________________________________________ activation_175 (Activation) (None, 10) 0 dense_175[0][0] ==================================================================================================== Total params: 185,300 Trainable params: 185,300 Non-trainable params: 0 ____________________________________________________________________________________________________ SVG(model_to_dot(model).create(prog='dot', format='svg')) tensorboard4 = TensorBoard(log_dir='/home/tensorflow/log/five_layer_relu_dropout/epoch')my_tensorboard4 = BatchTensorBoard(log_dir='/home/tensorflow/log/five_layer_relu_dropout/batch')model.fit(x_train_1, y_train_1, nb_epoch=30, verbose=0, batch_size=100, callbacks=[tensorboard4, my_tensorboard4]) &lt;keras.callbacks.History at 0x27819610&gt; #模型的测试误差指标print(model.metrics_names)# 对测试数据进行测试model.evaluate(x_test_1, y_test_1, verbose=1, batch_size=100) [&apos;loss&apos;, &apos;acc&apos;] 9900/10000 [============================&gt;.] - ETA: 0s [0.025450729207368569, 0.99462999999523161]]]></content>
      <categories>
        <category>技术博文</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>入门教程</tag>
        <tag>深度学习</tag>
        <tag>算法</tag>
        <tag>Keras</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IoT的PaaS平台]]></title>
    <url>%2F2017%2F%E6%9E%B6%E6%9E%84%2FIoT%E7%9A%84PaaS%E5%B9%B3%E5%8F%B0%2F</url>
    <content type="text"><![CDATA[演讲稿（图文版） 文字版IoT与云计算为什么提IoT与云计算？ 1）困扰物联网发展的瓶颈之一物联网平台随着云计算的发展而得到了长足的进步。以AWS提供的IoT服务为例，它可以支持数十亿台设备和数万亿条消息，并且可以对这些消息进行处理并将其安全可靠地路由至终端节点和其他设备，而且这样的一个平台可以极大简化开发物联网应用的复杂性。 2）低功耗广域网（LPWAN）在过去一年进步惊人。相比于短距技术（蓝牙、Wi-Fi、ZigBee等），LPWA无需额外部署汇聚网关，大大降低了用户的部署成本和复杂度，应用终端即插即用消除了部署限制。 3）NB-IoT技术协议获得了3GPP无线接入网（RAN）技术规范组会议通过，已经具备了在2017年投入商用的条件。LoRa作为一种无线技术以较低功耗远距离通信，对建筑物的穿透力很强。LoRa的技术特点更适合于低成本大规模的物联网部署，例如智慧城市。 IoT开发的痛点IoT开发的痛点： 1）避免“重复造轮子”，将常用的功能组件和整合成统一的平台接口，集中精力解决核心业务研发。 2）降低使用IoT开发的“门槛”，将分布式集群部署、弹性扩容、安全等难题交由统一的平台处理。 3）简化大数据开发流程，将大数据分析、数据可视化等功能以云端API的形式封装，供业务人员使用，使业务员无需关注大数据底层架构和算法。 PaaS主要解决的问题IoT PaaS主要解决的问题： 1）使得IoT开发转向serverless架构，降低使用IoT开发的“门槛”，让系统钟最复杂的扩展性、高可用性、任务调度以及运维工作用服务提供者转为管理，实现no-Architecture和no-Ops转变。 2）做数据运营，类似DaaS(Data as a Service)。作为一个开箱即用的工具自动针对用户和设备使用行为进行分析， 以指导产品功能改进、营销策略实施、增值服务运营。 3）提供成熟和标准化的平台接口，如账号体系、设备绑定管理、事件通知引擎、OTA管理、定时任务引擎、设备分享、微信接入等，避免“重复造轮子”。 4)网络功能虚拟化NFV(Network Function Virtualization)。通过软硬件解耦及功能抽象，使网络设备功能不再依赖于专用硬件，资源可以充分灵活共享，实现新业务的快速开发和部署。 发展方向一）发展Serverless架构。a）应用逻辑并非全部在服务端实现，而是采用FAAS（Function as a Service）架构，通过功能组合来实现应用程序逻辑。b）Serverless架构能够让开发者在构建应用的过程中无需关注计算资源的获取和运维，由平台来按需分配计算资源并保证应用执行的SLA，按照调用次数进行计费，有效的节省应用成本。 二）数据运营。a）实现DaaS（Data as a Service）的架构。将数据采集、标准化、聚合和分析放在一个集中化的位置，使得数据管理更集中化和标准化，让IoT的研究和开发专注于核心业务，可以快速的探索数据。b）将各类算法、可视化工具整合成多个相互独立功能组件，并以API服务的形式向外提供服务。c）搭建数据中心，负责时序存储、数据处理群集、数据API网关访问，以及可视化Web服务等任务。 三）SDN技术（Software Defined Network）与NFV技术(Network Function Virtualization)a）控制转发分离架构。通过openflow等将网络设备控制面与数据面分离开来，由集中的控制器管理，无须依赖底层网络设备，控制权完全开放，用户可以自定义任何想实现的网络路由和传输规则策略，从而实现了网络流量的灵活控制，使网络作为管道变得更加智能。 平台架构设计IoT PaaS设计架构。左侧是数据中心，右侧是IoT网关。使用OpenStack作为承载所有控制服务的云，网关使用Kubernetes对服务进行微分隔，为了实现多租户功能并确保不同传感器的安全，使用OpenContrail将两端连接在一起，并为Kubernetes POD和OpenStack Project虚拟机提供网络分隔。 网关操作系统和数据中心边缘路由器之间的VPN连接可以看作该平台的最底层，该层之上是SDN，在这里可以通过OpenContrail实现虚拟机（OpenStack云）和容器（网关）之间的直接通信。 数据中心数据中心是整个IoT平台的中心管理点。其中包含OpenStack IaaS云，以及伴随云同时运行的虚拟机和SDN控制面板。这些计算机负责了时序存储、数据处理群集、数据API网关访问，以及可视化Web服务等任务。 数据中心包含下列服务： 1）管理服务。硬件群集中运行的虚拟机承载了所有控制服务：OpenStack控制器、OpenContrail控制器（SDN）、Kubernetes主机、Salt主机。 2）OpenStack云。OpenStack项目为数据库、大数据处理，以及数据可视化所涉及的不同虚拟机服务提供了分隔和划分。这个云运行在KVM hypervisor之上，通过OpenContrail的Neutron插件实现网络连接。 3）边缘路由器。OpenContrail会与数据中心边缘路由器创建iBGP对端，这样便可以将OpenStack虚拟机和Kubernetes POD的动态网络路由传播至IoT网关。该设备可以MPLSoverGRE或MPLSoverUDP方式创建标准的L3VPN。 网关IoT网关可位于任何目标位置，例如街灯、工厂机械、家用电器中。SDN提供的传输层将远程IoT网关与云服务连接在一起。网关可支持多平台，甚至可能混合使用了x86/64和ARM设备。该技术可以通过一个网关为多个客户承载多种传感器平台，这一特性是通过微服务分隔（Docker容器）和Kubernetes对多租户的支持实现的。整个平台可以提供可伸缩的多租户环境，无论多远距离的应用程序和传感器都可位于同一个网络中。 远程网关包含下列组件： 1）Kubernetes MinionKubernetes minion负责与数据中心内的Kubernetes主机通信，并负责管理Kubeletand POD。Kubelet使用了Opencontrail插件，借此将Docker容器与vRouter代理连接在一起。 2）Kubernetes PODKubernetes POD是连接到vRouter的一个或多个Docker容器。POD可按照标签进行分隔，这样即可启动不同应用程序，从不同消息总线以IQRF、蓝牙，或GPIO方式读取数据。 3）Docker容器Kubernetes POD中的Docker容器为整个平台提供了极大的收益，可在无需特别安装的情况下支持任何类型的操作系统。例如，IQRF使用了某一版本的简单Java应用程序，可通过容器在几分钟内交付，并且不会与网关本身的操作系统产生不匹配的情况。 借助OpenContrail覆盖的帮助，OpenStack云内部的虚拟机可以通过L2或L3私有网络联系位于任何地理位置的Docker容器，使得应用程序开发者可以使用标准云平台中用过的同一套工具。 传感器直接连接至容器，数据在Docker容器中处理后发送至Graphite时序数据库，最后以图形化方式实时呈现数据。]]></content>
      <categories>
        <category>演讲稿展示</category>
        <category>物联网</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>物联网</tag>
        <tag>Paas</tag>
        <tag>Serverless</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[KVM虚拟机静态迁移]]></title>
    <url>%2F2016%2F%E8%BF%90%E7%BB%B4%2FKVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%9D%99%E6%80%81%E8%BF%81%E7%A7%BB%2F</url>
    <content type="text"><![CDATA[KVM 背景简介KVM 全称是 基于内核的虚拟机（Kernel-based Virtual Machine），它是一个 Linux 的一个内核模块，该内核模块使得 Linux 变成了一个 Hypervisor，KVM 是基于虚拟化扩展（Intel VT 或者 AMD-V）的 X86 硬件的开源的 Linux 原生的全虚拟化解决方案。KVM 中，虚拟机被实现为常规的 Linux 进程，由标准 Linux 调度程序进行调度；虚机的每个虚拟 CPU 被实现为一个常规的 Linux 进程。这使得 KMV 能够使用 Linux 内核的已有功能。但是，KVM 本身不执行任何硬件模拟，需要客户空间程序通过 /dev/kvm 接口设置一个客户机虚拟服务器的地址空间，向它提供模拟的 I/O，并将它的视频显示映射回宿主的显示屏。 Guest：客户机系统，包括CPU（vCPU）、内存、驱动（Console、网卡、I/O 设备驱动等），被 KVM 置于一种受限制的 CPU 模式下运行。 KVM：运行在内核空间，提供CPU 和内存的虚级化，以及客户机的 I/O 拦截。Guest 的 I/O 被 KVM 拦截后，交给 QEMU 处理。 QEMU：修改过的为 KVM 虚机使用的 QEMU 代码，运行在用户空间，提供硬件 I/O 虚拟化，通过 IOCTL /dev/kvm 设备和 KVM 交互。 安装virsh、qemu sudo apt-get install qemu-kvm libvirt 拷贝image文件先查看下要img的格式：qemu-img info devstack-controller-clone.img image: devstack-controller.imgfile format: rawvirtual size: 120G (128849125376 bytes)disk size: 120G[root@ue211 images]# qemu-img info devstack-controller.imgimage: devstack-controller.imgfile format: rawvirtual size: 120G (128849018880 bytes)disk size: 120G 说明这是一个raw格式的image，image文件通常是raw，相对较大，不适合传输，所以先把raw转为qcow2格式:qemu-img convert -c -f raw -O qcow2 devstack-controller.img devstack-controller-clone2.img 看看转换后的格式：qemu-img info devstack-controller-clon2e.img image: devstack-controller-clone2.imgfile format: qcow2virtual size: 120G (128849018880 bytes)disk size: 3.5Gcluster_size: 65536Format specific information: compat: 1.1 lazy refcounts: false 用scp传到目标地址上：scp /var/lib/libvirt/images/devstack-controller-clone2.img root@192.168.0.12:/var/lib/libvirt/images/devstack-controller-clone2.img 修改和拷贝配置文件导出配置文件： virsh dumpxml devstack-controller &gt; /home/devstack-controller.xml 或者直接找到路径拷贝也可以，centos下路径在：`` 修改配置文件，主要需要修改的地方有name、uuid、mac: &lt;name&gt;devstack-controller&lt;/name&gt;&lt;uuid&gt;4aba494c-6f6a-f992-2ec2-23795f6c4680&lt;/uuid&gt;&lt;mac address=&#39;52:54:00:49:03:d2&#39;/&gt; name表示虚拟机的名字 ,uuid表示id号，可以用uuid命令生成,mac表示网关mac地址, 如果是迁移到其他系统，其他机器上，还需要修改emulator、source file: &lt;emulator&gt;/usr/bin/kvm-spice&lt;/emulator&gt;&lt;source file=&#39;/var/lib/libvirt/images/devstack-controller-clone2.img&#39;/&gt; emulator表示kvm路径,source file 表示image路径 用scp传到目标地址上： scp /home/devstack-controller.xml root@192.168.0.12:/home/devstack-controller.xml 将配置文件和image都传到目标机后，将qcow2转换为raw： qemu-img convert -f qcow2 -O raw devstack-controller-clone2.img devstack-controller.img 启动虚拟机用virsh启动新的虚拟机 virsh define devstack-controller.xml 命令解说qemu-img convert [-c] [-e] [-f format] filename [-O output_format] output_filename qemu-img convert主要用来转换镜像格式，-c表示压缩，只有qcow和qcow2才有压缩，-f表示输入的格式,-O表示输出的格式]]></content>
      <categories>
        <category>技术博文</category>
        <category>系统运维</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>KVM</tag>
        <tag>虚拟化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于wifi的行为轨迹数据挖掘分享]]></title>
    <url>%2F2016%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2F%E5%9F%BA%E4%BA%8Ewifi%E7%9A%84%E8%A1%8C%E4%B8%BA%E8%BD%A8%E8%BF%B9%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%88%86%E4%BA%AB%2F</url>
    <content type="text"><![CDATA[演讲稿（图文版） 移动对象轨迹数据挖掘方法研究综述（文字版）系统框架 （1）数据层。用来收集相关移动对象的轨迹数据并存储在相应数据库中，工作包括移动对象轨迹数据的采集、清洗以及不同轨迹数据的集成。 （2）逻辑层。以移动对象轨迹数据为基础进行移动对象活动规律的挖掘，并对挖掘结果进行深入的分析。逻辑层上针对对象的轨迹数据可以分为四个层：微观层次的数据挖掘、宏观层次的数据挖掘、模式发现相关的数据挖掘、知识发现相关的数据挖掘。 （3）用户层。用户层主要包括用户的输入交互以及移动对象的数据挖掘的结果可视化展示两方面功能。展示主要包括：轨迹再现，挖掘结果的展示，相关数据的统计图表展示等。 方法层次（1）微观层次的数据挖掘，主要在移动对象轨迹数据内部，从采样点及采样时间的分布上来研究移动对象的活动特征。其包括轨迹的聚类分析、轨迹的分类分析、轨迹的异常检测分析、轨迹的异常检测分析、轨迹的索引建立。 （2）宏观层次的数据挖掘，通过利用微观分析的结果，或者微观层次分析的相关方法对移动对象的宏观活动进行发现，发现对象较为有意义的活动。其包括：对象的STPM 发现、兴趣区域发现、运动特征分析、对象的活动发现。 （3）模式发现相关的数据挖掘，主要在移动对象微观和宏观分析的基础上，研究对象活动的时间和空间特点来发现对象的活动规律，从庞杂琐碎的移动对象轨迹数据中分析出对象的活动规律和行为模式。 （4）知识发现相关的数据挖掘，整合已知的挖掘成果或先验知识并以此为基础进行高层次的知识发现，主要包括：移动对象活动的预测、移动对象时空知识推理、移动对象时空知识推理。 系统结构（1）数据预处理模块。对轨迹数据进行清洗和降噪等处理，增强移动对象轨迹挖掘相关方法的运行效率，主要包括：轨迹数据的清洗，轨迹数据的降噪以及轨迹识别等操作。 （2）轨迹数据的微观分析模块。从轨迹数据本身出发，研究移动对象的运动特点，通过轨迹数据的异常检测与轨迹的聚类来描述该模块在微观分析中的功能。 （3）轨迹数据的宏观分析模块。通过移动对象的兴趣活动发现、对象的兴趣路径发现两个方面的应用，对该模块的宏观轨迹数据分析过程进行描述。 （4）轨迹数据的模式发现模块。过移动对象的多粒度兴趣活动发现、对象活动的多粒度周期模式发现两个方面来对移动对象活动的模式进行发现和分析。 （5）轨迹数据的可视化分析模块。以轨迹数据的分析结果为基础，通过参数输入调整各种方法的计算，最后通过用户界面将结果展现出来。 关键技术移动对象轨迹数据挖掘的关键技术： （1）基于结构特征的轨迹微观数据分析技术。基于结构特征的轨迹微观数据分析技术主要以从轨迹数据入手，深入研究轨迹数据的特征，从而完成对轨迹结构的抽取、计算和分析。 （2）基于协同过滤的对象宏观活动分析技术。在轨迹微观分析的基础上，应用移动对象微观的分析方法，从中发现与识别已知兴趣区域，找到移动对象潜在的兴趣区域。 （3）基于多粒度的对象活动的模式发现技术。应用基于密度聚类的方法发现在特定轨迹上对象活动较为集中的热点区域，并标记为一个对象活动，记录活动的相关属性，通过明确时间粒度和表示和转化关系，实现移动对象的多粒度周期活动挖掘，发现关联的周期活动、周期的长度、间隔时间等信息。 基于结构特征的轨迹分析方法基于结构特征的轨迹数据分析方法主要可以分为 5 个步骤： （1）轨迹数据的加载、重构。对数据的降噪处理，构建索引结构，然后进行重构。 （2）轨迹数据的转角计算与划分。计算轨迹的转向角，设定转角阈值，根据转角阈值对轨迹进行划分，保证每个轨迹片段都具有相对平稳的结构特征。 （3）轨迹结构特征的抽取。对轨迹进行结构建模并抽取轨迹的结构特征，根据移动对象的运动特点以及轨迹相关属性，抽取速度、方向、转角、密度等 等特征对轨迹进行表示。 （4）轨迹的结构相似度计算。通过结构相似度计算，生成的轨迹结构相似度矩阵，并将计算结果应用到轨迹聚类和异常检测等方法上。 （5）结果检验和验证。对分析效果进行验证，通过设置不同的参数验证该方法的可靠性和性能。 基于协同过滤的移动对象兴趣活动发现流程基于协同过滤的移动对象兴趣活动发现步骤： （1）确定轨迹中的停留点。对移动对象轨迹数据进行Stop-Move点识别，确定轨迹中的停留点。 （2）发现兴趣区域。采用聚类方法将属于同一停留区域的Stop点聚集起来，发现移动对象的兴趣区域。 （3）构建兴趣区域集合。根据对单个移动对象的每个兴趣区域访问进行信息收集和标注，包括：移动对象标识、兴趣区域表示，访问时间、停留时长、访问次数等信息，形成移动对象的兴趣区域集合。 （4）找出重叠区域。找出不同移动对象的兴趣区域在地理空间上具有一定的重叠。 （5）发现潜在的兴趣活动以及感兴趣的路径。利用协同过滤计算重叠的区域出现的次数、发生时刻、停留的时间等的相似程度，确定相似程度较高的移动对象为相似的对象，以相似的移动对象为基础发现他们之间潜在的兴趣活动以及感兴趣的路径。 基于多粒度的对象活动的模式发现移动对象周期活动挖掘的步骤： （1）明确描述形式。对时间空间、时间单元、时刻、时间粒度等进行形式化描述，明确时间粒度的表示方式，以及不同粒度的转换关系。 （2）确定移动对象的活动，通过基于密度的聚类方式，发现移动对象频繁停留区域，标记移动对象对该区域的访问为一个对象活动，记录对象活动的相关属性信息。 （3）对移动对象单个活动进行周期模式挖掘。针对移动对象单个活动分析其发生的时间特征，形成对象活动序列，通过计算支持度对活动对象组的频繁模式进行筛选和评价，过滤发生概率较低的周期模式。 （4）对移动对象关联活动进行周期模式挖掘，通过应用基于对象单活动周期模式发现的结果，计算对象活动的关联程度，发现关联度较高的对象活动，通过构造最大子模式树的方式进行对象关联活动的发现，最后通过支持度、和时间修正值对挖掘的移动对象关联周期模式进行调整。 （5）对活动发生时间进行多粒度描述，发现更为精准、全面的周期模式。 基于wifi的用户生活模式挖掘（1）数据预处理。从wifi扫描列表提取数据，发现访问地点。 （2）构建移动图模型。基于用户在地点间的轨迹来构建移动图。 （3）基于地点时间特征的聚类质也叠加方法来识别所有用户的家和工作地点，通过分析用户在家和工作地的行为来理解用户作息规律 移动图模型构建 访问地点发现。将wifi扫描列表作为位置指纹，发现用户的访问地点，这些地点是逻辑地点。 停留点提取。每一个扫描列表都代表一个停留点，相似的停留点可能代表着用户对某个地点的多次访问，从原始wifi扫描列表数据中将代表停留点的扫描别表找出来，然后通过聚类将那些相近的停留点组合在一起便可Ｗ唯一表示一个访问地点。 停留点聚类。每一个停留点都含有一些固定且频繁出现的wifi组合，可表征该地点的部分特征，为了找到可表该地点全部特征的wifi组合，对相似的停留点进行聚类，得到的停留点簇便是用户长时间逗留的访问地点。 用户区域活动特征发现用户每天的轨迹其实就是移动图上由若干个访问地点构成的路径，用户规律性移动形成的大量路径将那些具有相似性质的结点联系起来，构成活动区域，在区域内结点之间联系紧密意味着用户移动较为频繁，而在区域间结点联系较为稀疏，意味着用户移动较少。 重要地点聚类。用户的重要地点发现问题可转为移动图中重要结点的发现问题，图中结点的重要性主要基于该结点与相邻结点的连接关系所展现的显著性，比如结点的度、最短路径和权值等基本属性。]]></content>
      <categories>
        <category>演讲稿展示</category>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>技术分享</tag>
        <tag>wifi</tag>
        <tag>行为轨迹</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pycon2016可视化爬虫技术分享]]></title>
    <url>%2F2016%2F%E6%9E%B6%E6%9E%84%2FPycon2016%E5%8F%AF%E8%A7%86%E5%8C%96%E7%88%AC%E8%99%AB%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB%2F</url>
    <content type="text"><![CDATA[这是Pycon2016的一份关于自研爬虫框架技术分享。 正文]]></content>
      <categories>
        <category>演讲稿展示</category>
        <category>网络爬虫</category>
      </categories>
      <tags>
        <tag>技术分享</tag>
        <tag>网络爬虫</tag>
        <tag>Python</tag>
        <tag>技术框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[扫楼小助手项目小结(1)]]></title>
    <url>%2F2016%2F%E6%9E%B6%E6%9E%84%2F%E6%89%AB%E6%A5%BC%E5%B0%8F%E5%8A%A9%E6%89%8B%E9%A1%B9%E7%9B%AE%E5%B0%8F%E7%BB%93-1%2F</url>
    <content type="text"><![CDATA[产品诞生背景 扫楼小助手是一款用于运营商业务推广的辅助工具，这个项目最早衍生于“智慧地产”的概念，某运营商研究院跟物业门禁公司合作，搞了一个智慧地产项目，实现了数据互联互通，希望可以利用数据做个内部使用的工具（主要由于数据敏感，不敢做外部工具）。研究院这边希望可以基于物业公司提供小区住户数据构建一套供内部业务推广的辅助工具，帮忙业务人员推销各类电信增值套餐，从而提升业绩。因为当时智慧地产的工作内容主要针对客户（开发商/物业公司）需求本身，对最终用户的电信业务推广或营销服务有所欠缺。同时电信内部已有的用户中，绝大部分为非电信用户，社区经理缺乏精准营销的有力武器，无法迅速找到异网目标客户进行业务推广或策反。因此，希望利用外部数据结合电信自身的数据资源开发一个实用的策反工具。 产品设计 首先，确定了项目的核心需求，是解决业务人员上门推广不清楚业务信息的问题，同时帮助业务经理了解整个片区的状况，可以清晰制定销售策略。因为这两个需求所面对的群体是不同的，因此，我们把他拆分为两个形态的应用：1、一个是给业务经理使用，侧重点是各类数据分析和图表的展示，为了他能够更好地从总体把握情况；2、一个是给一线业务人员使用，侧重点是要求简单方便，主要用来查询信息，可以快速了解客户的状况，根据不同住客应用不同的话术推销，同时可以记录客户的意向和拜访情况； 在形态上由于业务经理一般在办公室办公，同时需要大量图表，其展示形态以PC端形态呈现；而一线业务人员经常在外面跑，一般携带手机等移动端设备，因此业务版以移动应用形态呈现； 高保真图 PC端：经理版 移动端：员工版 技术选型 在技术选型上，后端采用 Django ，前端采用 AngluarJS，数据库采用了图数据库 neo4j 和关系型数据库 mysql。 那为什么会用到 图数据库 neo4j 呢，主要是由于每间房的人员数量不固定，一般是一对多的关系，而我们那时候希望可以通过住房确定一个关系网，比如房子h1属于房东A，同时住着 B,C,D, 房子h2也属于房东A，同时住着 F,G, 那么用图数据去查询这种关系就会很快了。]]></content>
      <categories>
        <category>随笔日志</category>
        <category>项目管理</category>
      </categories>
      <tags>
        <tag>项目管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[fabric 初步实践]]></title>
    <url>%2F2016%2F%E8%BF%90%E7%BB%B4%2Ffabric-%E5%88%9D%E6%AD%A5%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[在集群部署时，我们经常用到堡垒机作为跳板，堡垒机和集群的其他的用户名、密码、端口号都是不同的，fabric如何进行配置不同的用户、端口号和密码。 fabric作为一种强大的运维工具，可以让部署运维轻松很多，最简单的fabric使用，首先设置env.user, env.port, env.hosts, env.password,如： #coding:utf8from fabric.api import *#用户名env.user = "shikanon"#中转ip，堡垒机env.gateway = "10.17.35.92"env.port = 12303env.hosts = ["192.168.6.%d"%i for i in range(2,11)]#密码env.password = "shikanon_123456" 这样就配置好了集群，但通常情况下为了安全堡垒机和各机器的用户名、端口号、密码都是不同的，那么需要有针对性设置，在fabric中用env.hosts和env.password组合就可以了，不过需要注意的是原来的ip形式需要全部改为user@host:port这种形式，代码如下#需要以user@host:port填写env.gateway = "shikanon@183.3.169.134:12020"env.hosts = ["shikanon@183.3.169.134:12020", "root@192.168.0.171:22", "root@192.168.0.181:22"]#可以定义不同的密码env.passwords = &#123; "shikanon@183.3.169.134:12020":"shikanon_123456", "root@192.168.0.171:22":"12shikanon_3456", "root@192.168.0.181:22":"1234shikanon_56"&#125;#下面是rsa免登录设置#def create_keygen(): with settings(warn_only=True): run("rm -rf shikanon/.ssh") with settings(warn_only=True): run("mkdir -p shikanon/.ssh") with settings(warn_only=True): result = run(r"ssh-keygen -t rsa -P '' -f ~/shikanon/.ssh/id_rsa")def get_ras_id(): get("~/shikanon/.ssh/id_rsa.pub","./rsa/rsa_%s_id_rsa.pub"%(env.host))@runs_oncedef zip(): local("zip -r authorized_keys.zip rsa/")def clean(): run("rm -rf ~/shikanon/")def upload(): run("rm -f authorized_keys.zip") put("authorized_keys.zip","~/shikanon/") with settings(warn_only=True): run("unzip ~/shikanon/authorized_keys.zip -d ~/shikanon/.ssh") rsa_files = run("ls ~/shikanon/.ssh/rsa/") for commandline in rsa_files.split("\r\n"): for rsa_file in commandline.split(" "): if rsa_file: print("rsa_file:",rsa_file) run("cat ~/shikanon/.ssh/rsa/%s &gt;&gt; ~/shikanon/.ssh/authorized_keys"%rsa_file) 以上是一个设置ssh免密码登陆的脚本]]></content>
      <categories>
        <category>技术博文</category>
        <category>系统运维</category>
      </categories>
      <tags>
        <tag>入门教程</tag>
        <tag>fabric</tag>
        <tag>免密码登录</tag>
        <tag>部署</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python中烦人的编码问题]]></title>
    <url>%2F2015%2F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%2Fpython%E4%B8%AD%E7%83%A6%E4%BA%BA%E7%9A%84%E7%BC%96%E7%A0%81%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[被Python2烦了一天写个感想 mysql数据中都是UTF编码，导出到文件称csv还是xls都是utf-8，用python的pandas读取可以，但每次写代码的时候都需要很小心看文件原来是什么编码 比如如果在read_csv()中没用encoding转换为Unicode编码的话在后面的字段名什么都要用.decode(‘utf-8’)来解码巨麻烦，而且在用to_csv()之类的保存时候还得再次用到encoding编码将其Unicode转换为utf-8,而且好像window都不认utf-8的，果然还是应该转换为gbk呢，，， 最最关键是python在shell和自带的IDEL中的编码竟然是不同的！！明明在IDEL中用encoding=utf，也就是 ： #coding=UTF-8print repr('我')#这个是一个utf编码print repr(u'我')#这个是一个Unicodeprint repr('我'.decoding='UTF-8')#这个是一个Unicode但在shell中却是：print repr('我')#这个是一个GBK编码print repr(u'我')#这个是一个用unicode来读的GBK编码，也就是乱码。。。print repr('我'.decode('gbk'))#这个才是一个Unicode 以后再window平台不管三七二一都改成GBK编码算了，省心 Windows上得中文Python二进制包资源：https://www.lfd.uci.edu/~gohlke/pythonlibs/]]></content>
      <categories>
        <category>技术博文</category>
        <category>编程语言</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>编码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于opencv的摄像头脸部识别抓取及格式储存(python)]]></title>
    <url>%2F2014%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2F%E5%9F%BA%E4%BA%8Eopencv%E7%9A%84%E6%91%84%E5%83%8F%E5%A4%B4%E8%84%B8%E9%83%A8%E8%AF%86%E5%88%AB%E6%8A%93%E5%8F%96%E5%8F%8A%E6%A0%BC%E5%BC%8F%E5%82%A8%E5%AD%98-python%2F</url>
    <content type="text"><![CDATA[opencv作为优秀的视觉处理在动态图像处理上也是很不错的，本次主要基于Opencv抓取视频，然后保存为avi，同时进行脸部识别作业 刚接触opencv，参照opencv的sample例子做了一个视频头像抓取的小代码，顺便一起学习着用，先上视频抓取及存储代码： # -*- coding: cp936 -*-import cv2capture=cv2.VideoCapture(0)#将capture保存为motion-jpeg,cv_fourcc为保存格式size = (int(capture.get(cv2.cv.CV_CAP_PROP_FRAME_WIDTH)), int(capture.get(cv2.cv.CV_CAP_PROP_FRAME_HEIGHT)))#cv_fourcc值要设置对，不然无法写入，而且不报错，坑video=cv2.VideoWriter("VideoTest.avi", cv2.cv.CV_FOURCC('I','4','2','0'), 30, size)#isopened可以查看摄像头是否开启print capture.isOpened()num=0#要不断读取image需要设置一个循环while True: ret,img=capture.read() #视频中的图片一张张写入 video.write(img) cv2.imshow('Video',img) key=cv2.waitKey(1)#里面数字为delay时间，如果大于0为刷新时间， #超过指定时间则返回-1，等于0没有返回值,但也可以读取键盘数值， cv2.imwrite('%s.jpg'%(str(num)),img) num=num+1 if key==ord('q'):#ord为键盘输入对应的整数, breakvideo.release()#如果不用release方法的话无法储存，要等结束程序再等摄像头关了才能显示保持成功capture.release()#把摄像头也顺便关了cv2.destroyAllWindows() opencv视频抓取好简单，主要用videowriter就可以了，主要要注意的是opencv中的抓取是放在内存中的，所以需要一个释放命令，不然就只能等到程序关闭后进行垃圾回收时才能释放了。视频抓取就不上图了。 然后是脸部识别，opencv自带了很多特征库有脸部，眼睛的还有很多，原理都一样，只是眼睛的库识别率视乎并不高，直接上代码： #coding=utf-8import cv2import cv2.cv as cvimg = cv2.imread("5.jpg")def detect(img, cascade): '''detectMultiScale函数中smallImg表示的是要检测的输入图像为smallImg，faces表示检测到的人脸目标序列，1.3表示每次图像尺寸减小的比例为1.3， 4表示每一个目标至少要被检测到3次才算是真的目标(因为周围的像素和不同的窗口大小都可以检测到人脸), CV_HAAR_SCALE_IMAGE表示不是缩放分类器来检测，而是缩放图像，Size(20, 20)为目标的最小最大尺寸''' rects = cascade.detectMultiScale(img, scaleFactor=1.3, minNeighbors=5, minSize=(30, 30), flags = cv.CV_HAAR_SCALE_IMAGE) if len(rects) == 0: return [] rects[:,2:] += rects[:,:2] print rects return rects#在img上绘制矩形def draw_rects(img, rects, color): for x1, y1, x2, y2 in rects: cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)#转换为灰度图gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)#直方图均衡处理gray = cv2.equalizeHist(gray)#脸部特征分类地址，里面还有其他cascade_fn = 'data/haarcascades/haarcascade_frontalface_alt.xml'#读取分类器,CascadeClassifier下面有一个detectMultiScale方法来得到矩形cascade = cv2.CascadeClassifier(cascade_fn)#通过分类器得到rectsrects = detect(gray, cascade)#vis为img副本vis = img.copy()#画矩形draw_rects(vis, rects, (0, 255, 0))cv2.imshow('facedetect', vis)cv2.waitKey(0)cv2.destroyAllWindows() 直接上效果图和原图对比：]]></content>
      <categories>
        <category>技术博文</category>
        <category>图像识别</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>opencv</tag>
        <tag>图像识别</tag>
        <tag>摄像头</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[围墙的文化和社会性转变——从里坊制到门禁社区]]></title>
    <url>%2F2014%2F%E7%94%9F%E6%B4%BB%2F%E5%9B%B4%E5%A2%99%E7%9A%84%E6%96%87%E5%8C%96%E5%92%8C%E7%A4%BE%E4%BC%9A%E6%80%A7%E8%BD%AC%E5%8F%98%2F</url>
    <content type="text"><![CDATA[墙被认为是具有保护性和排他性的空间边界，同时是一种隔离的符号。伍尔德喜仁龙(Osvald Siren)在描述中国城市时，曾经提到墙的无处不在：“墙连接着墙，连着还是墙，这形成了每个中国城市的基本构架。哪些墙包围着空间，并且将空间划分成为地块和大院，这标志着中国社区区别于其他结构的基本特征。”墙一直从古代延续到现在，大型的城墙逐渐消失或被遗留为历史遗迹，而作为“空间小碎片”的围墙延续了下来，将城市分割成一块块的“空间碎片”，人被分开成了“墙内人”和“墙外人”，而墙的界限分割了墙内外的认知，使得墙内的人群结构同质化逐渐形成一个相互认同的群体，而墙外则被视为“他者”（the other）的存在。从古代的里坊到现代的门禁社区，由于社会结构的改变，墙的社会性和文化性特征发生了重构，墙的社会控制功能减弱，出于个体安全和归宿的需求增强，墙的构建机制逐渐由权威型主导转向资本型主导，同时使得墙的空间结构发生了重构。 围合的墙——躲避风险的归宿墙是空间的物质载体，构造了实体性空间，使得空间定格在具体的范围中。墙的内部空间得以维持稳定的社会文化空间，在围合的墙内，一切都可以被控制和安全地构建起来。林蔚(Arthur Waldron)在关于中国长城的研究中，提出中国最早的墙可能是为了家庭之间的分隔而建起的。随后，墙的作用被延伸而用于围合村庄和城镇。墙在早期的功能主要是用来规避外界不确定的风险而营造的一个稳定的社会环境，人类为了逃避不安定的自然逐渐建起来了墙。“家”的构建是通过创建“边界”来实现的，墙不仅仅是物质性的边界，更是一种社会和文化的建构，它构建了“家”，使“家”在空间结构上得以体现。 “家”的概念运用不仅仅是强调个人与地方的情感依恋，还强化了与外界的对立，为了强化和维护这种身份统一的幻象，围墙外面的人被构建为“他者”，陌生人和“非家人”。 詹纳（W.J.F.Jenner）认为从连绵万里的长城到几十米高的城墙，再到城市中的基本单元四合院，墙都在努力扮演者将“他者”排除在外，长城将外国人排除在中国之外，城墙将农民排除在城市之外，院墙将外人排除在家庭之外。构建起共同的“他者”概念从而加强对群体的认同。随着历史的变迁，古代的大院逐渐隐退，但它的墙却以一种新的方式延续下来——门禁社区。随着资本的发展，实体空间竞争的矛盾被激发，人们开始选择“簇拥而居”，而在空间选择上，资本使得相似身份的人群在空间上得以“簇拥”同时过滤掉“那些不达标的个体”。特别在资本驱动下，为了给予个体“家”的依恋，“家”的概念被大量构建起来，“墙”也大量的建立起来。 封闭的墙——我与他者的边界围墙或篱笆作为边界的物质性载体，它分隔了空间，同时也分割墙内外的相互认知，对墙内人来说墙内为家人，梦幻乐园，墙外为混乱，吵杂的“他者”。 墙阻隔了认知空间的连续性，使得实践认知在边界处断裂只剩幻想的延续。 规整的墙——社会空间结构的构造詹纳（W.J.F.Jenner）认为墙在中国历史演变中的意义在于围合、限定和社会控制。Huang 认为，围墙之所以在中国社会中长盛不衰，缘于政府长期以来在居住区层面的政治控制，而门禁社区正是这种政治控制的体现。 读书笔记 参考文献 Low S . Behind the Gates: Life , Security and the Pursuit of Happiness in Fortress America 1 New York: Rout le dg e,2003 Davis M . City of quartz: Excavating the Future of Los Angeles 1 New York: Verso , 1990. Sibley, D. Geographies of exclusion: society and difference in the West[M]. London: Routledge, 1995. Dixon, J. Contact and boundaries: ‘Locating’ the social psychology of intergroup relations [J]. Theory &amp; Psychology, 2001, 11(5): 587-608. Young, M. House and home: feminist variations on a theme, in Intersecting Voices: Dilemmas of Gender, Political Philosophy, and Policy[M]. Princeton, NJ: Princeton University Press, 1997: 134 –164. Breitung, W. Borders and the city –Intra-urban boundaries in Guangzhou (China). Quaestiones Geographicae[M]. Poznan: Adam Mickiewicz University Press, 2012. 加藤繁： 《中国经济史考证》 第1 卷， 台北华世出版社 1981 年版， 第 464 页。 （清）曹寅等编纂： 《全唐诗》， 中华书局 1960 年版，第 5041 页。 （宋）宋敏求： 《长安志》卷 7，中华书局 1990 年影印本。 （五代）王溥： 《唐会要》卷 25，上海古籍出版社 1991 年版。 但“有故者不坐”。 （唐）长孙无忌： 《唐律疏议》卷 26《杂律》， 中华书局 1993 年版。 （后晋）刘昫等： 《旧唐书》卷 15，中华书局 1986 年版。 （清）曹寅等编纂： 《全唐诗》， 第 979 页。 （五代）王溥： 《唐会要》卷 86 （五代）王溥： 《唐会要》卷 86 （唐）张九龄： 《唐六典》卷 20，中华书局，1992 出版。]]></content>
      <categories>
        <category>人文地理</category>
        <category>社会学</category>
      </categories>
      <tags>
        <tag>墙</tag>
        <tag>社会隔离</tag>
        <tag>哲学</tag>
        <tag>社会学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线性规划问题解决开源工具(GNU Linear Programming Kit)]]></title>
    <url>%2F2014%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2F%E7%BA%BF%E6%80%A7%E8%A7%84%E5%88%92%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E5%BC%80%E6%BA%90%E5%B7%A5%E5%85%B7-GNU-Linear-Programming-Kit%2F</url>
    <content type="text"><![CDATA[GNU Linear Programming Kit (GLPK)一个开源的线性规划工具，用了一下感觉语法还挺简单了（有点像python的感觉，但没python清晰）向大家介绍一下 入门实践最近在做一个叫交通最小通勤计算问题，需要用到线性规划来解决，因此在网上搜了一下啊线性规划工具，因为不想装MATLAB，(实在是太大了，电脑c盘剩下不到4g了)就找了一个开源的线性规划小工具，感觉还蛮实用的，(GNU Linear Programming Kit, GLPK)[http://gnu.april.org/software/glpk/] 一个开源的线性规划工具，再这里给大家介绍介绍。 glpsol.exe就是主程序了，glpsol.exe主要是通过命令行运行，可以通过 –help 命令了解下他的主要命令： GLPK所使用的编译语言主要是 GNU MathProg language，我主要尝试了glpsol的两个命令–math 和 –model，分别介绍下： 线性规划方程： 本案列就用Sriram在Coursera公开课的上讲的案例直接进行介绍了，math方法是最简单的方法，就是直接把线性方程写下来，找一个txt记事本： var x1&gt;=0;var x2&gt;=0;maximize obj:x1+2*x2;c1:-3*x1+x2&lt;=2;c2:x2&lt;=11;c3:x1-x2&lt;=3;c4:x1&lt;=6;solve;display x1;display x2;end; 可以看出MathProg language很简单，定义变量范围var,定义目标maximize obj:和约束条件就可以了，最后求解solve和显示display 然后保持为first.ampl 在CMD命令行直接输入glpsol –math fitst.ampl就可以了 可以看到结果为这种方法在解决简单少量的线性规划的时候很简单清晰，但是在解决大量线性规划的时候是不具备可操作性的，因此介绍GLPK的第二种命令--model,这种命令可以用两个文件存储一个为MODEL文件，一个为DATA文件，MODEL文件主要通过构建矩阵进行线性规划计算，同样以上面的线性规划为例，可以得出其实上面的约束方程可以看出两个矩阵相乘，分别为一个系数矩阵A和所求矩阵X相乘小于等于b矩阵(A*x&lt;=b)： param m;param n; param c{i in 1..n};param A{i in 1..m,j in 1..n};param b{i in 1..m}; var x{i in 1..n}&gt;=0; maximize obj:sum{i in 1..n} c[i]x[i];s.t.e{j in 1..m}:sum{i in 1..n} A[j,i]x[i]&lt;=b[j]; solve;display x;end;写完model文件还需要写一个赋值的data文件对model中的参数赋值： param n:=2; param m:=4; param c:=1 2：1 2; param A:=1 2：1 -3 12 0 13 1 -14 1 0; param b:= 1：1 22 113 34 6;具体data文件的写作格式可以参考我的百度云盘上的gmpl文件（ http://pan.baidu.com/s/1i3CDq8t ）里面有详细说明，然后只要再在cmd中用命令--model执行就可以了：![GLPK-计算结果](./img/GLPK-计算结果.png)结果和math命令一样，不过内存使用稍微大了点。## 过剩通勤应用&gt; 本文继续对 GNU Linear Programming Kit进行解释，本次介绍引进实际应用，计算最大过剩通勤和最小过剩通勤。---------------通过上面对GLPK的建模计算有了大概了解，本章完成BOSS下达任务，完成一个过剩通勤计算。首先当然是写好model文件,其中最大通勤为： param n;param m; param Population{i in 1..n,j in 1..m};param Distance{i in 1..n,j in 1..m}; var x{i in 1..n,j in 1..m}&gt;=0,integer; maximize obj:sum{i in 1..n}sum{j in 1..m} Distance[i,j]*x[i,j];s.t.e{i in 1..n}:sum{j in 1..m}x[i,j]=sum{j in 1..m}Population[i,j];f{j in 1..m}:sum{i in 1..n}x[i,j]=sum{i in 1..n}Population[i,j]; solve;printf “min sum:%d”,sum{i in 1..n}sum{j in 1..m} Distance[i,j]*x[i,j];end;最小通勤为： param n;param m; param Population{i in 1..n,j in 1..m};param Distance{i in 1..n,j in 1..m}; var x{i in 1..n,j in 1..m}&gt;=0,integer; minimize obj:sum{i in 1..n}sum{j in 1..m} Distance[i,j]*x[i,j];s.t.e{i in 1..n}:sum{j in 1..m}x[i,j]=sum{j in 1..m}Population[i,j];f{j in 1..m}:sum{i in 1..n}x[i,j]=sum{i in 1..n}Population[i,j]; solve;printf “min sum:%d”,sum{i in 1..n}sum{j in 1..m} Distance[i,j]*x[i,j];end;就是将maximize改为miniminze，写了个run.bat文件方便输出： glpsol –model MaxTrafficCommuting.model –data Data.data –output max.solveglpsol –model MinTrafficCommuting.model –data Data.data –output min.solve接下来是data文件部分了，由于原始数据是excel数据，需要先进行格式整理，主要就用pandas进行整理，操作方便，直接附上python代码：（data文件的格式可以参照上一篇GPLK解释的文章） -- coding: cp936 --import pandas as pd def toformat(): #data is big table, and data1 is small table #make the big equal to the small data=pd.read_excel(&apos;Distance.xlsx&apos;,index_col=None)#big data1=pd.read_excel(&apos;Population.xlsx&apos;,index_col=None)#small #change its column data=data[data1.columns] if len(data1.columns)!=len(data.columns): print &quot;row exist Duplicate items&quot; #change its row&apos;s index data=data.loc[data1.index] if len(data1.index)!=len(data.index): print &quot;row exist Duplicate items&quot; data.to_excel(&apos;Distance.xlsx&apos;,sheet_name=&apos;Sheet1&apos;,engine=&apos;xlsxwriter&apos;) #to creat txt file data.to_csv(&apos;Distance.txt&apos;,sep=&apos;\t&apos;) data1.to_csv(&apos;Population.txt&apos;,sep=&apos;\t&apos;) pop,popnum=changeformat(&apos;Population.txt&apos;) dis,disnum=changeformat(&apos;Distance.txt&apos;) if popnum!=disnum: print &apos;两个矩阵大小不相等，请检查数据&apos; print &apos;实际通勤为%d&apos;%(sum(data*data1)) return pop,dis,str(len(data.index)),str(len(data.columns)) def todealmiss(): data=pd.read_excel(‘Population.xlsx’,’Sheet1’,index_col=None,na_values=[‘0’]) data=data.fillna(0) data.to_excel(‘Population.xlsx’,sheet_name=’Sheet1’,engine=’xlsxwriter’) def changeformat(filename=’Population.txt’): with open(filename,’r’) as datafile: data=datafile.read().split(‘\n’) n=len(data) data[0]=&apos;param &apos;+filename[:-4]+&apos;:&apos;+data[0][1:]+&apos;:=&apos; #从excel转换为txt时最后一个空格键多出了一行， data[n-2]=data[n-2]+&apos;;&apos; outputname=&apos;new_&apos;+filename return data,n todealmiss()pop,dis,row,col=toformat()with open(‘Data.data’,’w’) as datafile: datafile.write(‘param n:=’+row+’;’+’\n’) datafile.write(‘param m:=’+col+’;’+’\n’) for p in pop: datafile.write(p+’\n’) for d in dis: datafile.write(d+’\n’)``` 代码写的很乱，没优化了，直接运行结果，总体来说速度还是挺快的，381*381（145161）个数据大概用了5秒多：]]></content>
      <categories>
        <category>技术博文</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>线性规划</tag>
        <tag>GLPK</tag>
        <tag>过剩通勤</tag>
      </tags>
  </entry>
</search>
